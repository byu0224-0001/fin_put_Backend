# -*- coding: utf-8 -*-
"""
Top20 ì‹¤íŒ¨ 12ê°œ ê¸°ì—… ì›ì¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ë¶„ì„ í•­ëª©:
1. ì›ë¬¸ HTMLì—ì„œ í‘œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
2. extract_key_sectionsê°€ ê·¸ í‘œë¥¼ í¬í•¨í–ˆëŠ”ì§€ í™•ì¸
3. í¬í•¨í–ˆëŠ”ë°ë„ LLMì´ ëª» ë½‘ëŠ”ì§€ í™•ì¸
"""
import sys
import os
import json
import re
import time
import requests
from bs4 import BeautifulSoup
from typing import Dict, List, Optional, Tuple

# Windows í™˜ê²½ì—ì„œ UTF-8 ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
    os.environ['PYTHONIOENCODING'] = 'utf-8'
else:
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

sys.path.insert(0, '.')

from app.services.dart_parser import DartParser
from app.services.llm_handler import LLMHandler
from app.services.embedding_filter import select_relevant_chunks
from dotenv import load_dotenv
import logging

load_dotenv()
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

DART_API_KEY = os.getenv('DART_API_KEY')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
MAX_LLM_CHARS = 50000

# ğŸ†• ì‹¤íŒ¨í•œ ê¸°ì—… ëª©ë¡ (refetch_revenue_monitoring.jsonì—ì„œ ë¡œë“œ)
FAILED_TICKERS = [
    "105560",  # KBê¸ˆìœµ
    "000270",  # ê¸°ì•„
    "012450",  # í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤
    "055550",  # ì‹ í•œì§€ì£¼
    "032830",  # ì‚¼ì„±ìƒëª…
    "086790",  # í•˜ë‚˜ê¸ˆìœµì§€ì£¼
    "005490",  # POSCOí™€ë”©ìŠ¤
    "000810",  # ì‚¼ì„±í™”ì¬
    "011200",  # HMM
    "138040",  # ë©”ë¦¬ì¸ ê¸ˆìœµì§€ì£¼
    "096770",  # SKì´ë…¸ë² ì´ì…˜
    "024110",  # ê¸°ì—…ì€í–‰
]


def check_table_in_html(html_content: str, ticker: str, company_name: str) -> Dict:
    """
    ì›ë¬¸ HTMLì—ì„œ í‘œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    
    Returns:
        {
            'has_table': bool,
            'table_count': int,
            'revenue_keywords_found': List[str],
            'table_preview': str  # ì²« ë²ˆì§¸ í‘œì˜ ë¯¸ë¦¬ë³´ê¸°
        }
    """
    if not html_content:
        return {
            'has_table': False,
            'table_count': 0,
            'revenue_keywords_found': [],
            'table_preview': None
        }
    
    soup = BeautifulSoup(html_content, 'html.parser')
    tables = soup.find_all('table')
    
    # ë§¤ì¶œ/ìˆ˜ìµ ê´€ë ¨ í‚¤ì›Œë“œ
    revenue_keywords = [
        'ë§¤ì¶œ', 'ìˆ˜ìµ', 'ì˜ì—…', 'ë¶€ë¬¸', 'ì‚¬ì—…ë¶€ë¬¸', 'ì˜ì—…ì˜ í˜„í™©', 'ì˜ì—…ì˜ ì¢…ë¥˜',
        'ì˜ì—…ìˆ˜ìµ', 'ë‹¹ê¸°ì†ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ë³´í—˜ìˆ˜ìµ', 'ì´ììˆ˜ìµ',
        'ì€í–‰ë¶€ë¬¸', 'ê¸ˆìœµíˆ¬ìë¶€ë¬¸', 'ë³´í—˜ë¶€ë¬¸', 'ìƒëª…ë³´í—˜', 'ì†í•´ë³´í—˜',
        'ì‚¬ì—…ë¶€ë¬¸', 'ë¶€ë¬¸ë³„', 'ì„¸ê·¸ë¨¼íŠ¸', 'ì˜ì—…ì¢…ë¥˜', 'ì˜ì—…ë¶€ë¬¸'
    ]
    
    revenue_keywords_found = []
    table_preview = None
    
    for table in tables:
        table_text = table.get_text()
        table_text_lower = table_text.lower()
        
        # í‚¤ì›Œë“œ í™•ì¸
        for keyword in revenue_keywords:
            if keyword in table_text_lower and keyword not in revenue_keywords_found:
                revenue_keywords_found.append(keyword)
        
        # ì²« ë²ˆì§¸ í‘œ ë¯¸ë¦¬ë³´ê¸° ì €ì¥
        if not table_preview and len(table_text) > 50:
            table_preview = table_text[:500]  # ì²˜ìŒ 500ìë§Œ
    
    return {
        'has_table': len(tables) > 0,
        'table_count': len(tables),
        'revenue_keywords_found': revenue_keywords_found,
        'table_preview': table_preview
    }


def check_table_in_extracted_text(extracted_text: str, ticker: str, company_name: str) -> Dict:
    """
    extract_key_sectionsë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì—ì„œ í‘œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    
    Returns:
        {
            'has_table_markers': bool,  # ë§ˆí¬ë‹¤ìš´ í‘œ ë§ˆì»¤(|) ì¡´ì¬ ì—¬ë¶€
            'table_marker_count': int,
            'revenue_keywords_found': List[str],
            'text_preview': str  # ê´€ë ¨ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°
        }
    """
    if not extracted_text:
        return {
            'has_table_markers': False,
            'table_marker_count': 0,
            'revenue_keywords_found': [],
            'text_preview': None
        }
    
    # ë§ˆí¬ë‹¤ìš´ í‘œ ë§ˆì»¤ í™•ì¸
    table_markers = re.findall(r'\|', extracted_text)
    table_marker_count = len(table_markers)
    has_table_markers = table_marker_count > 10  # ìµœì†Œ 10ê°œ ì´ìƒì˜ |ê°€ ìˆì–´ì•¼ í‘œë¡œ ê°„ì£¼
    
    # ë§¤ì¶œ/ìˆ˜ìµ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
    revenue_keywords = [
        'ë§¤ì¶œ', 'ìˆ˜ìµ', 'ì˜ì—…', 'ë¶€ë¬¸', 'ì‚¬ì—…ë¶€ë¬¸', 'ì˜ì—…ì˜ í˜„í™©', 'ì˜ì—…ì˜ ì¢…ë¥˜',
        'ì˜ì—…ìˆ˜ìµ', 'ë‹¹ê¸°ì†ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ë³´í—˜ìˆ˜ìµ', 'ì´ììˆ˜ìµ',
        'ì€í–‰ë¶€ë¬¸', 'ê¸ˆìœµíˆ¬ìë¶€ë¬¸', 'ë³´í—˜ë¶€ë¬¸', 'ìƒëª…ë³´í—˜', 'ì†í•´ë³´í—˜',
        'ì‚¬ì—…ë¶€ë¬¸', 'ë¶€ë¬¸ë³„', 'ì„¸ê·¸ë¨¼íŠ¸', 'ì˜ì—…ì¢…ë¥˜', 'ì˜ì—…ë¶€ë¬¸'
    ]
    
    revenue_keywords_found = []
    text_lower = extracted_text.lower()
    
    for keyword in revenue_keywords:
        if keyword in text_lower and keyword not in revenue_keywords_found:
            revenue_keywords_found.append(keyword)
    
    # ê´€ë ¨ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸° (í‚¤ì›Œë“œ ì£¼ë³€ í…ìŠ¤íŠ¸)
    text_preview = None
    if revenue_keywords_found:
        # ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ì£¼ë³€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        first_keyword = revenue_keywords_found[0]
        idx = text_lower.find(first_keyword)
        if idx != -1:
            start = max(0, idx - 200)
            end = min(len(extracted_text), idx + 500)
            text_preview = extracted_text[start:end]
    
    return {
        'has_table_markers': has_table_markers,
        'table_marker_count': table_marker_count,
        'revenue_keywords_found': revenue_keywords_found,
        'text_preview': text_preview
    }


def test_llm_extraction(extracted_text: str, ticker: str, company_name: str, llm_handler: LLMHandler) -> Dict:
    """
    LLM ì¶”ì¶œ ì‹œë„ ë° ê²°ê³¼ í™•ì¸
    
    Returns:
        {
            'llm_success': bool,
            'revenue_by_segment': Optional[Dict],
            'error': Optional[str]
        }
    """
    if not extracted_text:
        return {
            'llm_success': False,
            'revenue_by_segment': None,
            'error': 'NO_EXTRACTED_TEXT'
        }
    
    try:
        # í•„í„°ë§
        filtered_text = select_relevant_chunks(extracted_text, ticker=ticker)
        effective_text = filtered_text if filtered_text and len(filtered_text) > 200 else extracted_text
        if len(effective_text) > MAX_LLM_CHARS:
            effective_text = effective_text[:MAX_LLM_CHARS]
        
        # LLM ì¶”ì¶œ ì‹œë„
        structured_data = llm_handler.extract_structured_data(
            effective_text,
            ticker=ticker,
            company_name=company_name
        )
        
        if structured_data and structured_data.get('revenue_by_segment'):
            revenue_data = structured_data.get('revenue_by_segment')
            if isinstance(revenue_data, dict) and len(revenue_data) > 0:
                return {
                    'llm_success': True,
                    'revenue_by_segment': revenue_data,
                    'error': None
                }
        
        return {
            'llm_success': False,
            'revenue_by_segment': None,
            'error': 'NO_REVENUE_DATA_IN_RESPONSE'
        }
    except Exception as e:
        return {
            'llm_success': False,
            'revenue_by_segment': None,
            'error': str(e)
        }


def get_raw_html_from_dart(dart_parser: DartParser, ticker: str, year: int = 2024) -> Optional[str]:
    """
    DARTì—ì„œ ì›ë¬¸ HTML ê°€ì ¸ì˜¤ê¸°
    
    Returns:
        HTML ë¬¸ìì—´ ë˜ëŠ” None
    """
    try:
        # ì‚¬ì—…ë³´ê³ ì„œ ì°¾ê¸°
        report_info = dart_parser.find_business_report(ticker, year)
        if not report_info:
            logger.warning(f"[{ticker}] ì‚¬ì—…ë³´ê³ ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        rcept_no = report_info['rcept_no']
        
        # í•˜ìœ„ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ
        sub_docs = dart_parser.get_sub_docs(rcept_no)
        if sub_docs is None or len(sub_docs) == 0:
            logger.warning(f"[{ticker}] í•˜ìœ„ ë¬¸ì„œ ì—†ìŒ.")
            return None
        
        # "ì˜ì—…ì˜ í˜„í™©" ë˜ëŠ” "ì£¼ìš” ì œí’ˆ ë° ì„œë¹„ìŠ¤" ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
        target_keywords = ['ì˜ì—…ì˜ í˜„í™©', 'ì˜ì—…ì˜ ì¢…ë¥˜', 'ì£¼ìš” ì œí’ˆ', 'ë§¤ì¶œ', 'ì‚¬ì—…ë¶€ë¬¸', 'ì˜ì—…ê°œí™©']
        
        html_content = None
        for idx, row in sub_docs.iterrows():
            title = str(row.get('title', ''))
            url = row.get('url', '')
            
            # ê´€ë ¨ ì„¹ì…˜ ì°¾ê¸°
            if any(keyword in title for keyword in target_keywords):
                try:
                    # URLì—ì„œ HTML ê°€ì ¸ì˜¤ê¸°
                    response = requests.get(url, timeout=30)
                    if response.status_code == 200:
                        html_content = response.text
                        logger.info(f"[{ticker}] ê´€ë ¨ ì„¹ì…˜ HTML ì¶”ì¶œ ì„±ê³µ: {title}")
                        break
                except Exception as e:
                    logger.warning(f"[{ticker}] HTML ì¶”ì¶œ ì‹¤íŒ¨ ({title}): {e}")
        
        # ê´€ë ¨ ì„¹ì…˜ì„ ëª» ì°¾ìœ¼ë©´ "ì‚¬ì—…ì˜ ë‚´ìš©" ì„¹ì…˜ ì‚¬ìš©
        if not html_content:
            for idx, row in sub_docs.iterrows():
                title = str(row.get('title', ''))
                url = row.get('url', '')
                
                if 'ì‚¬ì—…ì˜ ë‚´ìš©' in title or 'ì‚¬ì—…ì˜ ê°œìš”' in title:
                    try:
                        response = requests.get(url, timeout=30)
                        if response.status_code == 200:
                            html_content = response.text
                            logger.info(f"[{ticker}] ì‚¬ì—…ì˜ ë‚´ìš© ì„¹ì…˜ HTML ì¶”ì¶œ ì„±ê³µ: {title}")
                            break
                    except Exception as e:
                        logger.warning(f"[{ticker}] HTML ì¶”ì¶œ ì‹¤íŒ¨ ({title}): {e}")
        
        # ê·¸ë˜ë„ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë¬¸ì„œ ì‚¬ìš©
        if not html_content and len(sub_docs) > 0:
            first_url = sub_docs.iloc[0].get('url', '')
            if first_url:
                try:
                    response = requests.get(first_url, timeout=30)
                    if response.status_code == 200:
                        html_content = response.text
                        logger.info(f"[{ticker}] ì²« ë²ˆì§¸ ë¬¸ì„œ HTML ì¶”ì¶œ ì„±ê³µ")
                except Exception as e:
                    logger.warning(f"[{ticker}] HTML ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return html_content
    except Exception as e:
        logger.error(f"[{ticker}] ì›ë¬¸ HTML ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return None


def analyze_failure_causes():
    """
    Top20 ì‹¤íŒ¨ 12ê°œ ê¸°ì—… ì›ì¸ ë¶„ì„
    """
    if not DART_API_KEY:
        print("âŒ DART_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", flush=True)
        return None
    
    if not OPENAI_API_KEY:
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", flush=True)
        return None
    
    dart_parser = DartParser(DART_API_KEY)
    llm_handler = LLMHandler()
    
    print("=" * 80, flush=True)
    print("Top20 ì‹¤íŒ¨ 12ê°œ ê¸°ì—… ì›ì¸ ë¶„ì„", flush=True)
    print("=" * 80, flush=True)
    
    # ì‹¤íŒ¨í•œ ê¸°ì—… ì •ë³´ ë¡œë“œ
    report_file = 'reports/refetch_revenue_monitoring.json'
    failed_companies = []
    
    if os.path.exists(report_file):
        with open(report_file, 'r', encoding='utf-8') as f:
            report = json.load(f)
        
        results = report.get('results', [])
        for result in results:
            if result.get('status') == 'FAIL' and result.get('ticker') in FAILED_TICKERS:
                failed_companies.append({
                    'ticker': result.get('ticker'),
                    'name': result.get('name'),
                    'error_code': result.get('error_code'),
                    'failure_cause': result.get('failure_cause')
                })
    else:
        # ë¦¬í¬íŠ¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ í‹°ì»¤ë§Œìœ¼ë¡œ ë¶„ì„
        print(f"âš ï¸  ë¦¬í¬íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í‹°ì»¤ë§Œìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.", flush=True)
        for ticker in FAILED_TICKERS:
            failed_companies.append({
                'ticker': ticker,
                'name': f"ê¸°ì—…_{ticker}",
                'error_code': 'NO_REVENUE_DATA',
                'failure_cause': 'B'
            })
    
    print(f"\në¶„ì„ ëŒ€ìƒ: {len(failed_companies)}ê°œ ê¸°ì—…", flush=True)
    print("=" * 80, flush=True)
    
    analysis_results = []
    
    for idx, company in enumerate(failed_companies, 1):
        ticker = company['ticker']
        name = company['name']
        
        print(f"\n[{idx}/{len(failed_companies)}] {name} ({ticker}) ë¶„ì„ ì¤‘...", flush=True)
        
        result = {
            'ticker': ticker,
            'name': name,
            'error_code': company.get('error_code'),
            'failure_cause': company.get('failure_cause'),
            'step1_html_table_check': None,
            'step2_extracted_text_check': None,
            'step3_llm_extraction_test': None,
            'diagnosis': None
        }
        
        # Step 1: ì›ë¬¸ HTMLì—ì„œ í‘œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        print(f"  [Step 1] ì›ë¬¸ HTMLì—ì„œ í‘œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì¤‘...", flush=True)
        try:
            raw_html = get_raw_html_from_dart(dart_parser, ticker, year=2024)
            html_check = check_table_in_html(raw_html, ticker, name) if raw_html else {
                'has_table': False,
                'table_count': 0,
                'revenue_keywords_found': [],
                'table_preview': None
            }
            result['step1_html_table_check'] = html_check
            
            if html_check['has_table']:
                print(f"    âœ… í‘œ ë°œê²¬: {html_check['table_count']}ê°œ", flush=True)
                if html_check['revenue_keywords_found']:
                    print(f"    âœ… ë§¤ì¶œ ê´€ë ¨ í‚¤ì›Œë“œ: {', '.join(html_check['revenue_keywords_found'][:5])}", flush=True)
            else:
                print(f"    âŒ í‘œ ì—†ìŒ", flush=True)
        except Exception as e:
            print(f"    âŒ ì˜¤ë¥˜: {e}", flush=True)
            result['step1_html_table_check'] = {'error': str(e)}
        
        # Step 2: extract_key_sectionsë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ í™•ì¸
        print(f"  [Step 2] extract_key_sections ì¶”ì¶œ í…ìŠ¤íŠ¸ í™•ì¸ ì¤‘...", flush=True)
        try:
            extracted_text = dart_parser.extract_key_sections(ticker, target_year=2024)
            text_check = check_table_in_extracted_text(extracted_text, ticker, name) if extracted_text else {
                'has_table_markers': False,
                'table_marker_count': 0,
                'revenue_keywords_found': [],
                'text_preview': None
            }
            result['step2_extracted_text_check'] = text_check
            
            if text_check['has_table_markers']:
                print(f"    âœ… í‘œ ë§ˆì»¤ ë°œê²¬: {text_check['table_marker_count']}ê°œ", flush=True)
            else:
                print(f"    âŒ í‘œ ë§ˆì»¤ ì—†ìŒ", flush=True)
            
            if text_check['revenue_keywords_found']:
                print(f"    âœ… ë§¤ì¶œ ê´€ë ¨ í‚¤ì›Œë“œ: {', '.join(text_check['revenue_keywords_found'][:5])}", flush=True)
            else:
                print(f"    âŒ ë§¤ì¶œ ê´€ë ¨ í‚¤ì›Œë“œ ì—†ìŒ", flush=True)
        except Exception as e:
            print(f"    âŒ ì˜¤ë¥˜: {e}", flush=True)
            result['step2_extracted_text_check'] = {'error': str(e)}
        
        # Step 3: LLM ì¶”ì¶œ ì‹œë„
        print(f"  [Step 3] LLM ì¶”ì¶œ ì‹œë„ ì¤‘...", flush=True)
        try:
            extracted_text = dart_parser.extract_key_sections(ticker, target_year=2024)
            llm_test = test_llm_extraction(extracted_text, ticker, name, llm_handler) if extracted_text else {
                'llm_success': False,
                'revenue_by_segment': None,
                'error': 'NO_EXTRACTED_TEXT'
            }
            result['step3_llm_extraction_test'] = llm_test
            
            if llm_test['llm_success']:
                revenue_data = llm_test['revenue_by_segment']
                print(f"    âœ… LLM ì¶”ì¶œ ì„±ê³µ: {len(revenue_data)}ê°œ ì„¸ê·¸ë¨¼íŠ¸", flush=True)
                print(f"    ì„¸ê·¸ë¨¼íŠ¸: {list(revenue_data.keys())[:3]}...", flush=True)
            else:
                print(f"    âŒ LLM ì¶”ì¶œ ì‹¤íŒ¨: {llm_test.get('error', 'UNKNOWN')}", flush=True)
        except Exception as e:
            print(f"    âŒ ì˜¤ë¥˜: {e}", flush=True)
            result['step3_llm_extraction_test'] = {'error': str(e)}
        
        # ì§„ë‹¨
        diagnosis = []
        step1 = result.get('step1_html_table_check', {})
        step2 = result.get('step2_extracted_text_check', {})
        step3 = result.get('step3_llm_extraction_test', {})
        
        if step1.get('has_table'):
            if not step2.get('has_table_markers') and not step2.get('revenue_keywords_found'):
                diagnosis.append("ì›ì¸ A: ì›ë¬¸ì— í‘œê°€ ìˆì§€ë§Œ extract_key_sectionsê°€ í‘œë¥¼ í¬í•¨í•˜ì§€ ì•ŠìŒ")
            elif step2.get('has_table_markers') or step2.get('revenue_keywords_found'):
                if not step3.get('llm_success'):
                    diagnosis.append("ì›ì¸ B: í‘œëŠ” í¬í•¨ë˜ì—ˆì§€ë§Œ LLMì´ revenue_by_segmentë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í•¨")
                else:
                    diagnosis.append("âœ… ëª¨ë“  ë‹¨ê³„ í†µê³¼: LLM ì¶”ì¶œ ì„±ê³µ (ì¬ìˆ˜ì§‘ ê°€ëŠ¥)")
            else:
                diagnosis.append("ì›ì¸ ë¶ˆëª…: í‘œëŠ” í¬í•¨ë˜ì—ˆì§€ë§Œ í‚¤ì›Œë“œ/ë§ˆì»¤ ì—†ìŒ")
        else:
            diagnosis.append("ì›ì¸ A: ì›ë¬¸ì— í‘œê°€ ì—†ìŒ (DART ë³´ê³ ì„œ êµ¬ì¡° ë¬¸ì œ)")
        
        result['diagnosis'] = diagnosis
        print(f"  [ì§„ë‹¨] {', '.join(diagnosis)}", flush=True)
        
        analysis_results.append(result)
        
        # Rate limiting
        time.sleep(1)
    
    # ê²°ê³¼ ì €ì¥
    os.makedirs('reports', exist_ok=True)
    output_file = 'reports/failure_cause_analysis.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_results, f, ensure_ascii=False, indent=2, default=str)
    
    print("\n" + "=" * 80, flush=True)
    print("ë¶„ì„ ê²°ê³¼ ìš”ì•½", flush=True)
    print("=" * 80, flush=True)
    
    # ì›ì¸ë³„ í†µê³„
    cause_a_count = sum(1 for r in analysis_results if 'ì›ì¸ A' in str(r.get('diagnosis', [])))
    cause_b_count = sum(1 for r in analysis_results if 'ì›ì¸ B' in str(r.get('diagnosis', [])))
    success_count = sum(1 for r in analysis_results if 'âœ… ëª¨ë“  ë‹¨ê³„ í†µê³¼' in str(r.get('diagnosis', [])))
    
    print(f"\n[ì›ì¸ë³„ ë¶„í¬]", flush=True)
    print(f"  ì›ì¸ A (DART/ì„¹ì…˜ ì¶”ì¶œ ë¬¸ì œ): {cause_a_count}ê°œ", flush=True)
    print(f"  ì›ì¸ B (LLM ì¶”ì¶œ ë¬¸ì œ): {cause_b_count}ê°œ", flush=True)
    print(f"  ì¬ìˆ˜ì§‘ ê°€ëŠ¥ (LLM ì¶”ì¶œ ì„±ê³µ): {success_count}ê°œ", flush=True)
    
    print(f"\nâœ… ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_file}", flush=True)
    print("=" * 80, flush=True)
    
    return analysis_results


if __name__ == '__main__':
    analyze_failure_causes()

