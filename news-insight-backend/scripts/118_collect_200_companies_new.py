# -*- coding: utf-8 -*-
"""
ë¯¸ìˆ˜ì§‘ ê¸°ì—… 200ê°œ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ (ìµœì‹  - ìµœì í™” ë²„ì „)
- ì•„ì§ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ ê¸°ì—… ì¤‘ ì´ë¦„ìˆœìœ¼ë¡œ 200ê°œ ì„ ë³„
- ìš°ì„ ì£¼/ìŠ¤íŒ© ì¢…ëª© ìë™ ì œì™¸
- ë³‘ë ¬ ì²˜ë¦¬ (max_workers=3)
- DART ìˆ˜ì§‘ë§Œ ë³‘ë ¬ ì²˜ë¦¬, ê´€ê³„ ì¶”ì¶œ/ì„¹í„° ë¶„ë¥˜ëŠ” ì „ì²´ ì™„ë£Œ í›„ 1íšŒì”© ì‹¤í–‰
"""
import sys
sys.path.insert(0, '.')
sys.stdout.reconfigure(encoding='utf-8')
import os
import subprocess
import time
from datetime import datetime
import traceback
from dotenv import load_dotenv
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import signal
import psutil
import re

# .env íŒŒì¼ ë¡œë“œ
project_root = Path(__file__).parent.parent
env_path = project_root / '.env'
load_dotenv(dotenv_path=env_path, override=True)

# TensorFlow ë¡œê¹… ì–µì œ
env_for_subprocess = os.environ.copy()
env_for_subprocess['TF_CPP_MIN_LOG_LEVEL'] = '3'
env_for_subprocess['TF_CPP_MIN_VLOG_LEVEL'] = '0'
env_for_subprocess['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'

from app.db import SessionLocal
from app.models import Stock, CompanyDetail
from sqlalchemy import text
from app.utils.preferred_stock import is_preferred_stock_smart

# ë¡œê·¸ íŒŒì¼ (ìƒˆë¡œìš´ ë¡œê·¸)
LOG_FILE = 'data/collect_200_companies_new_log.txt'
KONEX_SKIP_LOG = 'data/konex_skipped_companies.txt'

# ë¡œê·¸ ì“°ê¸°ìš© ë½
log_lock = threading.Lock()

# ì¢…ë£Œ í”Œë˜ê·¸
shutdown_flag = threading.Event()

# Signal í•¸ë“¤ëŸ¬
def signal_handler(signum, frame):
    log("\nâš ï¸  ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ . í˜„ì¬ ì‘ì—… ì™„ë£Œ í›„ ì¢…ë£Œ...")
    shutdown_flag.set()

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def log(msg):
    """ë¡œê·¸ ì¶œë ¥ (ìŠ¤ë ˆë“œ ì•ˆì „)"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    log_msg = f"[{timestamp}] {msg}"
    with log_lock:
        print(log_msg, flush=True)
        try:
            with open(LOG_FILE, 'a', encoding='utf-8') as f:
                f.write(log_msg + '\n')
        except:
            pass

def get_stats():
    """í˜„ì¬ í†µê³„ ì¡°íšŒ"""
    s = SessionLocal()
    try:
        companies = s.execute(text("SELECT COUNT(DISTINCT ticker) FROM company_details")).scalar()
        return companies
    finally:
        s.close()

def is_konex_company(db_session, ticker: str) -> bool:
    """ì½”ë„¥ìŠ¤ ìƒì¥ ê¸°ì—…ì¸ì§€ í™•ì¸"""
    result = db_session.execute(
        text("SELECT market FROM stocks WHERE ticker = :ticker"),
        {'ticker': ticker}
    ).first()
    return result and result[0] == 'KONEX'

def is_spac_or_preferred(stock_name: str) -> bool:
    """ìš°ì„ ì£¼/ìŠ¤íŒ© ì¢…ëª©ì¸ì§€ í™•ì¸"""
    # ìš°ì„ ì£¼ íŒ¨í„´
    preferred_pattern = re.compile(r'ìš°|ìš°B|ìš°\(|ì „í™˜\)', re.IGNORECASE)
    
    # ìŠ¤íŒ© íŒ¨í„´
    spac_pattern = re.compile(r'ìŠ¤íŒ©', re.IGNORECASE)
    
    # ìŠ¤ë§ˆíŠ¸ ì²´í¬
    db_session = SessionLocal()
    try:
        is_pref, _ = is_preferred_stock_smart(stock_name, db_session)
        if is_pref:
            return True
    except:
        pass
    finally:
        db_session.close()
    
    # ì´ë¦„ ê¸°ë°˜ ì²´í¬
    if preferred_pattern.search(stock_name) or spac_pattern.search(stock_name):
        return True
    
    return False

def get_uncollected_companies(limit=200):
    """ë¯¸ìˆ˜ì§‘ ê¸°ì—… ëª©ë¡ ì¡°íšŒ (ì´ë¦„ìˆœ ì •ë ¬, ìš°ì„ ì£¼/ìŠ¤íŒ© ì œì™¸)"""
    db = SessionLocal()
    try:
        # ì´ë¯¸ ìˆ˜ì§‘ëœ ê¸°ì—… í‹°ì»¤ ëª©ë¡
        collected_tickers = set(
            row[0] for row in db.execute(
                text("SELECT DISTINCT ticker FROM company_details")
            ).fetchall()
        )
        
        # ëª¨ë“  í•œêµ­ ì¦ì‹œ ìƒì¥ ê¸°ì—… (KOSPI/KOSDAQë§Œ)
        all_stocks = db.query(Stock).filter(
            Stock.market.in_(['KOSPI', 'KOSDAQ'])
        ).order_by(Stock.stock_name).all()
        
        # ë¯¸ìˆ˜ì§‘ + ìš°ì„ ì£¼/ìŠ¤íŒ© ì œì™¸ + ë§µìŠ¤ë¦¬ì–¼í‹° ì œì™¸
        uncollected = []
        for stock in all_stocks:
            if stock.ticker in collected_tickers:
                continue
            if stock.ticker == '094800':  # ë§µìŠ¤ë¦¬ì–¼í‹° ì œì™¸
                continue
            if is_spac_or_preferred(stock.stock_name):
                continue
            uncollected.append(stock)
        
        log(f"âœ… ì „ì²´ ë¯¸ìˆ˜ì§‘ ê¸°ì—… (ìš°ì„ ì£¼/ìŠ¤íŒ© ì œì™¸): {len(uncollected)}ê°œ ë°œê²¬")
        log(f"ğŸ“‹ ìƒìœ„ {min(limit, len(uncollected))}ê°œ ê¸°ì—… ì„ ë³„")
        
        # ì½”ë„¥ìŠ¤ ê¸°ì—… ì œì™¸
        konex_count = 0
        filtered_uncollected = []
        for stock in uncollected[:limit]:
            if is_konex_company(db, stock.ticker):
                konex_count += 1
                try:
                    with open(KONEX_SKIP_LOG, 'a', encoding='utf-8') as f:
                        f.write(f"{stock.ticker}\t{stock.stock_name}\n")
                except:
                    pass
                continue
            filtered_uncollected.append(stock)
        
        if konex_count > 0:
            log(f"âš ï¸  ì½”ë„¥ìŠ¤ ê¸°ì—… ì œì™¸: {konex_count}ê°œ")
        
        log(f"âœ… ì‹¤ì œ ìˆ˜ì§‘ ëŒ€ìƒ: {len(filtered_uncollected)}ê°œ")
        
        return filtered_uncollected
    
    finally:
        db.close()

def process_single_company(stock, index, total, env_for_subprocess):
    """ë‹¨ì¼ ê¸°ì—… ì²˜ë¦¬ í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ìš©) - DART ìˆ˜ì§‘ë§Œ"""
    ticker = stock.ticker
    name = stock.stock_name
    result = {
        'ticker': ticker,
        'name': name,
        'status': 'FAILED',
        'error': None,
        'index': index
    }
    
    db_session = SessionLocal()
    
    try:
        log(f"ğŸ”„ [{index}/{total}] {ticker}: {name} - DART ìˆ˜ì§‘ ì‹œì‘")
        
        # 1. DART ìˆ˜ì§‘
        dart_script = project_root / "scripts" / "04_fetch_dart.py"
        dart_result = subprocess.run(
            ["python", str(dart_script), "--ticker", ticker],
            cwd=str(project_root),
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace',
            timeout=600,  # 10ë¶„ (ì •ìƒ ìˆ˜ì§‘ ì‹œ ì¶©ë¶„)
            env=env_for_subprocess
        )
        
        time.sleep(0.5)  # DB ì»¤ë°‹ í™•ì¸ìš© ìµœì†Œ ëŒ€ê¸°ë§Œ
        db_session.expire_all()
        
        db_data_exists = db_session.query(CompanyDetail).filter(
            CompanyDetail.ticker == ticker
        ).first() is not None
        
        if not db_data_exists:
            error_msg = (dart_result.stderr[:500] if dart_result.stderr else dart_result.stdout[:500]) or 'Unknown error'
            # TensorFlow ê²½ê³  í•„í„°ë§
            error_lines = error_msg.split('\n')
            filtered_errors = [l for l in error_lines if 'tensorflow' not in l.lower() and 'tf_' not in l.lower() and l.strip()]
            error_msg = '\n'.join(filtered_errors) if filtered_errors else 'Unknown error'
            
            result['status'] = 'FAILED'
            result['error'] = f"DART ìˆ˜ì§‘ ì‹¤íŒ¨: {error_msg[:200]}"
            log(f"âŒ [{index}/{total}] {ticker}: {name} - DBì— ë°ì´í„° ì—†ìŒ")
            return result
        
        log(f"âœ… [{index}/{total}] {ticker}: {name} - DART ìˆ˜ì§‘ ì™„ë£Œ")
        
        result['status'] = 'SUCCESS'
        return result
    
    except subprocess.TimeoutExpired:
        result['status'] = 'FAILED'
        result['error'] = "Timeout"
        log(f"â±ï¸  [{index}/{total}] {ticker}: {name} - íƒ€ì„ì•„ì›ƒ")
        return result
    except Exception as e:
        result['status'] = 'FAILED'
        result['error'] = str(e)[:200]
        log(f"âŒ [{index}/{total}] {ticker}: {name} - ì˜¤ë¥˜: {str(e)[:100]}")
        return result
    finally:
        db_session.close()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™”
        with open(LOG_FILE, 'w', encoding='utf-8') as f:
            f.write(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ======================================================================\n")
            f.write(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ë¯¸ìˆ˜ì§‘ ê¸°ì—… 200ê°œ ìˆ˜ì§‘ ì‹œì‘\n")
            f.write(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ======================================================================\n")
        
        log("=" * 70)
        log("ë¯¸ìˆ˜ì§‘ ê¸°ì—… 200ê°œ ìˆ˜ì§‘ ì‹œì‘")
        log("=" * 70)
        
        initial_count = get_stats()
        log(f"ì´ˆê¸° ìƒíƒœ: {initial_count}ê°œ ê¸°ì—…")
        
        # ë¯¸ìˆ˜ì§‘ ê¸°ì—… ëª©ë¡ ì¡°íšŒ
        uncollected_companies = get_uncollected_companies(limit=200)
        
        if not uncollected_companies:
            log("âŒ ìˆ˜ì§‘í•  ê¸°ì—…ì´ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        log(f"\n{'='*70}")
        log(f"ì´ {len(uncollected_companies)}ê°œ ê¸°ì—… ìˆ˜ì§‘ ì‹œì‘")
        log(f"{'='*70}")
        
        success = 0
        failed = 0
        failed_list = []
        completed_count = 0
        
        start_time = datetime.now()
        
        log(f"ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (max_workers=5, íƒ€ì„ì•„ì›ƒ: 10ë¶„)\n")
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_stock = {
                executor.submit(process_single_company, stock, i, len(uncollected_companies), env_for_subprocess): (stock, i)
                for i, stock in enumerate(uncollected_companies, 1)
            }
            
            log(f"âœ… ì´ {len(future_to_stock)}ê°œ ì‘ì—… ì œì¶œ ì™„ë£Œ\n")
            
            for future in as_completed(future_to_stock):
                if shutdown_flag.is_set():
                    log("\nâš ï¸  ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ...")
                    break
                
                stock, index = future_to_stock[future]
                completed_count += 1
                
                try:
                    result = future.result(timeout=1)
                    
                    if result['status'] == 'SUCCESS':
                        success += 1
                        log(f"âœ… [{completed_count}/{len(uncollected_companies)}] {result['ticker']}: {result['name']} - ì„±ê³µ")
                    else:
                        failed += 1
                        failed_list.append({
                            'ticker': result['ticker'],
                            'name': result['name'],
                            'error': result.get('error', 'Unknown error')
                        })
                        log(f"âŒ [{completed_count}/{len(uncollected_companies)}] {result['ticker']}: {result['name']} - ì‹¤íŒ¨")
                    
                    if completed_count % 50 == 0:
                        current_count = get_stats()
                        elapsed = datetime.now() - start_time
                        log("=" * 70)
                        log(f"ğŸ“ [{completed_count}/{len(uncollected_companies)}] ì¤‘ê°„ ì²´í¬")
                        log(f"ì„±ê³µ: {success}, ì‹¤íŒ¨: {failed}")
                        log(f"í˜„ì¬ ì´ ê¸°ì—…: {current_count}ê°œ (+{current_count - initial_count})")
                        log(f"ì†Œìš” ì‹œê°„: {elapsed}")
                        log("=" * 70 + "\n")
                
                except Exception as e:
                    failed += 1
                    failed_list.append({
                        'ticker': stock.ticker,
                        'name': stock.stock_name,
                        'error': str(e)[:200]
                    })
                    log(f"âŒ [{completed_count}/{len(uncollected_companies)}] {stock.ticker}: {stock.stock_name} - ì˜ˆì™¸: {str(e)[:100]}")
        
        # ìµœì¢… ê²°ê³¼
        elapsed = datetime.now() - start_time
        final_count = get_stats()
        
        log("\n" + "=" * 70)
        log("DART ìˆ˜ì§‘ ì™„ë£Œ!")
        log("=" * 70)
        log(f"ì„±ê³µ: {success}ê°œ")
        log(f"ì‹¤íŒ¨: {failed}ê°œ")
        log(f"ì´ ê¸°ì—…: {final_count}ê°œ (+{final_count - initial_count})")
        log(f"ì†Œìš” ì‹œê°„: {elapsed}")
        
        if failed_list:
            log(f"\nâŒ ì‹¤íŒ¨ ëª©ë¡ ({len(failed_list)}ê°œ):")
            for item in failed_list[:20]:
                log(f"  - {item['ticker']}: {item['name']}")
            if len(failed_list) > 20:
                log(f"  ... ì™¸ {len(failed_list) - 20}ê°œ")
        
        # ì„¹í„° ë¶„ë¥˜ (ì „ì²´ DB ëŒ€ìƒ, 1íšŒë§Œ) - ê´€ê³„ ì¶”ì¶œë³´ë‹¤ ë¨¼ì € ì‹¤í–‰
        log("\n" + "=" * 70)
        log("ì„¹í„° ë¶„ë¥˜ ì‹œì‘ (ì „ì²´ DB ëŒ€ìƒ, 1íšŒ)")
        log("=" * 70)
        relation_script = project_root / "scripts" / "05_extract_relations.py"
        relation_log_file = project_root / "data" / "relation_extraction_log.txt"
        
        # ê´€ê³„ ì¶”ì¶œ ì „ Edge ìˆ˜ í™•ì¸
        db_check = SessionLocal()
        try:
            edges_before = db_check.execute(text("SELECT COUNT(*) FROM edges")).scalar()
            value_chain_before = db_check.execute(text("SELECT COUNT(*) FROM edges WHERE relation_type = 'VALUE_CHAIN_RELATED'")).scalar()
            log(f"ê´€ê³„ ì¶”ì¶œ ì „ Edge ìˆ˜: {edges_before:,}ê°œ (VALUE_CHAIN_RELATED: {value_chain_before:,}ê°œ)")
        finally:
            db_check.close()
        
        try:
            # ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡í•˜ë©´ì„œ ì‹¤ì‹œê°„ ì¶œë ¥ë„ ìœ ì§€
            with open(relation_log_file, 'w', encoding='utf-8') as log_file:
                relation_result = subprocess.run(
                    ["python", str(relation_script)],
                    cwd=str(project_root),
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    encoding='utf-8',
                    errors='replace',
                    timeout=1800,  # 30ë¶„
                    env=env_for_subprocess
                )
                
                # ì¶œë ¥ì„ ë¡œê·¸ íŒŒì¼ê³¼ í™”ë©´ì— ë™ì‹œì— ê¸°ë¡
                output = relation_result.stdout
                log_file.write(output)
                print(output, flush=True)  # ì‹¤ì‹œê°„ ì¶œë ¥
                
                # ê²°ê³¼ íŒŒì‹±í•˜ì—¬ ìš”ì•½ ë¡œê·¸ì— ê¸°ë¡
                import re
                if "ê´€ê³„ ì¶”ì¶œ ì™„ë£Œ" in output:
                    # Edge ìƒì„± ìˆ˜ ì¶”ì¶œ
                    edge_match = re.search(r'ìƒì„±ëœ Edge:\s*(\d+)ê°œ', output)
                    supplies_match = re.search(r'SUPPLIES_TO.*?(\d+)ê°œ', output)
                    sells_match = re.search(r'SELLS_TO.*?(\d+)ê°œ', output)
                    potential_match = re.search(r'POTENTIAL_SUPPLIES_TO.*?(\d+)ê°œ', output)
                    value_chain_match = re.search(r'VALUE_CHAIN_RELATED.*?(\d+)ê°œ', output)
                    companies_match = re.search(r'ì²˜ë¦¬ ê¸°ì—… ìˆ˜:\s*(\d+)ê°œ', output)
                    
                    if edge_match:
                        log(f"âœ… ê´€ê³„ ì¶”ì¶œ ì™„ë£Œ: Edge {edge_match.group(1)}ê°œ ìƒì„±")
                    if companies_match:
                        log(f"âœ… ì²˜ë¦¬ ê¸°ì—… ìˆ˜: {companies_match.group(1)}ê°œ")
                    if supplies_match:
                        log(f"  - SUPPLIES_TO: {supplies_match.group(1)}ê°œ")
                    if sells_match:
                        log(f"  - SELLS_TO: {sells_match.group(1)}ê°œ")
                    if potential_match:
                        log(f"  - POTENTIAL_SUPPLIES_TO: {potential_match.group(1)}ê°œ")
                    if value_chain_match:
                        log(f"  - VALUE_CHAIN_RELATED (ë°¸ë¥˜ì²´ì¸ ê¸°ë°˜): {value_chain_match.group(1)}ê°œ âœ…")
                    else:
                        log(f"  - VALUE_CHAIN_RELATED: 0ê°œ (ë°¸ë¥˜ì²´ì¸ Edge ìƒì„± ì•ˆ ë¨)")
            
            # ê´€ê³„ ì¶”ì¶œ í›„ Edge ìˆ˜ í™•ì¸
            db_check = SessionLocal()
            try:
                edges_after = db_check.execute(text("SELECT COUNT(*) FROM edges")).scalar()
                value_chain_after = db_check.execute(text("SELECT COUNT(*) FROM edges WHERE relation_type = 'VALUE_CHAIN_RELATED'")).scalar()
                edges_created = edges_after - edges_before
                value_chain_created = value_chain_after - value_chain_before
                
                log("\n" + "=" * 70)
                log("ê´€ê³„ ì¶”ì¶œ ê²°ê³¼ í™•ì¸")
                log("=" * 70)
                log(f"ì „ì²´ Edge ìˆ˜: {edges_before:,}ê°œ â†’ {edges_after:,}ê°œ (+{edges_created:,}ê°œ)")
                log(f"VALUE_CHAIN_RELATED Edge: {value_chain_before:,}ê°œ â†’ {value_chain_after:,}ê°œ (+{value_chain_created:,}ê°œ)")
                
                if value_chain_created > 0:
                    log(f"âœ… ë°¸ë¥˜ì²´ì¸ ë¶„ì„ ì™„ë£Œ: {value_chain_created:,}ê°œ VALUE_CHAIN_RELATED Edge ìƒì„±ë¨")
                else:
                    log(f"âš ï¸  ë°¸ë¥˜ì²´ì¸ ë¶„ì„: VALUE_CHAIN_RELATED Edge ìƒì„± ì•ˆ ë¨ (ì„¹í„° ë¶„ë¥˜ í›„ ì¬ì‹¤í–‰ í•„ìš”í•  ìˆ˜ ìˆìŒ)")
                log("=" * 70)
            finally:
                db_check.close()
            
            if relation_result.returncode == 0:
                log("âœ… ê´€ê³„ ì¶”ì¶œ ì™„ë£Œ")
            else:
                log(f"âš ï¸  ê´€ê³„ ì¶”ì¶œ ì¢…ë£Œ ì½”ë“œ: {relation_result.returncode}")
        except subprocess.TimeoutExpired:
            log("â±ï¸  ê´€ê³„ ì¶”ì¶œ íƒ€ì„ì•„ì›ƒ (30ë¶„ ì´ˆê³¼)")
        except Exception as e:
            log(f"âŒ ê´€ê³„ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)[:200]}")
        
        # ì„¹í„° ë¶„ë¥˜ (ì „ì²´ DB ëŒ€ìƒ, 1íšŒë§Œ)
        log("\n" + "=" * 70)
        log("ì„¹í„° ë¶„ë¥˜ ì‹œì‘ (ì „ì²´ DB ëŒ€ìƒ, 1íšŒ)")
        log("=" * 70)
        sector_script = project_root / "scripts" / "45_auto_classify_sectors.py"
        sector_log_file = project_root / "data" / "sector_classification_log.txt"
        
        # ì„¹í„° ë¶„ë¥˜ ì „ ìƒíƒœ í™•ì¸
        db_check = SessionLocal()
        try:
            # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            table_exists = db_check.execute(text("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_schema = 'public'
                    AND table_name = 'investor_sector'
                )
            """)).scalar()
            
            if not table_exists:
                log("âš ï¸  investor_sector í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
                log("   â†’ ì„¹í„° ë¶„ë¥˜ ìŠ¤í¬ë¦½íŠ¸ê°€ ìë™ìœ¼ë¡œ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                log("   â†’ í…Œì´ë¸” ìƒì„± í›„ ì„¹í„° ë¶„ë¥˜ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.")
                sectors_before = 0
                value_chain_before = 0
            else:
                sectors_before = db_check.execute(text("SELECT COUNT(*) FROM investor_sector")).scalar()
                value_chain_before = db_check.execute(text("SELECT COUNT(*) FROM investor_sector WHERE value_chain IS NOT NULL")).scalar()
                log(f"ì„¹í„° ë¶„ë¥˜ ì „: {sectors_before:,}ê°œ ê¸°ì—… (value_chain ë¶„ë¥˜: {value_chain_before:,}ê°œ)")
        except Exception as e:
            log(f"âš ï¸  ì„¹í„° ë¶„ë¥˜ ì „ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)[:200]}")
            log("   â†’ ì„¹í„° ë¶„ë¥˜ë¥¼ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤ (í…Œì´ë¸” ìë™ ìƒì„± ê°€ëŠ¥)")
            sectors_before = 0
            value_chain_before = 0
        finally:
            db_check.close()
        
        try:
            # ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡í•˜ë©´ì„œ ì‹¤ì‹œê°„ ì¶œë ¥ë„ ìœ ì§€
            with open(sector_log_file, 'w', encoding='utf-8') as log_file:
                sector_result = subprocess.run(
                    ["python", str(sector_script)],
                    cwd=str(project_root),
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    encoding='utf-8',
                    errors='replace',
                    timeout=1800,  # 30ë¶„
                    env=env_for_subprocess
                )
                
                output = sector_result.stdout
                log_file.write(output)
                print(output, flush=True)
                
                # ê²°ê³¼ íŒŒì‹±
                import re
                if "ì„¹í„° ë¶„ë¥˜ ì™„ë£Œ" in output or "ì„±ê³µ" in output:
                    success_match = re.search(r'ì„±ê³µ\s*:\s*(\d+)ê°œ', output)
                    skip_match = re.search(r'ìŠ¤í‚µ\s*:\s*(\d+)ê°œ', output)
                    fail_match = re.search(r'ì‹¤íŒ¨\s*:\s*(\d+)ê°œ', output)
                    
                    if success_match:
                        log(f"âœ… ì„¹í„° ë¶„ë¥˜ ì„±ê³µ: {success_match.group(1)}ê°œ")
                    if skip_match:
                        log(f"  - ìŠ¤í‚µ: {skip_match.group(1)}ê°œ")
                    if fail_match:
                        log(f"  - ì‹¤íŒ¨: {fail_match.group(1)}ê°œ")
            
            # ì„¹í„° ë¶„ë¥˜ í›„ ìƒíƒœ í™•ì¸
            db_check = SessionLocal()
            try:
                # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ ì¬í™•ì¸
                table_exists = db_check.execute(text("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_schema = 'public'
                        AND table_name = 'investor_sector'
                    )
                """)).scalar()
                
                if not table_exists:
                    log("âš ï¸  ì„¹í„° ë¶„ë¥˜ í›„ì—ë„ investor_sector í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
                    log("   â†’ ì„¹í„° ë¶„ë¥˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    sectors_after = 0
                    value_chain_after = 0
                    sectors_created = 0
                    value_chain_created = 0
                else:
                    sectors_after = db_check.execute(text("SELECT COUNT(*) FROM investor_sector")).scalar()
                    value_chain_after = db_check.execute(text("SELECT COUNT(*) FROM investor_sector WHERE value_chain IS NOT NULL")).scalar()
                    sectors_created = sectors_after - sectors_before
                    value_chain_created = value_chain_after - value_chain_before
                    
                    log("\n" + "=" * 70)
                    log("ì„¹í„° ë¶„ë¥˜ ê²°ê³¼ í™•ì¸")
                    log("=" * 70)
                    log(f"ì „ì²´ ì„¹í„° ë¶„ë¥˜: {sectors_before:,}ê°œ â†’ {sectors_after:,}ê°œ (+{sectors_created:,}ê°œ)")
                    log(f"Value Chain ìœ„ì¹˜ ë¶„ë¥˜: {value_chain_before:,}ê°œ â†’ {value_chain_after:,}ê°œ (+{value_chain_created:,}ê°œ)")
                    
                    if value_chain_created > 0:
                        log(f"âœ… Value Chain ìœ„ì¹˜ ë¶„ë¥˜ ì™„ë£Œ: {value_chain_created:,}ê°œ ê¸°ì—…")
                    elif sectors_created > 0:
                        log(f"âš ï¸  ì„¹í„°ëŠ” ë¶„ë¥˜ë˜ì—ˆìœ¼ë‚˜ Value Chain ìœ„ì¹˜ëŠ” ë¶„ë¥˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                        log(f"   â†’ 45_auto_classify_sectors.pyì—ì„œ value_chain ë¶„ë¥˜ ë¡œì§ í™•ì¸ í•„ìš”")
            finally:
                db_check.close()
            
            if sector_result.returncode == 0:
                log("âœ… ì„¹í„° ë¶„ë¥˜ ì™„ë£Œ")
            else:
                log(f"âš ï¸  ì„¹í„° ë¶„ë¥˜ ì¢…ë£Œ ì½”ë“œ: {sector_result.returncode}")
        except subprocess.TimeoutExpired:
            log("â±ï¸  ì„¹í„° ë¶„ë¥˜ íƒ€ì„ì•„ì›ƒ (30ë¶„ ì´ˆê³¼)")
        except Exception as e:
            log(f"âŒ ì„¹í„° ë¶„ë¥˜ ì˜¤ë¥˜: {str(e)[:200]}")
        
        # ê´€ê³„ ì¶”ì¶œ (ì „ì²´ DB ëŒ€ìƒ, 1íšŒë§Œ) - ì„¹í„° ë¶„ë¥˜ í›„ ì‹¤í–‰
        log("\n" + "=" * 70)
        log("ê´€ê³„ ì¶”ì¶œ ì‹œì‘ (ì „ì²´ DB ëŒ€ìƒ, 1íšŒ)")
        log("=" * 70)
        relation_script = project_root / "scripts" / "05_extract_relations.py"
        relation_log_file = project_root / "data" / "relation_extraction_log.txt"
        
        # ê´€ê³„ ì¶”ì¶œ ì „ Edge ìˆ˜ í™•ì¸
        db_check = SessionLocal()
        try:
            edges_before = db_check.execute(text("SELECT COUNT(*) FROM edges")).scalar()
            value_chain_before = db_check.execute(text("SELECT COUNT(*) FROM edges WHERE relation_type = 'VALUE_CHAIN_RELATED'")).scalar()
            
            # ì„¹í„° ë¶„ë¥˜ ì™„ë£Œ ì—¬ë¶€ í™•ì¸
            sector_table_exists = db_check.execute(text("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_schema = 'public'
                    AND table_name = 'investor_sector'
                )
            """)).scalar()
            
            if sector_table_exists:
                sectors_count = db_check.execute(text("SELECT COUNT(*) FROM investor_sector")).scalar()
                value_chain_count = db_check.execute(text("SELECT COUNT(*) FROM investor_sector WHERE value_chain IS NOT NULL")).scalar()
                log(f"ê´€ê³„ ì¶”ì¶œ ì „ Edge ìˆ˜: {edges_before:,}ê°œ (VALUE_CHAIN_RELATED: {value_chain_before:,}ê°œ)")
                log(f"ì„¹í„° ë¶„ë¥˜ ìƒíƒœ: {sectors_count:,}ê°œ ê¸°ì—… (value_chain ë¶„ë¥˜: {value_chain_count:,}ê°œ)")
                
                if value_chain_count == 0:
                    log("âš ï¸  Value Chain ìœ„ì¹˜ ë¶„ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤. VALUE_CHAIN_RELATED EdgeëŠ” ìƒì„±ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                log(f"ê´€ê³„ ì¶”ì¶œ ì „ Edge ìˆ˜: {edges_before:,}ê°œ (VALUE_CHAIN_RELATED: {value_chain_before:,}ê°œ)")
                log("âš ï¸  investor_sector í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. VALUE_CHAIN_RELATED EdgeëŠ” ìƒì„±ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        finally:
            db_check.close()
        
        try:
            # ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡í•˜ë©´ì„œ ì‹¤ì‹œê°„ ì¶œë ¥ë„ ìœ ì§€
            with open(relation_log_file, 'w', encoding='utf-8') as log_file:
                relation_result = subprocess.run(
                    ["python", str(relation_script)],
                    cwd=str(project_root),
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    encoding='utf-8',
                    errors='replace',
                    timeout=1800,  # 30ë¶„
                    env=env_for_subprocess
                )
                
                # ì¶œë ¥ì„ ë¡œê·¸ íŒŒì¼ê³¼ í™”ë©´ì— ë™ì‹œì— ê¸°ë¡
                output = relation_result.stdout
                log_file.write(output)
                print(output, flush=True)  # ì‹¤ì‹œê°„ ì¶œë ¥
                
                # ê²°ê³¼ íŒŒì‹±í•˜ì—¬ ìš”ì•½ ë¡œê·¸ì— ê¸°ë¡
                import re
                if "ê´€ê³„ ì¶”ì¶œ ì™„ë£Œ" in output:
                    # Edge ìƒì„± ìˆ˜ ì¶”ì¶œ
                    edge_match = re.search(r'ìƒì„±ëœ Edge:\s*(\d+)ê°œ', output)
                    supplies_match = re.search(r'SUPPLIES_TO.*?(\d+)ê°œ', output)
                    sells_match = re.search(r'SELLS_TO.*?(\d+)ê°œ', output)
                    potential_match = re.search(r'POTENTIAL_SUPPLIES_TO.*?(\d+)ê°œ', output)
                    value_chain_match = re.search(r'VALUE_CHAIN_RELATED.*?(\d+)ê°œ', output)
                    companies_match = re.search(r'ì²˜ë¦¬ ê¸°ì—… ìˆ˜:\s*(\d+)ê°œ', output)
                    
                    if edge_match:
                        log(f"âœ… ê´€ê³„ ì¶”ì¶œ ì™„ë£Œ: Edge {edge_match.group(1)}ê°œ ìƒì„±")
                    if companies_match:
                        log(f"âœ… ì²˜ë¦¬ ê¸°ì—… ìˆ˜: {companies_match.group(1)}ê°œ")
                    if supplies_match:
                        log(f"  - SUPPLIES_TO: {supplies_match.group(1)}ê°œ")
                    if sells_match:
                        log(f"  - SELLS_TO: {sells_match.group(1)}ê°œ")
                    if potential_match:
                        log(f"  - POTENTIAL_SUPPLIES_TO: {potential_match.group(1)}ê°œ")
                    if value_chain_match:
                        log(f"  - VALUE_CHAIN_RELATED (ë°¸ë¥˜ì²´ì¸ ê¸°ë°˜): {value_chain_match.group(1)}ê°œ âœ…")
                    else:
                        log(f"  - VALUE_CHAIN_RELATED: 0ê°œ (ë°¸ë¥˜ì²´ì¸ Edge ìƒì„± ì•ˆ ë¨)")
            
            # ê´€ê³„ ì¶”ì¶œ í›„ Edge ìˆ˜ í™•ì¸
            db_check = SessionLocal()
            try:
                edges_after = db_check.execute(text("SELECT COUNT(*) FROM edges")).scalar()
                value_chain_after = db_check.execute(text("SELECT COUNT(*) FROM edges WHERE relation_type = 'VALUE_CHAIN_RELATED'")).scalar()
                edges_created = edges_after - edges_before
                value_chain_created = value_chain_after - value_chain_before
                
                log("\n" + "=" * 70)
                log("ê´€ê³„ ì¶”ì¶œ ê²°ê³¼ í™•ì¸")
                log("=" * 70)
                log(f"ì „ì²´ Edge ìˆ˜: {edges_before:,}ê°œ â†’ {edges_after:,}ê°œ (+{edges_created:,}ê°œ)")
                log(f"VALUE_CHAIN_RELATED Edge: {value_chain_before:,}ê°œ â†’ {value_chain_after:,}ê°œ (+{value_chain_created:,}ê°œ)")
                
                if value_chain_created > 0:
                    log(f"âœ… ë°¸ë¥˜ì²´ì¸ ë¶„ì„ ì™„ë£Œ: {value_chain_created:,}ê°œ VALUE_CHAIN_RELATED Edge ìƒì„±ë¨")
                else:
                    log(f"âš ï¸  ë°¸ë¥˜ì²´ì¸ ë¶„ì„: VALUE_CHAIN_RELATED Edge ìƒì„± ì•ˆ ë¨")
                    log(f"   â†’ ì„¹í„° ë¶„ë¥˜ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸ í•„ìš”")
                log("=" * 70)
            finally:
                db_check.close()
            
            if relation_result.returncode == 0:
                log("âœ… ê´€ê³„ ì¶”ì¶œ ì™„ë£Œ")
            else:
                log(f"âš ï¸  ê´€ê³„ ì¶”ì¶œ ì¢…ë£Œ ì½”ë“œ: {relation_result.returncode}")
        except subprocess.TimeoutExpired:
            log("â±ï¸  ê´€ê³„ ì¶”ì¶œ íƒ€ì„ì•„ì›ƒ (30ë¶„ ì´ˆê³¼)")
        except Exception as e:
            log(f"âŒ ê´€ê³„ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)[:200]}")
        
        log("\n" + "=" * 70)
        log("ì „ì²´ ì‘ì—… ì™„ë£Œ!")
        log("=" * 70)
        
        log("\n" + "=" * 70)
        log(f"ğŸ“‹ ë¡œê·¸ íŒŒì¼: {LOG_FILE}")
        log("=" * 70)
        
    except Exception as e:
        log(f"âŒ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
    finally:
        sys.stdout.flush()
        sys.stderr.flush()
        try:
            sys.exit(0)
        except:
            import os
            os._exit(0)

if __name__ == "__main__":
    main()

