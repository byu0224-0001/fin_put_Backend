"""
LLM Handler Service

LLM í˜¸ì¶œ ê´€ë¦¬, JSON ê²€ì¦ ë° ìˆ˜ë¦¬, Fallback ëª¨ë¸ ì§€ì›
"""
import json
import logging
import os
import re
from typing import Dict, Optional, Any, Tuple
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
import json_repair
from app.services.retry_handler import retry_llm_api, llm_rate_limiter

logger = logging.getLogger(__name__)


class LLMHandler:
    """LLM í˜¸ì¶œ ë° ì‘ë‹µ ì²˜ë¦¬ í•¸ë“¤ëŸ¬"""
    
    def __init__(
        self,
        analysis_model: str = "gpt-5-mini",
        summary_model: str = "gpt-5-nano",
        api_key: Optional[str] = None,
        temperature: float = 0.0
    ):
        """
        Args:
            analysis_model: ë¶„ì„ìš© LLM ëª¨ë¸ëª…
            summary_model: ìš”ì•½ìš© LLM ëª¨ë¸ëª…
            api_key: OpenAI API Key (callableì´ë©´ ë¬¸ìì—´ë¡œ ë³€í™˜)
            temperature: Temperature ì„¤ì • (ì‚¬ìš©ì ì…ë ¥ ê·¸ëŒ€ë¡œ ì „ë‹¬)
        """
        self.analysis_model = analysis_model
        self.summary_model = summary_model
        
        # API í‚¤ë¥¼ ë¬¸ìì—´ë¡œ ê°•ì œ ë³€í™˜ (async callable ì˜¤ë¥˜ ë°©ì§€)
        key = api_key if api_key is not None else os.getenv("OPENAI_API_KEY", "")
        try:
            if callable(key):
                key = key()
        except Exception as key_error:
            logger.warning(f"API key callable í˜¸ì¶œ ì‹¤íŒ¨: {key_error}")
            key = os.getenv("OPENAI_API_KEY", "")
        key = str(key) if key is not None else ""
        self.api_key = key
        
        # ë¶„ì„ìš© LLM
        self.llm = ChatOpenAI(
            model=analysis_model,
            openai_api_key=self.api_key,
            temperature=temperature
        )
        
        # ìš”ì•½ìš© LLM
        self.summary_llm = ChatOpenAI(
            model=summary_model,
            openai_api_key=self.api_key,
            temperature=temperature
        )
    
    @retry_llm_api
    @llm_rate_limiter
    def summarize(
        self,
        text: str,
        max_length: Optional[int] = None,
        target_length: Optional[int] = None
    ) -> str:
        """
        ê¸´ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½ (gpt-5-nano ì‚¬ìš©)
        
        Args:
            text: ìš”ì•½í•  í…ìŠ¤íŠ¸
            max_length: ìµœëŒ€ ê¸¸ì´ (ìë™ ê³„ì‚° ì‹œ None)
            target_length: ëª©í‘œ ê¸¸ì´
        
        Returns:
            ìš”ì•½ëœ í…ìŠ¤íŠ¸
        """
        if not text or not text.strip():
            return ""
        
        # ë™ì  ê¸¸ì´ ì¡°ì •
        if max_length is None:
            text_length = len(text)
            if text_length > 50000:
                max_length = 15000
            elif text_length > 30000:
                max_length = 12000
            else:
                max_length = 10000
        
        if target_length is None:
            target_length = max_length
        
        logger.info(f"í…ìŠ¤íŠ¸ ìš”ì•½ ì¤‘... (ì›ë³¸: {len(text)}ì â†’ ëª©í‘œ: {target_length}ì)")
        
        prompt = f"""
        ë‹¤ìŒ ì‚¬ì—…ë³´ê³ ì„œ ë‚´ìš©ì„ {target_length}ì ì´ë‚´ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜.
        
        [í¬í•¨í•  í•µì‹¬ ì •ë³´]
        - ì‚¬ì—… ë‚´ìš© ë° ì£¼ìš” ì œí’ˆ/ì„œë¹„ìŠ¤
        - ì£¼ìš” ê³ ê°ì‚¬/ë§¤ì¶œì²˜
        - í•µì‹¬ ì›ì¬ë£Œ
        - ë¹„ìš© êµ¬ì¡°
        - ê²½ì˜ ì „ëµ ë° ì „ë§
        
        [ì œì™¸í•  ë‚´ìš©]
        - ë©´ì±… ì¡°í•­
        - ì˜ˆì¸¡ ì •ë³´ ì£¼ì˜ì‚¬í•­
        - ë²•ê·œìƒ ê·œì œ ì‚¬í•­
        - ë°˜ë³µë˜ëŠ” í‘œë‚˜ ìˆ«ì ë‚˜ì—´
        
        ì›ë¬¸:
        {text[:50000]}  # ìµœëŒ€ 50,000ìê¹Œì§€ë§Œ
        """
        
        messages = [
            SystemMessage(content="You are a financial analyst. Summarize the business report concisely, focusing on key business information."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = self.summary_llm.invoke(messages)
            summarized = response.content.strip()
            logger.info(f"ìš”ì•½ ì™„ë£Œ: {len(summarized)}ì")
            return summarized
        except Exception as e:
            logger.error(f"ìš”ì•½ ì‹¤íŒ¨: {e}")
            # Fallback: ì›ë¬¸ ë°˜í™˜ (ê¸¸ì´ ì œí•œ)
            return text[:max_length]
    
    def is_financial_company(
        self,
        company_name: Optional[str] = None,
        ticker: Optional[str] = None,
        business_summary: Optional[str] = None,
        keywords: Optional[list] = None
    ) -> bool:
        """
        ê¸ˆìœµì‚¬ ì—¬ë¶€ íŒë‹¨ (financial_company_detector ì‚¬ìš©)
        
        ğŸ†• P1-4: ê¸ˆìœµì‚¬ ê°ì§€ ì¼ì›í™” - financial_company_detector ì‚¬ìš©
        
        Args:
            ticker: ì¢…ëª©ì½”ë“œ
            business_summary: ì‚¬ì—… ìš”ì•½
            company_name: íšŒì‚¬ëª…
            keywords: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ê¸ˆìœµì‚¬ ì—¬ë¶€ (True/False)
        """
        from app.services.financial_company_detector import detect_financial_company
        
        is_financial, _, _ = detect_financial_company(
            ticker=ticker,
            company_name=company_name,
            business_summary=business_summary,
            keywords=keywords
        )
        
        return is_financial
    
    def detect_single_segment(self, text: str) -> Tuple[bool, Optional[str]]:
        """
        P0-2: ë‹¨ì¼ ë³´ê³ ë¶€ë¬¸ ê°ì§€
        
        Returns:
            (is_single_segment, reason)
        """
        single_segment_keywords = [
            'í•˜ë‚˜ì˜ ë³´ê³  ë¶€ë¬¸', 'ë‹¨ì¼ ë³´ê³ ë¶€ë¬¸', 'í•˜ë‚˜ì˜ ë³´ê³ ë¶€ë¬¸',
            'ë‹¨ì¼ ë¶€ë¬¸', 'í•˜ë‚˜ì˜ ë¶€ë¬¸', 'ë‹¨ì¼ë³´ê³ ë¶€ë¬¸',
            'ì—°ê²°ì‹¤ì²´ëŠ” í•˜ë‚˜ì˜ ë³´ê³  ë¶€ë¬¸', 'í•˜ë‚˜ì˜ ë³´ê³  ë¶€ë¬¸ìœ¼ë¡œ êµ¬ì„±'
        ]
        
        text_lower = text.lower()
        for keyword in single_segment_keywords:
            if keyword in text_lower:
                return True, f"REPORT_STATES_SINGLE_SEGMENT:{keyword}"
        
        return False, None
    
    def handle_single_segment(
        self,
        text: str,
        company_name: Optional[str],
        ticker: Optional[str]
    ) -> Optional[Dict[str, float]]:
        """
        P0-2: ë‹¨ì¼ ë¶€ë¬¸ ì²˜ë¦¬
        
        Returns:
            {"ë‹¨ì¼ë¶€ë¬¸": 100.0} ë˜ëŠ” ì¡°ê±´ ì¶©ì¡± ì‹œ {"ì™„ì„±ì°¨(ìë™ì°¨ ì œì¡°)": 100.0}
        """
        is_single, reason = self.detect_single_segment(text)
        if not is_single:
            return None
        
        # ì¡°ê±´: íšŒì‚¬ëª…+í…ìŠ¤íŠ¸ì— 'ìë™ì°¨ ì œì¡°/ì™„ì„±ì°¨' ëª…ì‹œ
        auto_keywords = ['ì™„ì„±ì°¨', 'ìë™ì°¨ ì œì¡°', 'ìŠ¹ìš©', 'RV', 'ìë™ì°¨ íŒë§¤', 'ìë™ì°¨']
        text_lower = text.lower()
        company_lower = (company_name or "").lower()
        
        has_auto_context = any(kw in text_lower or kw in company_lower for kw in auto_keywords)
        
        if has_auto_context and (company_name and ('ê¸°ì•„' in company_name or ticker == '000270')):
            logger.info(f"[{ticker or 'N/A'}] ë‹¨ì¼ ë¶€ë¬¸ ê°ì§€ + ìë™ì°¨ ì»¨í…ìŠ¤íŠ¸ â†’ ì™„ì„±ì°¨ ë¼ë²¨ë§")
            return {"ì™„ì„±ì°¨(ìë™ì°¨ ì œì¡°)": 100.0}
        
        logger.info(f"[{ticker or 'N/A'}] ë‹¨ì¼ ë¶€ë¬¸ ê°ì§€ â†’ ë‹¨ì¼ë¶€ë¬¸ ë¼ë²¨ë§")
        return {"ë‹¨ì¼ë¶€ë¬¸": 100.0}
    
    def extract_text_percentages(self, text: str) -> Optional[Dict[str, float]]:
        """
        P0-3: í…ìŠ¤íŠ¸ì—ì„œ "OOì‚¬ì—… 67%" íŒ¨í„´ ì¶”ì¶œ (ì˜¤íƒ ë°©ì§€ ê°•í™”)
        
        Returns:
            {"ì„ìœ ì‚¬ì—…": 67.0, "í™”í•™ì‚¬ì—…": 14.0, ...} ë˜ëŠ” None
        """
        # ğŸ†• P0-B: ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ (ë§¤ì¶œ ë¹„ì¤‘ ê´€ë ¨ í‚¤ì›Œë“œë§Œ í—ˆìš©)
        context_keywords = ['ë§¤ì¶œ', 'ë¹„ì¤‘', 'ì°¨ì§€', 'êµ¬ì„±', 'ì‚¬ì—…', 'ë¶€ë¬¸', 'ìˆ˜ìµ', 'ì˜ì—…', 'ë§¤ì¶œì•¡', 'ë§¤ì¶œë¹„ì¤‘']
        
        # íŒ¨í„´ 1: "OOì‚¬ì—…/ë¶€ë¬¸ 67%" ë˜ëŠ” "OO 67%"
        pattern1 = r'([ê°€-í£A-Za-z0-9/&\-\s]+?)\s*(ì‚¬ì—…|ë¶€ë¬¸)?\s*(ì´|ê°€)?\s*(\d{1,2}(?:\.\d+)?)\s*%'
        # íŒ¨í„´ 2: "67%ëŠ” OOì‚¬ì—…"
        pattern2 = r'(\d{1,2}(?:\.\d+)?)\s*%[ëŠ”ì€ì´ê°€]?\s*([ê°€-í£A-Za-z0-9/&\-\s]+?)(?:ì‚¬ì—…|ë¶€ë¬¸)?'
        
        results = {}
        
        # íŒ¨í„´ 1 ì ìš©
        for match in re.finditer(pattern1, text):
            groups = match.groups()
            if len(groups) >= 4:
                segment = groups[0].strip()
                pct_str = groups[3]
                match_start = match.start()
                match_end = match.end()
                
                # ğŸ†• P0-B: ì£¼ë³€ 20ì ì´ë‚´ì— ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ í™•ì¸
                context_start = max(0, match_start - 20)
                context_end = min(len(text), match_end + 20)
                context_text = text[context_start:context_end].lower()
                
                has_context = any(kw in context_text for kw in context_keywords)
                if not has_context:
                    continue  # ì»¨í…ìŠ¤íŠ¸ ì—†ìœ¼ë©´ ìŠ¤í‚µ (ì˜¤íƒ ë°©ì§€)
                
                try:
                    pct = float(pct_str)
                    # ì„¸ê·¸ë¨¼íŠ¸ëª… ì •ë¦¬
                    segment = re.sub(r'\s*(ì‚¬ì—…|ë¶€ë¬¸)\s*$', '', segment)
                    if segment and 0 < pct <= 100:
                        # ì¤‘ë³µ ì œê±° (ê°™ì€ ì„¸ê·¸ë¨¼íŠ¸ë©´ ë” í° ê°’ ì‚¬ìš©)
                        if segment not in results or results[segment] < pct:
                            results[segment] = pct
                except (ValueError, TypeError):
                    continue
        
        # íŒ¨í„´ 2 ì ìš©
        for match in re.finditer(pattern2, text):
            groups = match.groups()
            if len(groups) >= 2:
                pct_str = groups[0]
                segment = groups[1].strip()
                match_start = match.start()
                match_end = match.end()
                
                # ğŸ†• P0-B: ì£¼ë³€ 20ì ì´ë‚´ì— ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ í™•ì¸
                context_start = max(0, match_start - 20)
                context_end = min(len(text), match_end + 20)
                context_text = text[context_start:context_end].lower()
                
                has_context = any(kw in context_text for kw in context_keywords)
                if not has_context:
                    continue  # ì»¨í…ìŠ¤íŠ¸ ì—†ìœ¼ë©´ ìŠ¤í‚µ (ì˜¤íƒ ë°©ì§€)
                
                try:
                    pct = float(pct_str)
                    # ì„¸ê·¸ë¨¼íŠ¸ëª… ì •ë¦¬
                    segment = re.sub(r'\s*(ì‚¬ì—…|ë¶€ë¬¸)\s*$', '', segment)
                    if segment and 0 < pct <= 100:
                        if segment not in results or results[segment] < pct:
                            results[segment] = pct
                except (ValueError, TypeError):
                    continue
        
        if len(results) >= 2:
            total = sum(results.values())
            # í•©ê³„ê°€ 70-130% ë²”ìœ„ë©´ ìœ íš¨
            if 70.0 <= total <= 130.0:
                logger.info(f"í…ìŠ¤íŠ¸ ê¸°ë°˜ % ì¶”ì¶œ ì„±ê³µ: {len(results)}ê°œ ì„¸ê·¸ë¨¼íŠ¸, ì´ {total:.1f}%")
                return results
            else:
                logger.debug(f"í…ìŠ¤íŠ¸ ê¸°ë°˜ % ì¶”ì¶œ: í•©ê³„ ë²”ìœ„ ì´ˆê³¼ ({total:.1f}%, ë²”ìœ„: 70-130%)")
        else:
            logger.debug(f"í…ìŠ¤íŠ¸ ê¸°ë°˜ % ì¶”ì¶œ: ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ ë¶€ì¡± ({len(results)}ê°œ, ìµœì†Œ 2ê°œ í•„ìš”)")
        
        return None
    
    @retry_llm_api
    @llm_rate_limiter
    def extract_structured_data(
        self,
        text: str,
        ticker: Optional[str] = None,
        company_name: Optional[str] = None,
        schema: Optional[Dict[str, Any]] = None
    ) -> Optional[Dict[str, Any]]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ (gpt-5-mini ì‚¬ìš©)
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            schema: JSON ìŠ¤í‚¤ë§ˆ (ì„ íƒì‚¬í•­)
        
        Returns:
            ì¶”ì¶œëœ ë°ì´í„° (Dict) ë˜ëŠ” None
        """
        if not text or not text.strip():
            return None
        
        # ê¸ˆìœµì‚¬ ì—¬ë¶€ íŒë‹¨
        is_financial = self.is_financial_company(
            ticker=ticker,
            business_summary=text[:500] if text else None,  # ì²˜ìŒ 500ìë§Œ í™•ì¸
            company_name=company_name
        )
        
        if is_financial:
            logger.info("ê¸ˆìœµì‚¬ë¡œ ê°ì§€ë¨ - ê¸ˆìœµì‚¬ ì „ìš© í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
            prompt = self._get_financial_prompt()
        else:
            logger.info("ì¼ë°˜ ê¸°ì—…ìœ¼ë¡œ ê°ì§€ë¨ - ì œì¡°ì—… í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
            prompt = self._get_manufacturing_prompt()
        
        logger.info("AI ë¶„ì„ ë° JSON êµ¬ì¡°í™” ì¤‘...")
        
        messages = [
            SystemMessage(content="You are a precise financial analyst. Extract only factual information from the provided text. Do not hallucinate or make assumptions. Output JSON only."),
            HumanMessage(content=prompt + "\n\n[ì‚¬ì—…ë³´ê³ ì„œ ë‚´ìš©]\n" + text[:50000])  # ìµœëŒ€ 50,000ì
        ]
        
        try:
            response = self.llm.invoke(messages)
            content = response.content.replace("```json", "").replace("```", "").strip()
            
            # JSON ìˆ˜ë¦¬ ì‹œë„
            try:
                parsed_data = json.loads(content)
            except json.JSONDecodeError:
                logger.warning("JSON íŒŒì‹± ì‹¤íŒ¨, json_repairë¡œ ìˆ˜ë¦¬ ì‹œë„ ì¤‘...")
                try:
                    repaired_json = json_repair.repair_json(content)
                    parsed_data = json.loads(repaired_json)
                    logger.info("JSON ìˆ˜ë¦¬ ì„±ê³µ")
                except Exception as repair_error:
                    logger.error(f"JSON ìˆ˜ë¦¬ ì‹¤íŒ¨: {repair_error}")
                    logger.debug(f"ì›ë³¸ ì‘ë‹µ: {content[:500]}")
                    return None
            
            # âœ… íƒ€ì… ê²€ì¦ ê°•í™”: parsed_dataê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆë©´ ì˜¤ë¥˜
            if not isinstance(parsed_data, dict):
                logger.error(f"íŒŒì‹±ëœ ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤. íƒ€ì…: {type(parsed_data)}, ê°’: {str(parsed_data)[:200]}")
                return None
            
            # í•˜ìœ„ í˜¸í™˜ì„±: supply_chainì´ ì—†ìœ¼ë©´ raw_materialsì—ì„œ ìƒì„± ì‹œë„
            if 'supply_chain' not in parsed_data or not parsed_data.get('supply_chain'):
                if 'raw_materials' in parsed_data and parsed_data['raw_materials']:
                    # raw_materialsë¥¼ supply_chain í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ê³µê¸‰ì‚¬ ì •ë³´ ì—†ìŒ)
                    parsed_data['supply_chain'] = [
                        {"item": item, "supplier": "ì •ë³´ì—†ìŒ"} 
                        for item in parsed_data['raw_materials']
                    ]
            
            # risk_factors í•„ë“œ ì œê±° (í† í° ì ˆì•½)
            if 'risk_factors' in parsed_data:
                del parsed_data['risk_factors']
            
            # âœ… Pydantic ëª¨ë¸ì„ ì‚¬ìš©í•œ ë°ì´í„° ê²€ì¦ ë° íƒ€ì… ë³€í™˜
            try:
                from app.models.llm_output import LLMOutputModel
                
                # Pydantic ëª¨ë¸ë¡œ ê²€ì¦ ë° íƒ€ì… ë³€í™˜
                validated_data = LLMOutputModel(**parsed_data)
                logger.info("Pydantic ê²€ì¦ ì™„ë£Œ - ìˆ«ì í•„ë“œ ë³€í™˜ ë° ë¦¬ìŠ¤íŠ¸ í•„ë“œ ê²€ì¦ ì™„ë£Œ")
                
                # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
                parsed_data = validated_data.to_dict()
                
            except Exception as validation_error:
                logger.warning(f"Pydantic ê²€ì¦ ì‹¤íŒ¨, ê¸°ë³¸ ê²€ì¦ìœ¼ë¡œ ëŒ€ì²´: {validation_error}")
                # Pydantic ê²€ì¦ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
                is_financial = 'financial_value_chain' in parsed_data and parsed_data.get('financial_value_chain')
                
                if is_financial:
                    parsed_data['supply_chain'] = []
                
                # í•„ìˆ˜ í•„ë“œ ê¸°ë³¸ê°’ ì„¤ì •
                required_fields = {
                    'business_summary': "ì •ë³´ì—†ìŒ",
                    'major_products': [],
                    'major_clients': "ì •ë³´ì—†ìŒ",
                    'supply_chain': [],
                    'capax_investment': "ì •ë³´ì—†ìŒ",
                    'cost_structure': "ì •ë³´ì—†ìŒ",
                    'keywords': []
                }
                
                for field, default_value in required_fields.items():
                    if field not in parsed_data:
                        logger.warning(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}, ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ì›€")
                        parsed_data[field] = default_value
            
            # âœ… ìµœì¢… ë°˜í™˜ ì „ íƒ€ì… ì¬í™•ì¸ (ì•ˆì „ì¥ì¹˜)
            if not isinstance(parsed_data, dict):
                logger.error(f"ìµœì¢… ê²€ì¦ ì‹¤íŒ¨: parsed_dataê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤. íƒ€ì…: {type(parsed_data)}")
                return None
            
            logger.info("êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
            
            # ğŸ†• P0-2/P0-3: revenue_by_segmentê°€ ì—†ìœ¼ë©´ Fallback ë¡œì§ ì‹œë„
            if parsed_data and not parsed_data.get('revenue_by_segment'):
                logger.warning(f"[{ticker or 'N/A'}] LLMì—ì„œ revenue_by_segment ì¶”ì¶œ ì‹¤íŒ¨, Fallback ë¡œì§ ì‹œë„")
                
                # Fallback 1: ë‹¨ì¼ ë¶€ë¬¸ ê°ì§€
                single_segment_data = self.handle_single_segment(text, company_name, ticker)
                if single_segment_data:
                    logger.info(f"[{ticker or 'N/A'}] ë‹¨ì¼ ë¶€ë¬¸ ì²˜ë¦¬ ì„±ê³µ: {single_segment_data}")
                    parsed_data['revenue_by_segment'] = single_segment_data
                    return parsed_data
                else:
                    logger.debug(f"[{ticker or 'N/A'}] ë‹¨ì¼ ë¶€ë¬¸ ê°ì§€ ì‹¤íŒ¨")
                
                # Fallback 2: í…ìŠ¤íŠ¸ ê¸°ë°˜ % ì¶”ì¶œ
                text_percentages = self.extract_text_percentages(text)
                if text_percentages:
                    logger.info(f"[{ticker or 'N/A'}] í…ìŠ¤íŠ¸ ê¸°ë°˜ % ì¶”ì¶œ ì„±ê³µ: {text_percentages}")
                    parsed_data['revenue_by_segment'] = text_percentages
                    return parsed_data
                else:
                    logger.debug(f"[{ticker or 'N/A'}] í…ìŠ¤íŠ¸ ê¸°ë°˜ % ì¶”ì¶œ ì‹¤íŒ¨ (íŒ¨í„´ ë¯¸ë§¤ì¹­ ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ë¶€ì¡±)")
                
                # Fallback 3: ê¸ˆìœµì‚¬ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©í–ˆëŠ”ë° revenue_by_segmentê°€ ì—†ìœ¼ë©´ ì œì¡°ì—… í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
                if is_financial:
                    logger.warning(f"[{ticker or 'N/A'}] ê¸ˆìœµì‚¬ í”„ë¡¬í”„íŠ¸ì—ì„œ revenue_by_segment ì¶”ì¶œ ì‹¤íŒ¨, ì œì¡°ì—… í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„")
                    prompt = self._get_manufacturing_prompt()
                    messages = [
                        SystemMessage(content="You are a precise financial analyst. Extract only factual information from the provided text. Do not hallucinate or make assumptions. Output JSON only."),
                        HumanMessage(content=prompt + "\n\n[ì‚¬ì—…ë³´ê³ ì„œ ë‚´ìš©]\n" + text[:50000])
                    ]
                    try:
                        response = self.llm.invoke(messages)
                        content = response.content.replace("```json", "").replace("```", "").strip()
                        
                        try:
                            retry_parsed_data = json.loads(content)
                        except json.JSONDecodeError:
                            try:
                                repaired_json = json_repair.repair_json(content)
                                retry_parsed_data = json.loads(repaired_json)
                            except Exception:
                                retry_parsed_data = None
                        
                        if retry_parsed_data and isinstance(retry_parsed_data, dict) and retry_parsed_data.get('revenue_by_segment'):
                            logger.info(f"[{ticker or 'N/A'}] ì œì¡°ì—… í”„ë¡¬í”„íŠ¸ ì¬ì‹œë„ ì„±ê³µ: revenue_by_segment ì¶”ì¶œë¨")
                            parsed_data['revenue_by_segment'] = retry_parsed_data.get('revenue_by_segment')
                    except Exception as retry_error:
                        logger.warning(f"[{ticker or 'N/A'}] ì œì¡°ì—… í”„ë¡¬í”„íŠ¸ ì¬ì‹œë„ ì‹¤íŒ¨: {retry_error}")
            
            return parsed_data  # âœ… ë°˜ë“œì‹œ ë”•ì…”ë„ˆë¦¬ë§Œ ë°˜í™˜
            
        except Exception as e:
            error_str = str(e).lower()
            error_msg = str(e)
            
            # OpenAI API quota ì˜¤ë¥˜ ê°ì§€
            if any(keyword in error_str for keyword in [
                "insufficient_quota", "quota", "rate limit", 
                "exceeded your current quota", "billing"
            ]):
                logger.error(f"âš ï¸ OpenAI API Quota ì´ˆê³¼: {error_msg}")
                # quota ì˜¤ë¥˜ëŠ” íŠ¹ë³„íˆ í‘œì‹œí•˜ê¸° ìœ„í•´ ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒ
                raise ValueError(f"QUOTA_ERROR: {error_msg}")
            
            logger.error(f"LLM ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            logger.debug(f"ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            return None  # âœ… ì˜ˆì™¸ ë°œìƒ ì‹œ None ë°˜í™˜ (ë¬¸ìì—´ ì ˆëŒ€ ë°˜í™˜ ì•ˆ í•¨)
    
    def _get_manufacturing_prompt(self) -> str:
        """ì œì¡°ì—…/ì¼ë°˜ ê¸°ì—…ìš© í”„ë¡¬í”„íŠ¸"""
        return """
        ë„ˆëŠ” 10ë…„ ì°¨ í€ë“œë§¤ë‹ˆì €ì•¼. ì œê³µëœ ê¸°ì—…ì˜ [ì‚¬ì—…ë³´ê³ ì„œ] ë‚´ìš©ì„ ë¶„ì„í•´ì„œ 
        íˆ¬ì íŒë‹¨ì— í•„ìš”í•œ í•µì‹¬ ì •ë³´ë¥¼ ì•„ë˜ JSON í¬ë§·ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´.
        
        [ğŸ”¥ ìµœìš°ì„  í™•ì¸: "ì‚¬ì—…ì˜ ê°œìš”" ì„¹ì…˜]
        - "â…¡. ì‚¬ì—…ì˜ ë‚´ìš© > 1. ì‚¬ì—…ì˜ ê°œìš”"ì—ì„œ íšŒì‚¬ ì†Œê°œì™€ ë§¤ì¶œ ë¹„ì¤‘ í…Œì´ë¸”ì´ ìˆìŒ
        - ì´ ì„¹ì…˜ì—ì„œ íšŒì‚¬ê°€ ì–´ë–¤ ì‚¬ì—…ì„ í•˜ëŠ”ì§€ (ì§€ì£¼íšŒì‚¬, ì œì¡°ì—…, ì„œë¹„ìŠ¤ì—… ë“±)ë¥¼ ë¨¼ì € íŒŒì•…í•  ê²ƒ
        - ì‚¬ì—…ì˜ ê°œìš” ë‚´ ë§¤ì¶œì•¡ í…Œì´ë¸”ì´ ìˆìœ¼ë©´ revenue_by_segment ì¶”ì¶œì— í™œìš©í•  ê²ƒ
        
        [ì¤‘ìš” ì§€ì¹¨]
        - ì œê³µëœ í…ìŠ¤íŠ¸ì—ì„œë§Œ ì •ë³´ë¥¼ ì¶”ì¶œí•  ê²ƒ (ì¶”ì¸¡í•˜ì§€ ë§ê²ƒ)
        - ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ì •ë³´ëŠ” "ì •ë³´ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œ
        - êµ¬ì²´ì ì¸ ìˆ«ì, ì´ë¦„, ì‚¬ì‹¤ë§Œ í¬í•¨í•  ê²ƒ
        
        [ì¶”ì¶œ í•­ëª©]
        1. business_summary: "ì‚¬ì—…ì˜ ê°œìš”"ì—ì„œ íšŒì‚¬ê°€ ì–´ë–¤ ì‚¬ì—…ì„ ì˜ìœ„í•˜ëŠ”ì§€ 3ì¤„ ìš”ì•½.
           - ì§€ì£¼íšŒì‚¬ì¸ ê²½ìš° "ì§€ì£¼íšŒì‚¬ë¡œì„œ ìíšŒì‚¬ ì§€ë¶„ ë³´ìœ  ë° ë°°ë‹¹ê¸ˆ ìˆ˜ìµ, ì„ëŒ€ìˆ˜ìµ, ë¡œì—´í‹° ìˆ˜ìµ ë“±ì„ ì˜ìœ„" í˜•íƒœë¡œ ëª…ì‹œ
           - ì œì¡°ì—…ì¸ ê²½ìš° ì£¼ìš” ì œí’ˆê³¼ ì‚¬ì—… ì˜ì—­ì„ ëª…í™•íˆ ê¸°ìˆ 
        2. major_products: ì£¼ìš” ì œí’ˆ ë° ì„œë¹„ìŠ¤ ë¦¬ìŠ¤íŠ¸ (êµ¬ì²´ì  ë¸Œëœë“œë‚˜ ëª¨ë¸ëª… í¬í•¨). ë³´ê³ ì„œì— ëª…ì‹œëœ ê²ƒë§Œ.
        3. major_clients: ì£¼ìš” ë§¤ì¶œì²˜/ê³ ê°ì‚¬ ì‹¤ëª… (ì˜ˆ: Apple, í˜„ëŒ€ì°¨). ë³´ê³ ì„œì— ëª…ì‹œëœ ê²ƒë§Œ. ì—†ìœ¼ë©´ "ì •ë³´ì—†ìŒ".
        4. supply_chain: ì›ì¬ë£Œ-ê³µê¸‰ì‚¬ ìŒ ë¦¬ìŠ¤íŠ¸. í‘œì˜ 'ë§¤ì…ì²˜' ì»¬ëŸ¼ì—ì„œ ì‹¤ëª… ì¶”ì¶œ.
           í¬ë§·: [{"item": "ì›ì¬ë£Œëª…", "supplier": "ê³µê¸‰ì‚¬1, ê³µê¸‰ì‚¬2"}]
           'ê¸°íƒ€', 'êµ­ë‚´ë²•ì¸' ë“± ì‹¤ëª…ì´ ì•„ë‹ˆë©´ ì œì™¸.
        5. capax_investment: ì„¤ë¹„íˆ¬ì(CAPEX)ë‚˜ ì‹ ê·œ ì‹œì„¤ íˆ¬ì ê³„íš ì–¸ê¸‰ ìš”ì•½. ë³´ê³ ì„œì— ëª…ì‹œëœ ê²ƒë§Œ.
        6. cost_structure: ë¹„ìš© êµ¬ì¡°ì—ì„œ ê°€ì¥ í° ë¹„ì¤‘ì„ ì°¨ì§€í•˜ëŠ” ê²ƒ (ì˜ˆ: ì›ì¬ë£Œë¹„, ì¸ê±´ë¹„). ë³´ê³ ì„œì— ëª…ì‹œëœ ê²ƒë§Œ.
        7. keywords: ê¸°ì—…ì„ ì„¤ëª…í•˜ëŠ” í•µì‹¬ í•´ì‹œíƒœê·¸ 5~7ê°œ.
           - ë°˜ë“œì‹œ í¬í•¨: ì‚°ì—… ë¶„ì•¼ (ì˜ˆ: #ì§€ì£¼íšŒì‚¬, #í™”ì¥í’ˆ, #ë°˜ë„ì²´, #ì˜ë¥˜)
           - ì‚¬ì—… íŠ¹ì„± (ì˜ˆ: #OEM, #ODM, #ìˆ˜ì¶œì¤‘ì‹¬, #ë°°ë‹¹ìˆ˜ìµ)
           - ì§€ì£¼íšŒì‚¬ì¸ ê²½ìš°: #ì§€ì£¼íšŒì‚¬, #ë°°ë‹¹ìˆ˜ìµ, #ì„ëŒ€ìˆ˜ìµ, #ë¡œì—´í‹° ë“±
        8. revenue_by_segment: ì‚¬ì—…ë¶€ë¬¸ë³„ ë§¤ì¶œ ë¹„ì¤‘ (%) - ğŸ”¥ í•µì‹¬ ì¶”ì¶œ í•­ëª©!
           - "ì‚¬ì—…ì˜ ê°œìš”" ë‚´ ë§¤ì¶œì•¡ í…Œì´ë¸”ì—ì„œ ìš°ì„  ì¶”ì¶œ
           - "ë§¤ì¶œ ë° ìˆ˜ì£¼ìƒí™©" ë˜ëŠ” "ì£¼ìš” ì œí’ˆ ë§¤ì¶œ" í‘œì—ì„œë„ ì¶”ì¶œ
           - ë¶€ë¬¸ëª…ì€ ë³´ê³ ì„œì— ëª…ì‹œëœ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì˜ˆ: "ê±´ì„¤ë¶€ë¬¸", "ìƒì‚¬ë¶€ë¬¸", "ë°”ì´ì˜¤ë¶€ë¬¸")
           - ë¹„ì¤‘(%)ì´ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ ë§¤ì¶œì•¡ ê¸°ì¤€ìœ¼ë¡œ ë¹„ì¤‘ ê³„ì‚°
           - í¬ë§·: {"ë¶€ë¬¸ëª…": ë¹„ì¤‘(ìˆ«ì), ...}
           - ì§€ì£¼íšŒì‚¬ì¸ ê²½ìš°: {"ë°°ë‹¹ê¸ˆìˆ˜ìµ": ë¹„ì¤‘, "ì„ëŒ€ìˆ˜ìµ": ë¹„ì¤‘, "ë¡œì—´í‹°ìˆ˜ìµ": ë¹„ì¤‘, ...}
           
           [ë³µí•© í‘œ(ê³„ì¸µ êµ¬ì¡°) ì²˜ë¦¬]
           - í‘œê°€ "ì‚¬ì—…ë¶€ë¬¸ > í’ˆëª© > êµ¬ì²´ì  ìš©ë„"ì²˜ëŸ¼ ê³„ì¸µ êµ¬ì¡°ë¡œ ë˜ì–´ ìˆì„ ê²½ìš°:
             * ê°€ì¥ ìƒìœ„ ê°œë…ì¸ "ì‚¬ì—…ë¶€ë¬¸"ì„ ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¶œì„ í•©ì‚°í•˜ì„¸ìš”
             * í•˜ìœ„ í’ˆëª©(ì˜ˆ: ì—´ì—°, ëƒ‰ì—°)ì€ ë¬´ì‹œí•˜ê³  ìƒìœ„ ë¶€ë¬¸(ì˜ˆ: ì² ê°•ë¶€ë¬¸)ì˜ í•©ê³„ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
           - "ë‚´ë¶€ê±°ë˜ì œê±°", "ì—°ê²°ì¡°ì •", "ë‹¨ìˆœí•©ê³„" í–‰ì€ ì‚¬ì—…ë¶€ë¬¸ì´ ì•„ë‹ˆë¯€ë¡œ ì¶”ì¶œì—ì„œ ì œì™¸í•˜ì„¸ìš”
           
           - ë¶€ë¬¸ ë‚´ "ë‚´ë¶€ê±°ë˜ ì œê±°" í•­ëª©ì€ ì œì™¸
           - ğŸ†• P0-3: í‘œê°€ ì•„ë‹ˆë¼ ë¬¸ì¥ìœ¼ë¡œ "OOì‚¬ì—… 67%, OOë¶€ë¬¸ 14%"ì²˜ëŸ¼ ì í˜€ ìˆìœ¼ë©´ ê·¸ê²ƒë„ revenue_by_segmentì— ë„£ì–´ë¼ (ì¶”ì¸¡ ê¸ˆì§€, ëª…ì‹œëœ í¼ì„¼íŠ¸ë§Œ)
           - ğŸ†• P0-2: ë³´ê³ ì„œì— "í•˜ë‚˜ì˜ ë³´ê³  ë¶€ë¬¸" ë˜ëŠ” "ë‹¨ì¼ ë³´ê³ ë¶€ë¬¸"ì´ë¼ê³  ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ {"ë‹¨ì¼ë¶€ë¬¸": 100.0} ë°˜í™˜
           - ğŸš¨ ë°˜ë“œì‹œ ì¶”ì¶œí•˜ë ¤ê³  ì‹œë„í•  ê²ƒ! ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ {} ë°˜í™˜
        
        [ë°˜í™˜ í˜•ì‹]
        ì˜¤ì§ JSON í˜•ì‹ë§Œ ë°˜í™˜í•  ê²ƒ. (Markdown code block ì—†ì´)
        JSON í˜•ì‹:
        {
            "business_summary": "...",
            "major_products": [...],
            "major_clients": "...",
            "supply_chain": [{"item": "ì›ì¬ë£Œëª…", "supplier": "ê³µê¸‰ì‚¬ëª…"}],
            "capax_investment": "...",
            "cost_structure": "...",
            "keywords": [...],
            "revenue_by_segment": {"ë¶€ë¬¸ëª…": ë¹„ì¤‘, ...}
        }
        """
    
    def _get_financial_prompt(self) -> str:
        """ê¸ˆìœµì‚¬ ì „ìš© í”„ë¡¬í”„íŠ¸"""
        return """
        ë„ˆëŠ” 10ë…„ ì°¨ í€ë“œë§¤ë‹ˆì €ì•¼. ì œê³µëœ [ê¸ˆìœµì‚¬ ì‚¬ì—…ë³´ê³ ì„œ] ë‚´ìš©ì„ ë¶„ì„í•´ì„œ 
        íˆ¬ì íŒë‹¨ì— í•„ìš”í•œ í•µì‹¬ ì •ë³´ë¥¼ ì•„ë˜ JSON í¬ë§·ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´.
        
        [ğŸ”¥ ìµœìš°ì„  í™•ì¸: "ì‚¬ì—…ì˜ ê°œìš”" ë° "ì˜ì—…ì˜ í˜„í™©" ì„¹ì…˜]
        - "â…¡. ì‚¬ì—…ì˜ ë‚´ìš© > 1. ì‚¬ì—…ì˜ ê°œìš”"ì—ì„œ íšŒì‚¬ê°€ ì–´ë–¤ ê¸ˆìœµì‚¬ì—…ì„ í•˜ëŠ”ì§€ í™•ì¸
        - "2. ì˜ì—…ì˜ í˜„í™©" ì„¹ì…˜ì—ì„œ "ì˜ì—…ì˜ ì¢…ë¥˜", "ì˜ì—…ì˜ ê°œí™©", "ë¶€ë¬¸ì •ë³´", "ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´" í…Œì´ë¸” í™•ì¸
        - ê¸ˆìœµì§€ì£¼íšŒì‚¬ì¸ ê²½ìš°: "ì˜ì—…ì˜ ì¢…ë¥˜" í…Œì´ë¸”ì—ì„œ ì‚¬ì—…ë¶€ë¬¸ë³„ êµ¬ë¶„ ì¶”ì¶œ (ì€í–‰ë¶€ë¬¸, ê¸ˆìœµíˆ¬ìë¶€ë¬¸, ë³´í—˜ë¶€ë¬¸ ë“±)
        - ì¼ë°˜ ê¸ˆìœµì‚¬(ì€í–‰/ë³´í—˜/ì¦ê¶Œ)ì¸ ê²½ìš°: "ì˜ì—…ì˜ í˜„í™©" ì„¹ì…˜ì˜ ì˜ì—…ì¢…ë¥˜ë³„ ìˆ˜ìµ êµ¬ì¡° ì¶”ì¶œ
        
        [ì¤‘ìš” ì§€ì¹¨]
        - ì œê³µëœ í…ìŠ¤íŠ¸ì—ì„œë§Œ ì •ë³´ë¥¼ ì¶”ì¶œí•  ê²ƒ (ì¶”ì¸¡í•˜ì§€ ë§ê²ƒ)
        - ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ì •ë³´ëŠ” "ì •ë³´ì—†ìŒ" ë˜ëŠ” nullë¡œ í‘œì‹œ
        - êµ¬ì²´ì ì¸ ìˆ«ì, ë¹„ìœ¨, ì‚¬ì‹¤ë§Œ í¬í•¨í•  ê²ƒ
        - ê¸ˆìœµì‚¬ëŠ” supply_chainì´ ì—†ìœ¼ë¯€ë¡œ ë¹ˆ ë°°ì—´ []ë¡œ ë°˜í™˜
        
        [ì¶”ì¶œ í•­ëª© - ê¸ˆìœµì‚¬ ì „ìš©]
        1. business_summary: "ì‚¬ì—…ì˜ ê°œìš”"ì—ì„œ ë™ì‚¬ê°€ ì˜ìœ„í•˜ëŠ” ê¸ˆìœµì‚¬ì—… ë‚´ìš©ì„ 3ì¤„ ìš”ì•½.
           - ê¸ˆìœµì§€ì£¼íšŒì‚¬ì¸ ê²½ìš°: "ê¸ˆìœµì§€ì£¼íšŒì‚¬ë¡œì„œ ìíšŒì‚¬(ì€í–‰, ì¦ê¶Œ, ì¹´ë“œ, ë³´í—˜ ë“±) ì§€ë¶„ ë³´ìœ  ë° ë°°ë‹¹ê¸ˆ ìˆ˜ìµì„ ì˜ìœ„" í˜•íƒœë¡œ ëª…ì‹œ
        
        2. major_products: ì£¼ìš” ê¸ˆìœµìƒí’ˆ ë° ì„œë¹„ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ê¸°ì—…ëŒ€ì¶œ, ê°€ê³„ëŒ€ì¶œ, ì¹´ë“œ, ë³´í—˜ìƒí’ˆ, ìì‚°ìš´ìš© ë“±)
        
        3. major_clients: ì£¼ìš” ê±°ë˜ ìƒëŒ€ë°© (ì˜ˆ: "ê¸°ì—…ê³ ê°, ê°œì¸ê³ ê°, ê¸ˆìœµê¸°ê´€" ë˜ëŠ” "ì •ë³´ì—†ìŒ")
        
        4. supply_chain: ê¸ˆìœµì‚¬ëŠ” ê³µê¸‰ë§ì´ ì—†ìœ¼ë¯€ë¡œ ë¹ˆ ë°°ì—´ [] ë°˜í™˜
        
        5. financial_value_chain: ê¸ˆìœµì‚¬ ë°¸ë¥˜ì²´ì¸ êµ¬ì¡°í™” (í•µì‹¬!)
           - funding_structure: ìê¸ˆ ì¡°ë‹¬ êµ¬ì¡°
             * sources: ìê¸ˆ ì¡°ë‹¬ì› ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["ì˜ˆê¸ˆ", "ì±„ê¶Œë°œí–‰", "í•´ì™¸ì°¨ì…", "CP", "RP"], ë³´ê³ ì„œì— ëª…ì‹œëœ ê²ƒë§Œ)
             * cost_of_funding: ì´ìë¹„ìš©ë¥  (ë³´ê³ ì„œì— ëª…ì‹œëœ ê²½ìš°ë§Œ ìˆ«ì, ì—†ìœ¼ë©´ null)
             * rate_sensitivity: ê¸ˆë¦¬ ë¯¼ê°ë„ ("HIGH", "MEDIUM", "LOW" ë˜ëŠ” "ì •ë³´ì—†ìŒ")
             * duration_structure: ALM êµ¬ì¡° (ì˜ˆ: "ë³€ë™ê¸ˆë¦¬ ìœ„ì£¼", "ê³ ì •ê¸ˆë¦¬ ìœ„ì£¼", ì—†ìœ¼ë©´ null)
           - asset_structure: ìì‚° êµ¬ì„±
             * loans: ëŒ€ì¶œ êµ¬ì„± (ë³´ê³ ì„œì— ëª…ì‹œëœ ê²½ìš°ë§Œ)
               - corporate: ê¸°ì—…ëŒ€ì¶œ ë¹„ì¤‘ (%)
               - retail: ê°€ê³„ëŒ€ì¶œ ë¹„ì¤‘ (%)
               - mortgage: ì£¼íƒë‹´ë³´ëŒ€ì¶œ ë¹„ì¤‘ (%)
             * securities: ìœ ê°€ì¦ê¶Œ êµ¬ì„± (ë³´ê³ ì„œì— ëª…ì‹œëœ ê²½ìš°ë§Œ)
               - bonds: ì±„ê¶Œ ë¹„ì¤‘ (%)
               - stocks: ì£¼ì‹ ë¹„ì¤‘ (%)
               - alternatives: ëŒ€ì²´íˆ¬ì ë¹„ì¤‘ (%)
             * industry_exposure: ì‚°ì—…êµ° ë…¸ì¶œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["ê±´ì„¤", "PF", "ì¡°ì„ ", "ì¤‘ì†Œê¸°ì—…"], ë³´ê³ ì„œì— ëª…ì‹œëœ ê²ƒë§Œ)
           - revenue_structure: ìˆ˜ìµ êµ¬ì¡° (ë³´ê³ ì„œì— ëª…ì‹œëœ ê²½ìš°ë§Œ)
             * interest_income_ratio: ì´ììˆ˜ìµ ë¹„ì¤‘ (%)
             * fee_income_ratio: ìˆ˜ìˆ˜ë£Œìˆ˜ìµ ë¹„ì¤‘ (%)
             * trading_income_ratio: íŠ¸ë ˆì´ë”©ìˆ˜ìµ ë¹„ì¤‘ (%)
           - capital_adequacy: ìë³¸ì ì •ì„± ì§€í‘œ (BIS ë¹„ìœ¨ - í•µì‹¬!)
             * bis_total_ratio: BIS ì´ìë³¸ë¹„ìœ¨ (%) - [ì´ìë³¸/ìœ„í—˜ê°€ì¤‘ìì‚°]x100
             * bis_tier1_ratio: BIS ê¸°ë³¸ìë³¸ë¹„ìœ¨ (%) - [ê¸°ë³¸ìë³¸/ìœ„í—˜ê°€ì¤‘ìì‚°]x100
             * bis_cet1_ratio: BIS ë³´í†µì£¼ìë³¸ë¹„ìœ¨ (%) - [ë³´í†µì£¼ìë³¸/ìœ„í—˜ê°€ì¤‘ìì‚°]x100
             * total_capital: ì´ìë³¸ (ì–µì›)
             * risk_weighted_assets: ìœ„í—˜ê°€ì¤‘ìì‚° (ì–µì›)
             * report_year: ë³´ê³ ì„œ ê¸°ì¤€ì—°ë„ (ì˜ˆ: "2024")
           - risk_exposure: ë¦¬ìŠ¤í¬ ë…¸ì¶œ (ë³´ê³ ì„œì— ëª…ì‹œëœ ê²½ìš°ë§Œ)
             * credit_risk: ì‹ ìš©ë¦¬ìŠ¤í¬
               - npl_ratio: ë¶€ì‹¤ì±„ê¶Œ ë¹„ìœ¨ (%)
               - provision_ratio: ì¶©ë‹¹ê¸ˆ ë¹„ìœ¨ (%)
               - stage3_ratio: Stage3 ë¹„ìœ¨ (%)
             * market_risk: ì‹œì¥ë¦¬ìŠ¤í¬
               - rate_risk: ê¸ˆë¦¬ ë¦¬ìŠ¤í¬ ("HIGH", "MEDIUM", "LOW" ë˜ëŠ” "ì •ë³´ì—†ìŒ")
               - fx_risk: í™˜ìœ¨ ë¦¬ìŠ¤í¬ ("HIGH", "MEDIUM", "LOW" ë˜ëŠ” "ì •ë³´ì—†ìŒ")
               - equity_risk: ì£¼ê°€ ë¦¬ìŠ¤í¬ ("HIGH", "MEDIUM", "LOW" ë˜ëŠ” "ì •ë³´ì—†ìŒ")
             * liquidity_risk: ìœ ë™ì„±ë¦¬ìŠ¤í¬
               - lcr: ìœ ë™ì„±ì»¤ë²„ë¦¬ì§€ë¹„ìœ¨ (ë³´ê³ ì„œì— ëª…ì‹œëœ ê²½ìš°ë§Œ)
               - loan_to_deposit_ratio: ì˜ˆëŒ€ìœ¨ (ë³´ê³ ì„œì— ëª…ì‹œëœ ê²½ìš°ë§Œ)
               - nsfr: ìˆœì•ˆì •ìê¸ˆë¹„ìœ¨ (ë³´ê³ ì„œì— ëª…ì‹œëœ ê²½ìš°ë§Œ)
             * sector_exposure: íŠ¹ì • ì„¹í„° ë…¸ì¶œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["ë¶€ë™ì‚°", "PF", "ê±´ì„¤"], ë³´ê³ ì„œì— ëª…ì‹œëœ ê²ƒë§Œ)
           - major_counterparties: ì£¼ìš” ê±°ë˜ ìƒëŒ€ë°© (["ê¸°ì—…ê³ ê°", "ê°œì¸ê³ ê°", "ê¸ˆìœµê¸°ê´€"] ë“±)
        
        6. capax_investment: ì„¤ë¹„íˆ¬ì(CAPEX)ë‚˜ ì‹ ê·œ ì‹œì„¤ íˆ¬ì ê³„íš ì–¸ê¸‰ ìš”ì•½. ë³´ê³ ì„œì— ëª…ì‹œëœ ê²ƒë§Œ. ì—†ìœ¼ë©´ "ì •ë³´ì—†ìŒ".
        
        7. cost_structure: ë¹„ìš© êµ¬ì¡°ì—ì„œ ê°€ì¥ í° ë¹„ì¤‘ì„ ì°¨ì§€í•˜ëŠ” ê²ƒ (ì˜ˆ: ì´ìë¹„ìš©, ì¸ê±´ë¹„, ìš´ì˜ë¹„). ë³´ê³ ì„œì— ëª…ì‹œëœ ê²ƒë§Œ.
        
        8. keywords: ê¸°ì—…ì„ ì„¤ëª…í•˜ëŠ” í•µì‹¬ í•´ì‹œíƒœê·¸ 5ê°œ. (ë³´ê³ ì„œ ë‚´ìš© ê¸°ë°˜)
        
        9. revenue_by_segment: ì‚¬ì—…ë¶€ë¬¸ë³„ ë§¤ì¶œ/ìˆ˜ìµ ë¹„ì¤‘ (%) - ğŸ”¥ í•µì‹¬ ì¶”ì¶œ í•­ëª©!
           [ìš©ì–´ í™•ì¥] ê¸ˆìœµì‚¬ëŠ” "ë§¤ì¶œì•¡"ì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ì“°ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ìŒ ìš©ì–´ë“¤ì„ ëª¨ë‘ "ë§¤ì¶œ ë°ì´í„°"ë¡œ ê°„ì£¼í•˜ê³  ì¶”ì¶œí•˜ì„¸ìš”:
           - "ë§¤ì¶œì•¡", "ë§¤ì¶œë¹„ì¤‘" ì™¸ì— "ì˜ì—…ìˆ˜ìµ", "ìˆœì˜ì—…ì†Œë“", "ì´ììˆ˜ìµ", "ë³´í—˜ìˆ˜ìµ", "ìˆ˜ì…ë³´í—˜ë£Œ", "ë‹¹ê¸°ìˆœì´ìµ", "ë‹¹ê¸°ì†ìµ", "ì˜ì—…ì´ìµ", "ë¶€ë¬¸ë³„ ì†ìµ", "ë¶€ë¬¸ë³„ ê¸°ì—¬ë„"
           
           [ê¸ˆìœµì§€ì£¼íšŒì‚¬ ì¶”ì¶œ ë°©ë²•]
           - "2. ì˜ì—…ì˜ í˜„í™© > ë‚˜. ì˜ì—…ì˜ ì¢…ë¥˜" í…Œì´ë¸”ì—ì„œ ì‚¬ì—…ë¶€ë¬¸ë³„ êµ¬ë¶„ ì¶”ì¶œ
           - ì˜ˆ: {"ì€í–‰ë¶€ë¬¸": ë¹„ì¤‘, "ê¸ˆìœµíˆ¬ìë¶€ë¬¸": ë¹„ì¤‘, "ë³´í—˜ë¶€ë¬¸": ë¹„ì¤‘, "ì—¬ì‹ ì „ë¬¸ë¶€ë¬¸": ë¹„ì¤‘, "ì €ì¶•ì€í–‰ë¶€ë¬¸": ë¹„ì¤‘, "ê¸°íƒ€ë¶€ë¬¸": ë¹„ì¤‘}
           - ê° ë¶€ë¬¸ì˜ ê³„ì—´ì‚¬ì™€ ì£¼ìš” ì‚¬ì—… ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë¶€ë¬¸ëª… ì •í™•íˆ ì¶”ì¶œ
           - "ë‹¹ê¸°ì†ìµ ë¹„ì¤‘(%)", "ë¶€ë¬¸ë³„ ê¸°ì—¬ë„(%)" ê°™ì€ í‘œê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
           
           [ì¼ë°˜ ê¸ˆìœµì‚¬(ì€í–‰/ë³´í—˜/ì¦ê¶Œ) ì¶”ì¶œ ë°©ë²•]
           - "2. ì˜ì—…ì˜ í˜„í™©" ì„¹ì…˜ì˜ ì˜ì—…ì¢…ë¥˜ë³„ ìˆ˜ìµ êµ¬ì¡° ì¶”ì¶œ
           - ì€í–‰: {"ì€í–‰ê³„ì •": ë¹„ì¤‘, "ì‹ íƒê³„ì •": ë¹„ì¤‘, ...}
           - ë³´í—˜: {"ìƒëª…ë³´í—˜": ë¹„ì¤‘, "ì†í•´ë³´í—˜": ë¹„ì¤‘, "ì¥ê¸°ë³´í—˜": ë¹„ì¤‘, "ì¼ë°˜ë³´í—˜": ë¹„ì¤‘, "ìë™ì°¨ë³´í—˜": ë¹„ì¤‘, ...}
             * ë³´í—˜ì‚¬ëŠ” "ìƒëª…/ì†í•´ë³´í—˜" êµ¬ë¶„ ì™¸ì— "ì¼ë°˜/ì¥ê¸°/ìë™ì°¨" ë³´í—˜ êµ¬ë¶„ì´ë‚˜ "ì‚¬ë§/ìƒì¡´" ê¸‰ë¶€ êµ¬ë¶„ë„ ì‚¬ì—…ë¶€ë¬¸ìœ¼ë¡œ ì¸ì •
           - ì¦ê¶Œ: {"íˆ¬ìë§¤ë§¤ì—…": ë¹„ì¤‘, "íˆ¬ìì¤‘ê°œì—…": ë¹„ì¤‘, "ìì‚°ìš´ìš©": ë¹„ì¤‘, ...}
           
           [ë¹„ì¤‘ ê³„ì‚° ëª…ë ¹] âš ï¸ ë§¤ìš° ì¤‘ìš”!
           - í‘œì— ë¹„ì¤‘(%)ì´ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
           - ë¹„ì¤‘(%)ì´ ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš°:
             1. ê° ë¶€ë¬¸ì˜ ê¸ˆì•¡(ì˜ì—…ìˆ˜ìµ/ë‹¹ê¸°ì†ìµ/ë³´í—˜ìˆ˜ìµ ë“±)ì„ í•©ì‚°í•˜ì—¬ ì´ì•¡ì„ êµ¬í•˜ì„¸ìš”
             2. ê° ë¶€ë¬¸ì˜ ê¸ˆì•¡ì„ ì´ì•¡ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë¹„ì¤‘(%)ì„ ê³„ì‚°í•˜ì„¸ìš”
             3. ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ê³„ì‚°í•˜ì—¬ revenue_by_segmentì— í¬í•¨í•˜ì„¸ìš”
             4. ì˜ˆ: ì€í–‰ë¶€ë¬¸ 100ì–µ, ì¦ê¶Œë¶€ë¬¸ 50ì–µ, ì´ì•¡ 150ì–µ â†’ {"ì€í–‰ë¶€ë¬¸": 66.67, "ì¦ê¶Œë¶€ë¬¸": 33.33}
           
           [ë³µí•© í‘œ(ê³„ì¸µ êµ¬ì¡°) ì²˜ë¦¬]
           - í‘œê°€ "ì‚¬ì—…ë¶€ë¬¸ > í’ˆëª© > êµ¬ì²´ì  ìš©ë„"ì²˜ëŸ¼ ê³„ì¸µ êµ¬ì¡°ë¡œ ë˜ì–´ ìˆì„ ê²½ìš°:
             * ê°€ì¥ ìƒìœ„ ê°œë…ì¸ "ì‚¬ì—…ë¶€ë¬¸"ì„ ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¶œì„ í•©ì‚°í•˜ì„¸ìš”
             * í•˜ìœ„ í’ˆëª©(ì˜ˆ: ì—´ì—°, ëƒ‰ì—°)ì€ ë¬´ì‹œí•˜ê³  ìƒìœ„ ë¶€ë¬¸(ì˜ˆ: ì² ê°•ë¶€ë¬¸)ì˜ í•©ê³„ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
           - "ë‚´ë¶€ê±°ë˜ì œê±°", "ì—°ê²°ì¡°ì •", "ë‹¨ìˆœí•©ê³„" í–‰ì€ ì‚¬ì—…ë¶€ë¬¸ì´ ì•„ë‹ˆë¯€ë¡œ ì¶”ì¶œì—ì„œ ì œì™¸í•˜ì„¸ìš”
           
           [ë¶€ë¬¸ëª… ê·œì¹™]
           - ë¶€ë¬¸ëª…ì€ ë³´ê³ ì„œì— ëª…ì‹œëœ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì˜ˆ: "ì€í–‰ë¶€ë¬¸", "ê¸ˆìœµíˆ¬ìë¶€ë¬¸", "ìƒëª…ë³´í—˜", "ì†í•´ë³´í—˜")
           - í¬ë§·: {"ë¶€ë¬¸ëª…": ë¹„ì¤‘(ìˆ«ì), ...}
           - ë¶€ë¬¸ ë‚´ "ë‚´ë¶€ê±°ë˜ ì œê±°" í•­ëª©ì€ ì œì™¸
           - ğŸ†• P0-3: í‘œê°€ ì•„ë‹ˆë¼ ë¬¸ì¥ìœ¼ë¡œ "OOì‚¬ì—… 67%, OOë¶€ë¬¸ 14%"ì²˜ëŸ¼ ì í˜€ ìˆìœ¼ë©´ ê·¸ê²ƒë„ revenue_by_segmentì— ë„£ì–´ë¼ (ì¶”ì¸¡ ê¸ˆì§€, ëª…ì‹œëœ í¼ì„¼íŠ¸ë§Œ)
           - ğŸ†• P0-2: ë³´ê³ ì„œì— "í•˜ë‚˜ì˜ ë³´ê³  ë¶€ë¬¸" ë˜ëŠ” "ë‹¨ì¼ ë³´ê³ ë¶€ë¬¸"ì´ë¼ê³  ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ {"ë‹¨ì¼ë¶€ë¬¸": 100.0} ë°˜í™˜
           - ğŸš¨ ë°˜ë“œì‹œ ì¶”ì¶œí•˜ë ¤ê³  ì‹œë„í•  ê²ƒ! ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ {} ë°˜í™˜
        
        [ë°˜í™˜ í˜•ì‹]
        ì˜¤ì§ JSON í˜•ì‹ë§Œ ë°˜í™˜í•  ê²ƒ. (Markdown code block ì—†ì´)
        JSON í˜•ì‹:
        {
            "business_summary": "...",
            "major_products": [...],
            "major_clients": "...",
            "supply_chain": [],
            "financial_value_chain": {
                "funding_structure": {
                    "sources": [...],
                    "cost_of_funding": null,
                    "rate_sensitivity": "...",
                    "duration_structure": null
                },
                "asset_structure": {
                    "loans": {"corporate": null, "retail": null, "mortgage": null},
                    "securities": {"bonds": null, "stocks": null, "alternatives": null},
                    "industry_exposure": [...]
                },
                "revenue_structure": {
                    "interest_income_ratio": null,
                    "fee_income_ratio": null,
                    "trading_income_ratio": null
                },
                "capital_adequacy": {
                    "bis_total_ratio": null,
                    "bis_tier1_ratio": null,
                    "bis_cet1_ratio": null,
                    "total_capital": null,
                    "risk_weighted_assets": null,
                    "report_year": "2024"
                },
                "risk_exposure": {
                    "credit_risk": {"npl_ratio": null, "provision_ratio": null, "stage3_ratio": null},
                    "market_risk": {"rate_risk": "...", "fx_risk": "...", "equity_risk": "..."},
                    "liquidity_risk": {"lcr": null, "loan_to_deposit_ratio": null, "nsfr": null},
                    "sector_exposure": [...]
                },
                "major_counterparties": [...]
            },
            "capax_investment": "...",
            "cost_structure": "...",
            "keywords": [...],
            "revenue_by_segment": {"ë¶€ë¬¸ëª…": ë¹„ì¤‘, ...}  // ğŸ†• ì¶”ê°€
        }
        
        ì£¼ì˜: 
        - ë³´ê³ ì„œì— ëª…ì‹œë˜ì§€ ì•Šì€ ì •ë³´ëŠ” null ë˜ëŠ” "ì •ë³´ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œ
        - ìˆ«ìëŠ” ë³´ê³ ì„œì— ì •í™•íˆ ëª…ì‹œëœ ê²½ìš°ë§Œ í¬í•¨
        - ì¶”ì¸¡í•˜ì§€ ë§ ê²ƒ
        """
    
    def validate_json(self, json_str: str) -> Optional[Dict[str, Any]]:
        """
        JSON ë¬¸ìì—´ ê²€ì¦ ë° ìˆ˜ë¦¬
        
        Args:
            json_str: ê²€ì¦í•  JSON ë¬¸ìì—´
        
        Returns:
            íŒŒì‹±ëœ Dict ë˜ëŠ” None
        """
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            try:
                repaired = json_repair.repair_json(json_str)
                return json.loads(repaired)
            except Exception as e:
                logger.error(f"JSON ê²€ì¦ ë° ìˆ˜ë¦¬ ì‹¤íŒ¨: {e}")
                return None

