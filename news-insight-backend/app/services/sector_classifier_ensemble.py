"""
4ë‹¨ê³„ ë©€í‹° ëª¨ë¸ ì•™ìƒë¸” ì„¹í„° ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸

Step 1: Rule-based (ê°€ì¤‘ì¹˜ 40%) - Confidence HIGHë©´ ì¦‰ì‹œ ë°˜í™˜
Step 2: ì„ë² ë”© ëª¨ë¸ (ê°€ì¤‘ì¹˜ 30%) - Top-5 í›„ë³´ ìƒì„±
Step 3: BGE-M3 (ê°€ì¤‘ì¹˜ 20%) - Top-5 â†’ Top-2 Re-ranking
Step 4: gpt-5-mini (ê°€ì¤‘ì¹˜ 10%) - Top-2 â†’ ìµœì¢… 1~3ê°œ ê²€ì¦

ì˜ˆìƒ ì •í™•ë„: 90-95%
"""
import os
import logging
from typing import Optional, Dict, Any, List, Tuple
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)

# ê¸°ì¡´ Rule-based ë¶„ë¥˜ê¸°
from app.services.sector_classifier import (
    classify_sector_rule_based,
    SECTOR_KEYWORDS
)

# Phase 1: ì„ë² ë”© ëª¨ë¸ ê¸°ë°˜ í›„ë³´ ìƒì„±ê¸°
EMBEDDING_AVAILABLE = False
try:
    from app.services.sector_classifier_embedding import generate_sector_candidates, SENTENCE_TRANSFORMERS_AVAILABLE
    if SENTENCE_TRANSFORMERS_AVAILABLE:
        EMBEDDING_AVAILABLE = True
        logger.info("ì„ë² ë”© ëª¨ë¸ ëª¨ë“ˆ import ì„±ê³µ (lazy loading - ì‹¤ì œ ì‚¬ìš© ì‹œì ì— ë¡œë“œ)")
    else:
        EMBEDDING_AVAILABLE = False
        logger.warning("sentence-transformers not installed. Embedding model not available.")
except ImportError as e:
    EMBEDDING_AVAILABLE = False
    logger.warning(f"ì„ë² ë”© ëª¨ë¸ import ì‹¤íŒ¨: {e}. Will skip candidate generation.")

# Phase 2: BGE-M3 Re-ranking
try:
    from app.services.sector_classifier_reranker import rerank_sector_candidates
    BGE_AVAILABLE = True
except ImportError:
    BGE_AVAILABLE = False
    logger.warning("BGE-M3 not available. Will skip reranking.")

# Phase 3: GPT ìµœì¢… ê²€ì¦
try:
    from app.services.sector_classifier_validator import validate_sectors_with_gpt
    GPT_AVAILABLE = True
except ImportError:
    GPT_AVAILABLE = False
    logger.warning("GPT validator not available. Will skip final validation.")

from app.models.company_detail import CompanyDetail
from app.models.sector_reference import LEGACY_SECTOR_MAPPING
from app.models.edge import Edge
from app.models.investor_sector import InvestorSector
from app.services.llm_handler import LLMHandler
from app.utils.text_chunking import truncate_to_sentences
from app.utils.company_complexity_detector import is_complex_company

# ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜ (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)
try:
    from app.services.value_chain_classifier import classify_value_chain_hybrid
    VALUE_CHAIN_CLASSIFIER_AVAILABLE = True
except ImportError:
    VALUE_CHAIN_CLASSIFIER_AVAILABLE = False
    logger.warning("Value chain classifier not available. Will use rule-based only.")

# ì˜ë¯¸ ê¸°ë°˜ í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ (Phase 1)
try:
    from app.utils.semantic_sentence_extractor import extract_key_sentences_for_sector
    SEMANTIC_EXTRACTION_AVAILABLE = True
except ImportError:
    SEMANTIC_EXTRACTION_AVAILABLE = False
    logger.warning("Semantic sentence extraction not available. Will use fallback.")


# ì „ëµ B: Anchor Boostingì„ ìœ„í•œ White-list Anchor ì •ì˜
# ê³ ê°ì‚¬(major_clients)ì— ì´ ê¸°ì—…ë“¤ì´ í¬í•¨ë˜ë©´ í•´ë‹¹ ì„¹í„°ì— ê°€ì‚°ì  ë¶€ì—¬
# ë‹¨, í›„ë³´êµ°(Candidates)ì— í•´ë‹¹ ì„¹í„°ê°€ ì´ë¯¸ ì¡´ì¬í•  ë•Œë§Œ ë¶€ì—¬ (êµì§‘í•© ì „ëµ)
STRICT_ANCHORS = {
    # [ë°˜ë„ì²´] ì‚¼ì„±ì „ì, í•˜ì´ë‹‰ìŠ¤ ë‚©í’ˆ = 99% ë°˜ë„ì²´ ì†Œë¶€ì¥
    'ì‚¼ì„±ì „ì': 'SEC_SEMI', 'SKí•˜ì´ë‹‰ìŠ¤': 'SEC_SEMI', 
    
    # [2ì°¨ì „ì§€] ì…€/ì†Œì¬ ì—…ì²´ ë‚©í’ˆ = ë°°í„°ë¦¬ ë°¸ë¥˜ì²´ì¸
    'LGì—ë„ˆì§€ì†”ë£¨ì…˜': 'SEC_BATTERY', 'ì‚¼ì„±SDI': 'SEC_BATTERY', 'SKì˜¨': 'SEC_BATTERY', 
    'ì—ì½”í”„ë¡œë¹„ì— ': 'SEC_BATTERY', 'í¬ìŠ¤ì½”í“¨ì²˜ì— ': 'SEC_BATTERY',
    
    # [ìë™ì°¨] í˜„ëŒ€ê¸°ì•„ì°¨ ë‚©í’ˆ = ìë™ì°¨ ë¶€í’ˆ
    'í˜„ëŒ€ìë™ì°¨': 'SEC_AUTO', 'ê¸°ì•„': 'SEC_AUTO', 'í˜„ëŒ€ëª¨ë¹„ìŠ¤': 'SEC_AUTO',
    
    # [ë°”ì´ì˜¤] ì‚¼ë°”/ì…€íŠ¸ë¦¬ì˜¨ ë‚©í’ˆ = ë°”ì´ì˜¤ ì†Œë¶€ì¥/ì›ë£Œ
    'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤': 'SEC_BIO', 'ì…€íŠ¸ë¦¬ì˜¨': 'SEC_BIO',
    
    # [ì¡°ì„ ] ì¡°ì„  3ì‚¬ ë‚©í’ˆ = ì¡°ì„  ê¸°ìì¬
    'HDí˜„ëŒ€ì¤‘ê³µì—…': 'SEC_SHIP', 'í•œí™”ì˜¤ì…˜': 'SEC_SHIP', 'ì‚¼ì„±ì¤‘ê³µì—…': 'SEC_SHIP',
    
    # [ë°©ì‚°] ì²´ê³„ì¢…í•©ì—…ì²´ ë‚©í’ˆ = ë°©ì‚° ë¶€í’ˆ
    'í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤': 'SEC_DEFENSE', 'LIGë„¥ìŠ¤ì›': 'SEC_DEFENSE', 'í•œêµ­í•­ê³µìš°ì£¼': 'SEC_DEFENSE'
}

# ë²”ìš© ì„¹í„° (Block List) - Boosting ì™„ì „ ê¸ˆì§€
INDUSTRY_AGNOSTIC_SECTORS = {
    'SEC_IT', 'SEC_IT_SERVICE', 'SEC_SI', 'SEC_SW', 'SEC_PLATFORM',
    'SEC_CONST', 'SEC_ENG', 'SEC_MEDIA', 'SEC_AD',
    'SEC_LOGISTICS', 'SEC_DISTRIBUTION', 'SEC_FINANCE', 'SEC_HOLDING'
}

# Boosting Budget (ì´ëŸ‰ ìƒí•œì œ)
MAX_TOTAL_BOOST = 0.05  # ìµœëŒ€ +0.05
TOP2_GAP_THRESHOLD = 0.03  # Top-2 ì ìˆ˜ ì°¨ì´ ì„ê³„ê°’

# Base Boosting ê°’
BASE_ANCHOR_BOOST = 0.03
BASE_KG_BOOST = 0.02

# Edge íƒ€ì…ë³„ ê°€ì¤‘ì¹˜ (ì•ˆì „í•œ Edgeë§Œ ì‚¬ìš©)
EDGE_WEIGHTS = {
    'SUPPLIES_TO': 1.0,  # ê³µê¸‰ ê´€ê³„ (ì•ˆì „)
    'CORE_DEPENDENCY': 0.8,  # í•µì‹¬ ì˜ì¡´ (ì•ˆì „)
    'CUSTOMER_OF': 0.0,  # ê³ ê° ê´€ê³„ (ìœ„í—˜)
    'PROJECT_WITH': 0.0,  # í”„ë¡œì íŠ¸ ê´€ê³„ (ìœ„í—˜)
    'RELATED_TO': 0.0,  # ì¼ë°˜ ê´€ë ¨ (ìœ„í—˜)
    'BUSINESS_RELATION': 0.0,  # ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ê³„ (ìœ„í—˜)
}


# Role ì •ì˜ (ìµœì¢… ì„¤ê³„ì•ˆ)
ROLE_DEFINITIONS = {
    'SI_IT_SERVICE': {
        'positive': ['si', 'ì‹œìŠ¤í…œí†µí•©', 'sm', 'ìœ ì§€ë³´ìˆ˜', 'êµ¬ì¶•', 'ì»¨ì„¤íŒ…', 'itì„œë¹„ìŠ¤', 'it ì„œë¹„ìŠ¤'],
        'negative': ['ê³µì¥', 'ì–‘ì‚°', 'ìƒì‚°ë¼ì¸', 'ì„¤ë¹„'],
        'is_agnostic': True
    },
    'SECURITY': {
        'positive': ['edr', 'xdr', 'siem', 'waf', 'iam', 'sso', 'ë³´ì•ˆê´€ì œ', 'ë³´ì•ˆì†”ë£¨ì…˜'],
        'negative': ['ê²½ë¹„', 'cctv', 'ë¬¼ë¦¬ë³´ì•ˆ'],
        'is_agnostic': True
    },
    'DATA_INFRA': {
        'positive': ['etl', 'data lake', 'warehouse', 'bi', 'mlops', 'ë°ì´í„°ì¸í”„ë¼'],
        'negative': ['ê³µì¥', 'ì–‘ì‚°'],
        'is_agnostic': True
    },
    'CONSTRUCTION': {
        'positive': ['ê±´ì„¤', 'ì‹œê³µ', 'í† ëª©', 'í”ŒëœíŠ¸', 'epc'],
        'negative': ['ì–‘ì‚°', 'ì œí’ˆ'],
        'is_agnostic': True
    }
}


def classify_company_role(
    company_detail: CompanyDetail,
    company_name: Optional[str] = None
) -> Tuple[Optional[Dict[str, Any]], float]:
    """
    ê¸°ì—… íƒ€ì…(company_role) ë¶„ë¥˜
    
    ì„¤ê³„ ì›ì¹™:
    - Boostingì„ ì°¨ë‹¨í•˜ëŠ” ì‹ í˜¸ì´ì§€ ì„¹í„°ë¥¼ ì •í•˜ëŠ” ì‹ í˜¸ê°€ ì•„ë‹˜
    - Positive/Negative ê°€ì¤‘ì¹˜ ë°©ì‹
    - ConfidenceëŠ” ê²©ì°¨ ê¸°ë°˜ ê³„ì‚°
    
    Returns:
        (role_info, confidence): role_infoëŠ” {'role': str, 'is_agnostic': bool} í˜•íƒœ, confidenceëŠ” 0.0 ~ 1.0
    """
    text = (company_detail.biz_summary or "").lower()
    products_text = ' '.join([str(p).lower() for p in (company_detail.products or [])])
    keywords_text = ' '.join([str(k).lower() for k in (company_detail.keywords or [])])
    combined_text = f"{text} {products_text} {keywords_text}"
    
    role_scores = {}
    
    # ê° Roleë³„ ì ìˆ˜ ê³„ì‚° (positive * 2 - negative * 3)
    for role_key, role_def in ROLE_DEFINITIONS.items():
        positive_hits = sum(1 for kw in role_def['positive'] if kw in combined_text)
        negative_hits = sum(1 for kw in role_def['negative'] if kw in combined_text)
        score = (positive_hits * 2) - (negative_hits * 3)
        role_scores[role_key] = {
            'score': score,
            'is_agnostic': role_def['is_agnostic']
        }
    
    # ìµœê³  ì ìˆ˜ Role ì°¾ê¸°
    if not role_scores or max(r['score'] for r in role_scores.values()) <= 0:
        return (None, 0.0)
    
    # Top-2 ì ìˆ˜ë¡œ confidence ê³„ì‚° (ê²©ì°¨ ê¸°ë°˜)
    sorted_roles = sorted(role_scores.items(), key=lambda x: x[1]['score'], reverse=True)
    top1_score = sorted_roles[0][1]['score']
    top2_score = sorted_roles[1][1]['score'] if len(sorted_roles) > 1 else 0.0
    
    # Confidence = (top1 - top2) / (top1 + 1e-6)
    confidence = (top1_score - top2_score) / (top1_score + 1e-6)
    confidence = min(max(confidence, 0.0), 1.0)
    
    detected_role_key = sorted_roles[0][0]
    role_info = {
        'role': detected_role_key,
        'is_agnostic': role_scores[detected_role_key]['is_agnostic']
    }
    
    return (role_info, confidence)


def apply_anchor_boosting(
    candidates: List[Dict], 
    company_detail: CompanyDetail,
    company_name: Optional[str] = None,
    top2_gap: Optional[float] = None,
    remaining_budget: float = MAX_TOTAL_BOOST
) -> Tuple[List[Dict], Dict[str, Any], float]:
    """
    ì „ëµ B: Anchor Boosting (ë³´ì •, íŒë‹¨ ì•„ë‹˜)
    
    ì„¤ê³„ ì›ì¹™:
    - Boostingì€ íŒë‹¨ì´ ì•„ë‹ˆë¼ ë³´ì •ì´ë‹¤
    - ë™ì  ê¹¨ê¸°ë§Œ í—ˆìš© (Top-2 gap < threshold)
    - ë²”ìš© ì„¹í„°ëŠ” ì™„ì „ ê¸ˆì§€
    - company_role ê¸°ë°˜ ê°ì‡ (Multiplier) ì ìš©
    - Budget ì‚¬ì „ ì²´í¬ í›„ ì ìš©
    
    Args:
        candidates: ì„¹í„° í›„ë³´ ë¦¬ìŠ¤íŠ¸ (ì ìˆ˜ìˆœ ì •ë ¬ë¨)
        company_detail: CompanyDetail ê°ì²´
        company_name: íšŒì‚¬ëª…
        top2_gap: Top-2 ì ìˆ˜ ì°¨ì´ (Noneì´ë©´ ê³„ì‚°)
        remaining_budget: ë‚¨ì€ Boosting Budget
    
    Returns:
        (ë³´ì •ëœ í›„ë³´ ë¦¬ìŠ¤íŠ¸, boosting_log, ì‹¤ì œ ì ìš©ëœ boost)
    """
    boosting_log = {
        "anchor_applied": False,
        "kg_applied": False,
        "reason": "",
        "multiplier": 1.0,
        "final_boost": 0.0
    }
    
    # Multiplier ì´ˆê¸°í™”
    multiplier = 1.0
    
    # Gate 1: L1 ì„¹í„° Gate (ê°€ì¥ ê°•ë ¥ - ì™„ì „ ê¸ˆì§€)
    if not candidates or len(candidates) < 2:
        return candidates, boosting_log, 0.0
    
    top_sector = candidates[0].get('sector')
    if top_sector in INDUSTRY_AGNOSTIC_SECTORS:
        boosting_log["reason"] = f"ë²”ìš© ì„¹í„° ({top_sector}) â†’ Boosting ì™„ì „ ê¸ˆì§€"
        boosting_log["multiplier"] = 0.0
        return candidates, boosting_log, 0.0
    
    # Gate 2: Role Gate (ê°ì‡ )
    role_info, role_confidence = classify_company_role(company_detail, company_name)
    if role_info and role_info.get('is_agnostic') and role_confidence >= 0.7:
        multiplier = min(multiplier, 0.2)  # 80% ê°ì‡ 
        boosting_log["reason"] = f"Role={role_info['role']} (confidence={role_confidence:.2f}) â†’ 80% ê°ì‡ "
    
    # Gate 3: Tie-breaker Gate (ë™ì  ì•„ë‹ ë•Œ ì°¨ë‹¨)
    if top2_gap is None:
        if len(candidates) >= 2:
            top2_gap = candidates[0]['score'] - candidates[1]['score']
        else:
            top2_gap = 1.0
    
    if top2_gap >= TOP2_GAP_THRESHOLD:
        boosting_log["reason"] = f"Top-2 gap ({top2_gap:.3f}) >= threshold ({TOP2_GAP_THRESHOLD})"
        boosting_log["multiplier"] = 0.0
        return candidates, boosting_log, 0.0
    
    # Gate 4: ê³ ê°ì‚¬ ì—†ìŒ
    if not company_detail.clients:
        return candidates, boosting_log, 0.0
    
    # 1. ê³ ê°ì‚¬ í…ìŠ¤íŠ¸ì—ì„œ Anchor ì°¾ê¸°
    found_anchor_sectors = set()
    clients_text = str(company_detail.clients)
    
    # ì–´ë–¤ Anchorê°€ ë°œê²¬ë˜ì—ˆëŠ”ì§€ ì¶”ì  (ë¡œê¹…ìš©)
    found_anchors_map = {}  # {sector: [anchor_names]}
    
    for anchor_name, anchor_sector in STRICT_ANCHORS.items():
        if anchor_name in clients_text:
            found_anchor_sectors.add(anchor_sector)
            if anchor_sector not in found_anchors_map:
                found_anchors_map[anchor_sector] = []
            found_anchors_map[anchor_sector].append(anchor_name)
    
    if not found_anchor_sectors:
        return candidates, boosting_log, 0.0
        
    # 2. Boost ê³„ì‚°
    calculated_boost = BASE_ANCHOR_BOOST * multiplier
    
    # Budget ì‚¬ì „ ì²´í¬
    allowed_boost = min(calculated_boost, remaining_budget)
    
    if allowed_boost <= 0:
        boosting_log["reason"] = f"Budget ë¶€ì¡± (remaining: {remaining_budget:.3f})"
        return candidates, boosting_log, 0.0
    
    # êµì§‘í•©(Intersection)ì—ë§Œ ê°€ì‚°ì  ë¶€ì—¬
    boosted = False
    actual_boost = 0.0
    
    for candidate in candidates:
        sector = candidate['sector']
        if sector in found_anchor_sectors:
            # ë²”ìš© ì„¹í„°ëŠ” ì œì™¸
            if sector in INDUSTRY_AGNOSTIC_SECTORS:
                continue
                
            old_score = candidate['score']
            boost = allowed_boost  # Budget ì œí•œëœ boost ì‚¬ìš©
            candidate['score'] += boost
            candidate['score'] = min(1.0, candidate['score'])
            actual_boost = max(actual_boost, boost)
            
            # ê·¼ê±° ì¶”ê°€
            anchors = found_anchors_map.get(sector, [])
            anchor_str = ", ".join(anchors[:3])
            
            current_reasoning = candidate.get('reasoning', '')
            if current_reasoning:
                candidate['reasoning'] = f"{current_reasoning} [Anchor: {anchor_str}]"
            else:
                candidate['reasoning'] = f"ì£¼ìš” ê³ ê°ì‚¬({anchor_str}) ê¸°ë°˜ ë³´ì •"
            
            logger.info(
                f"ğŸš€ Anchor Boosting: {sector} "
                f"(Score: {old_score:.2f} â†’ {candidate['score']:.2f}, "
                f"Boost: +{boost:.3f}, Multiplier: {multiplier:.2f})"
            )
            boosted = True
    
    # ì ìˆ˜ìˆœ ì¬ì •ë ¬
    if boosted:
        candidates.sort(key=lambda x: x['score'], reverse=True)
        boosting_log.update({
            "anchor_applied": True,
            "multiplier": multiplier,
            "final_boost": actual_boost,
            "reason": f"Top-2 gap ({top2_gap:.3f}) < threshold, Anchor ë°œê²¬"
        })
        
    return candidates, boosting_log, actual_boost


def apply_kg_edge_boosting(
    candidates: List[Dict], 
    ticker: str, 
    db: Session,
    company_detail: CompanyDetail,
    company_name: Optional[str] = None,
    top2_gap: Optional[float] = None,
    remaining_budget: float = MAX_TOTAL_BOOST,
    multiplier: float = 1.0
) -> Tuple[List[Dict], Dict[str, Any], float]:
    """
    KG Edge ê¸°ë°˜ ë¯¸ì„¸ ë³´ì • (ë³´ì •, íŒë‹¨ ì•„ë‹˜)
    
    ì„¤ê³„ ì›ì¹™:
    - ì•ˆì „í•œ Edge íƒ€ì…ë§Œ ì‚¬ìš© (SUPPLIES_TO, CORE_DEPENDENCY)
    - ìœ„í—˜í•œ Edge íƒ€ì… ì œì™¸ (CUSTOMER_OF, PROJECT_WITH ë“±)
    - Edge íƒ€ì…ë³„ ê°€ì¤‘ì¹˜ ì°¨ë“± ì ìš©
    - ë™ì  ê¹¨ê¸°ë§Œ í—ˆìš©
    - Budget ì‚¬ì „ ì²´í¬ í›„ ì ìš©
    
    Args:
        candidates: ì„¹í„° í›„ë³´ ë¦¬ìŠ¤íŠ¸
        ticker: ì¢…ëª©ì½”ë“œ
        db: DB ì„¸ì…˜
        company_detail: CompanyDetail ê°ì²´
        company_name: íšŒì‚¬ëª…
        top2_gap: Top-2 ì ìˆ˜ ì°¨ì´
        remaining_budget: ë‚¨ì€ Boosting Budget
        multiplier: Role Gateì—ì„œ ê³„ì‚°ëœ multiplier
    
    Returns:
        (ë³´ì •ëœ í›„ë³´ ë¦¬ìŠ¤íŠ¸, boosting_log, ì‹¤ì œ ì ìš©ëœ boost)
    """
    boosting_log = {
        "anchor_applied": False,
        "kg_applied": False,
        "reason": "",
        "multiplier": multiplier,
        "final_boost": 0.0
    }
    
    # Gate 1: L1 ì„¹í„° Gate (ê°€ì¥ ê°•ë ¥ - ì™„ì „ ê¸ˆì§€)
    if not candidates or len(candidates) < 2:
        return candidates, boosting_log, 0.0
    
    top_sector = candidates[0].get('sector')
    if top_sector in INDUSTRY_AGNOSTIC_SECTORS:
        boosting_log["reason"] = f"ë²”ìš© ì„¹í„° ({top_sector}) â†’ KG Boosting ì™„ì „ ê¸ˆì§€"
        boosting_log["multiplier"] = 0.0
        return candidates, boosting_log, 0.0
    
    # Gate 2: Role Gate (ê°ì‡ ) - multiplierëŠ” ì´ë¯¸ ê³„ì‚°ë¨
    if multiplier <= 0:
        boosting_log["reason"] = f"Role Gateë¡œ ì¸í•œ ê°ì‡  (multiplier: {multiplier:.2f})"
        return candidates, boosting_log, 0.0
    
    # Gate 3: Tie-breaker Gate (ë™ì  ì•„ë‹ ë•Œ ì°¨ë‹¨)
    if top2_gap is None:
        if len(candidates) >= 2:
            top2_gap = candidates[0]['score'] - candidates[1]['score']
        else:
            top2_gap = 1.0
    
    if top2_gap >= TOP2_GAP_THRESHOLD:
        boosting_log["reason"] = f"Top-2 gap ({top2_gap:.3f}) >= threshold ({TOP2_GAP_THRESHOLD})"
        boosting_log["multiplier"] = 0.0
        return candidates, boosting_log, 0.0
    
    # Gate 4: Boosting Budget ì²´í¬
    if remaining_budget <= 0:
        boosting_log["reason"] = f"Budget ë¶€ì¡± (remaining: {remaining_budget:.3f})"
        return candidates, boosting_log, 0.0
    
    try:
        # ì•ˆì „í•œ Edge íƒ€ì…ë§Œ ì¡°íšŒ (ìœ„í—˜í•œ íƒ€ì… ì œì™¸)
        safe_edge_types = [et for et, weight in EDGE_WEIGHTS.items() if weight > 0]
        
        if not safe_edge_types:
            return candidates, boosting_log, 0.0
        
        # ì•ˆì „í•œ Edge ì¡°íšŒ
        edges = db.query(Edge).filter(
            Edge.source_id == ticker,
            Edge.relation_type.in_(safe_edge_types)
        ).limit(20).all()
        
        if not edges:
            logger.debug(f"[{ticker}] ì•ˆì „í•œ KG Edge ì—†ìŒ, ë³´ì • ìŠ¤í‚µ")
            return candidates, boosting_log, 0.0
        
        # ì—°ê²°ëœ ê¸°ì—…ë“¤ì˜ ì„¹í„° í™•ì¸ (Edge íƒ€ì…ë³„ ê°€ì¤‘ì¹˜ ì ìš©)
        connected_sectors = {}
        
        for edge in edges:
            edge_type = edge.relation_type
            edge_weight = EDGE_WEIGHTS.get(edge_type, 0.0)
            
            if edge_weight <= 0:
                continue  # ìœ„í—˜í•œ Edge íƒ€ì…ì€ ìŠ¤í‚µ
            
            target_ticker = edge.target_id
            target_sectors = db.query(InvestorSector).filter(
                InvestorSector.ticker == target_ticker,
                InvestorSector.is_primary == True
            ).all()
            
            for sector in target_sectors:
                if sector.major_sector not in connected_sectors:
                    connected_sectors[sector.major_sector] = 0.0
                # Edge íƒ€ì…ë³„ ê°€ì¤‘ì¹˜ ì ìš©
                connected_sectors[sector.major_sector] += edge.weight * edge_weight
        
        if not connected_sectors:
            return candidates, boosting_log, 0.0
        
        # Boost ê³„ì‚°
        calculated_boost = BASE_KG_BOOST * multiplier
        
        # Budget ì‚¬ì „ ì²´í¬
        allowed_boost = min(calculated_boost, remaining_budget)
        
        if allowed_boost <= 0:
            boosting_log["reason"] = f"Budget ë¶€ì¡± (remaining: {remaining_budget:.3f})"
            return candidates, boosting_log, 0.0
        
        # í›„ë³´ ì„¹í„°ì™€ ì—°ê²° ì„¹í„°ì˜ êµì§‘í•©ì— ë¯¸ì„¸ ê°€ì‚°ì 
        boosted = False
        actual_boost = 0.0
        
        for candidate in candidates:
            sector = candidate['sector']
            if sector in connected_sectors:
                # ë²”ìš© ì„¹í„°ëŠ” ì œì™¸
                if sector in INDUSTRY_AGNOSTIC_SECTORS:
                    continue
                
                # ì—°ê²° ê°•ë„ì— ë¹„ë¡€í•˜ì—¬ ë³´ì •
                connection_strength = min(connected_sectors[sector] / 5.0, 1.0)
                boost = connection_strength * allowed_boost  # Budget ì œí•œëœ boost ì‚¬ìš©
                
                if boost <= 0:
                    continue
                
                old_score = candidate['score']
                candidate['score'] += boost
                candidate['score'] = min(1.0, candidate['score'])
                actual_boost = max(actual_boost, boost)
                
                # ê·¼ê±° ì¶”ê°€
                current_reasoning = candidate.get('reasoning', '')
                kg_reasoning = f"[KG: {connected_sectors[sector]:.1f}]"
                candidate['reasoning'] = (
                    f"{current_reasoning} {kg_reasoning}"
                    if current_reasoning else f"KG Edge ë³´ì • (+{boost:.3f})"
                ).strip()
                
                logger.info(
                    f"[{ticker}] KG Edge Boosting: {sector} "
                    f"(Score: {old_score:.2f} â†’ {candidate['score']:.2f}, "
                    f"Boost: +{boost:.3f}, Multiplier: {multiplier:.2f})"
                )
                boosted = True
        
        # ì ìˆ˜ìˆœ ì¬ì •ë ¬
        if boosted:
            candidates.sort(key=lambda x: x['score'], reverse=True)
            boosting_log.update({
                "kg_applied": True,
                "multiplier": multiplier,
                "final_boost": actual_boost,
                "reason": f"Top-2 gap ({top2_gap:.3f}) < threshold, KG Edge ë°œê²¬"
            })
        
        return candidates, boosting_log, actual_boost
        
    except Exception as e:
        logger.warning(f"[{ticker}] KG Edge Boosting ì‹¤íŒ¨: {e}")
        return candidates, boosting_log, 0.0


def get_dynamic_weights(
    rule_conf: str,
    is_complex: bool,
    candidate_count: int,
    bge_used: bool,  # í˜¸í™˜ì„±ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° (í•­ìƒ False)
    gpt_used: bool
) -> Dict[str, float]:
    """
    Rule/Embedding/GPT ê°€ì¤‘ì¹˜ë¥¼ ìƒí™©ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì¡°ì •
    
    â­ BGE-M3 ì œê±°: Solar Embeddingìœ¼ë¡œ í†µí•©
    - ê¸°ì¡´: Rule 40%, KF-DeBERTa 30%, BGE-M3 20%, GPT 10%
    - ë³€ê²½ í›„: Rule 40%, Solar Embedding 50%, GPT 10%
    """
    weights = {
        'rule': 0.4,
        'embedding': 0.5,  # â¬† Solar Embedding (KF-DeBERTa + BGE-M3 í†µí•©)
        'bge': 0.0,  # ì œê±°ë¨
        'gpt': 0.1 if gpt_used else 0.0
    }

    def redistribute(amount: float, targets: List[str]):
        if amount <= 0:
            return
        share = amount / len(targets)
        for target in targets:
            weights[target] += share

    # GPT ë¹„í™œì„±í™” ì‹œ ê°€ì¤‘ì¹˜ ì¬ë¶„ë°°
    if not gpt_used:
        redistribute(weights.pop('gpt') if 'gpt' in weights else 0.0, ['rule', 'embedding'])
        weights['gpt'] = 0.0

    # Rule confidence ê¸°ë°˜ ì¡°ì •
    if rule_conf == 'HIGH':
        weights['rule'] += 0.15
        weights['embedding'] -= 0.10
        weights['gpt'] -= 0.05
    elif rule_conf == 'LOW':
        weights['rule'] -= 0.1
        weights['embedding'] += 0.08
        weights['gpt'] += 0.02

    # ë³µí•©ê¸°ì—…/í›„ë³´ ìˆ˜ê°€ ë§ìœ¼ë©´ ì„ë² ë”© ë¹„ì¤‘ ê°•í™”
    if is_complex or candidate_count > 3:
        weights['embedding'] += 0.05
        weights['rule'] -= 0.05

    # ìŒìˆ˜ ë°©ì§€
    for key in weights:
        weights[key] = max(weights[key], 0.0)

    total = sum(weights.values())
    if total == 0:
        return {'rule': 0.5, 'embedding': 0.5, 'bge': 0.0, 'gpt': 0.0}
    for key in weights:
        weights[key] = weights[key] / total
    return weights


def _prepare_company_text_for_embedding(
    company_detail: CompanyDetail,
    company_name: Optional[str] = None
) -> str:
    """
    Step 2 (Solar Embedding) ì „ìš©: ì „ì²´ í…ìŠ¤íŠ¸ (4,000 í† í° ì§€ì›)
    
    â­ 512 í† í° ì œí•œ ì œê±° - ì „ì²´ ì •ë³´ í¬í•¨
    Solar Embeddingì€ 4,000 í† í°ì„ ì§€ì›í•˜ë¯€ë¡œ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
    
    Args:
        company_detail: CompanyDetail ê°ì²´
        company_name: íšŒì‚¬ëª…
    
    Returns:
        ì „ì²´ í…ìŠ¤íŠ¸ (ì••ì¶• ì—†ìŒ)
    """
    text_parts = []
    
    if company_name:
        text_parts.append(f"íšŒì‚¬ëª…: {company_name}")
    
    # biz_summary ì „ì²´ ì‚¬ìš© (ì••ì¶• ë¶ˆí•„ìš”)
    if company_detail.biz_summary:
        text_parts.append(f"ì‚¬ì—… ê°œìš”: {company_detail.biz_summary}")
    
    # products/keywords ì „ì²´ í¬í•¨ (ì •ë ¬í•˜ì—¬ hash ì¼ê´€ì„± ë³´ì¥)
    if company_detail.products:
        products_sorted = sorted([str(p) for p in company_detail.products])
        products_text = ', '.join(products_sorted)
        text_parts.append(f"ì£¼ìš” ì œí’ˆ: {products_text}")
    
    if company_detail.keywords:
        keywords_sorted = sorted([str(k) for k in company_detail.keywords])
        keywords_text = ', '.join(keywords_sorted)
        text_parts.append(f"í‚¤ì›Œë“œ: {keywords_text}")
    
    # ì¶”ê°€ ì •ë³´ í¬í•¨ (ì •ë ¬í•˜ì—¬ hash ì¼ê´€ì„± ë³´ì¥)
    if company_detail.clients:
        clients_sorted = sorted([str(c) for c in company_detail.clients])
        clients_text = ', '.join(clients_sorted)
        text_parts.append(f"ì£¼ìš” ê³ ê°ì‚¬: {clients_text}")
    
    if company_detail.supply_chain:
        # supply_chainì€ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ ì •ë ¬ í›„ ë¬¸ìì—´ ë³€í™˜
        supply_items = [
            f"{item.get('item', '')} (ê³µê¸‰ì‚¬: {item.get('supplier', '')})"
            for item in company_detail.supply_chain
        ]
        supply_sorted = sorted(supply_items)
        supply_text = ', '.join(supply_sorted)
        text_parts.append(f"ê³µê¸‰ë§: {supply_text}")
    
    company_text = '\n\n'.join(text_parts)
    
    logger.debug(f"Step 2 ìµœì¢… í…ìŠ¤íŠ¸ ê¸¸ì´: {len(company_text)}ì (ì••ì¶• ì—†ìŒ, Solar Embedding)")
    return company_text


def _prepare_company_text_for_bge(
    company_detail: CompanyDetail,
    company_name: Optional[str] = None
) -> str:
    """
    Step 3 (BGE-M3) ì „ìš©: ì „ì²´ í…ìŠ¤íŠ¸ (8192 í† í° ì§€ì›)
    
    BGE-M3ëŠ” ì¥ë¬¸ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì „ì²´ ì •ë³´ í¬í•¨
    
    Args:
        company_detail: CompanyDetail ê°ì²´
        company_name: íšŒì‚¬ëª…
    
    Returns:
        ì „ì²´ í…ìŠ¤íŠ¸
    """
    text_parts = []
    
    if company_name:
        text_parts.append(f"íšŒì‚¬ëª…: {company_name}")
    
    # biz_summary ì „ì²´ ì‚¬ìš© (ì´ë¯¸ LLM ìš”ì•½ë³¸)
    if company_detail.biz_summary:
        text_parts.append(f"ì‚¬ì—… ê°œìš”: {company_detail.biz_summary}")
    
    # products/keywords ì „ì²´ í¬í•¨
    if company_detail.products:
        products_text = ', '.join([str(p) for p in company_detail.products[:20]])
        text_parts.append(f"ì£¼ìš” ì œí’ˆ: {products_text}")
    
    if company_detail.keywords:
        keywords_text = ', '.join([str(k) for k in company_detail.keywords[:20]])
        text_parts.append(f"í‚¤ì›Œë“œ: {keywords_text}")
    
    # ì¶”ê°€ ì •ë³´ (BGE-M3ëŠ” ì¥ë¬¸ ì§€ì›)
    if company_detail.clients:
        clients_text = ', '.join([str(c) for c in company_detail.clients[:10]])
        text_parts.append(f"ì£¼ìš” ê³ ê°ì‚¬: {clients_text}")
    
    if company_detail.supply_chain:
        supply_text = ', '.join([
            f"{item.get('item', '')} (ê³µê¸‰ì‚¬: {item.get('supplier', '')})"
            for item in company_detail.supply_chain[:10]
        ])
        text_parts.append(f"ê³µê¸‰ë§: {supply_text}")
    
    return '\n\n'.join(text_parts)


def _prepare_company_text_for_gpt(
    company_detail: CompanyDetail,
    company_name: Optional[str] = None
) -> str:
    """
    Step 4 (GPT) ì „ìš©: ìµœì í™”ëœ ì •ë³´ (ì¸ê³¼ ë¶„ì„ìš©, 2000ì)
    
    â­ ë¹„ìš© ì ˆê°: í•µì‹¬ ì •ë³´ë§Œ ì„ ë³„ (30ê°œ â†’ 10ê°œ)
    â­ í’ˆì§ˆ ìœ ì§€: ì¸ê³¼ ë¶„ì„ì— í•„ìš”í•œ ì •ë³´ëŠ” ëª¨ë‘ í¬í•¨
    
    Args:
        company_detail: CompanyDetail ê°ì²´
        company_name: íšŒì‚¬ëª…
    
    Returns:
        ìµœì í™”ëœ í…ìŠ¤íŠ¸ (2000ì ì´ë‚´)
    """
    text_parts = []
    
    if company_name:
        text_parts.append(f"íšŒì‚¬ëª…: {company_name}")
    
    # biz_summary: "ì‚¬ì—…ì˜ ê°œìš”" ìš°ì„  í¬í•¨ (2000ì ì œí•œ ê³ ë ¤)
    if company_detail.biz_summary:
        # GPTëŠ” 2000ì ì œí•œì´ ìˆìœ¼ë¯€ë¡œ, biz_summaryëŠ” 800ì ì •ë„ë¡œ ì œí•œ
        # ë‚˜ë¨¸ì§€ ê³µê°„ì€ products, keywords ë“±ì— í• ë‹¹
        summary = _extract_biz_summary_with_priority(
            company_detail.biz_summary,
            max_chars=800,
            use_semantic_extraction=True
        )
        text_parts.append(f"ì‚¬ì—… ê°œìš”: {summary}")
    
    # â­ ìµœì í™”: í•µì‹¬ ì •ë³´ë§Œ ì„ ë³„ (30ê°œ â†’ 10ê°œ)
    # products: 10ê°œ (ìƒìœ„ ì œí’ˆë§Œ)
    if company_detail.products:
        products_text = ', '.join([str(p) for p in company_detail.products[:10]])
        text_parts.append(f"ì£¼ìš” ì œí’ˆ: {products_text}")
    
    # keywords: 10ê°œ (ì¤‘ë³µ ì œê±° í›„ ìƒìœ„)
    if company_detail.keywords:
        # ì¤‘ë³µ ì œê±° ë° ìƒìœ„ 10ê°œë§Œ
        unique_keywords = list(dict.fromkeys([str(k) for k in company_detail.keywords]))[:10]
        keywords_text = ', '.join(unique_keywords)
        text_parts.append(f"í‚¤ì›Œë“œ: {keywords_text}")
    
    # clients: 10ê°œ (ì£¼ìš” ê³ ê°ì‚¬ë§Œ)
    if company_detail.clients:
        clients_text = ', '.join([str(c) for c in company_detail.clients[:10]])
        text_parts.append(f"ì£¼ìš” ê³ ê°ì‚¬: {clients_text}")
    
    # supply_chain: 10ê°œ (í•µì‹¬ ê³µê¸‰ë§ë§Œ)
    if company_detail.supply_chain:
        supply_text = ', '.join([
            f"{item.get('item', '')} (ê³µê¸‰ì‚¬: {item.get('supplier', '')})"
            for item in company_detail.supply_chain[:10]
        ])
        text_parts.append(f"ê³µê¸‰ë§: {supply_text}")
    
    # raw_materials: 10ê°œ (ì£¼ìš” ì›ì¬ë£Œë§Œ)
    if company_detail.raw_materials:
        raw_materials_text = ', '.join([str(rm) for rm in company_detail.raw_materials[:10]])
        text_parts.append(f"ì›ì¬ë£Œ: {raw_materials_text}")
    
    company_text = '\n\n'.join(text_parts)
    
    # â­ ë¹„ìš© ì ˆê°: 2000ìë¡œ ì œí•œ (ê¸°ì¡´ 3000ìì—ì„œ ê°ì†Œ)
    if len(company_text) > 2000:
        # ì˜ë¯¸ ê¸°ë°˜ìœ¼ë¡œ í•µì‹¬ ë¶€ë¶„ë§Œ ì„ íƒ
        try:
            company_text = extract_key_sentences_for_sector(
                company_text,
                max_chars=2000,
                min_chars=1500
            )
        except Exception as e:
            logger.warning(f"GPT í…ìŠ¤íŠ¸ ì••ì¶• ì‹¤íŒ¨: {e}")
            company_text = company_text[:1997] + "..."
    
    return company_text


def _extract_biz_summary_with_priority(
    biz_summary: str,
    max_chars: int = 500,
    use_semantic_extraction: bool = True
) -> str:
    """
    "ì‚¬ì—…ì˜ ê°œìš”" ê´€ë ¨ ë¬¸ë‹¨ì„ ìš°ì„  í¬í•¨í•˜ì—¬ biz_summary ì••ì¶•
    
    ìš°ì„ ìˆœìœ„:
    1. "ì‚¬ì—…ì˜ ê°œìš”" ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ë‹¨ (ìµœìš°ì„ )
    2. ì˜ë¯¸ ê¸°ë°˜ í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
    3. ì¼ë°˜ ë¬¸ë‹¨/ë¬¸ì¥ ë‹¨ìœ„ ì••ì¶•
    
    Args:
        biz_summary: ì›ë³¸ ì‚¬ì—… ìš”ì•½ í…ìŠ¤íŠ¸
        max_chars: ìµœëŒ€ ë¬¸ì ìˆ˜
        use_semantic_extraction: ì˜ë¯¸ ê¸°ë°˜ ì¶”ì¶œ ì‚¬ìš© ì—¬ë¶€
    
    Returns:
        ì••ì¶•ëœ ì‚¬ì—… ìš”ì•½ í…ìŠ¤íŠ¸
    """
    if not biz_summary:
        return ""
    
    # ì´ë¯¸ max_chars ì´í•˜ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if len(biz_summary) <= max_chars:
        return biz_summary
    
    # 1. "ì‚¬ì—…ì˜ ê°œìš”" ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ë‹¨ ìš°ì„  ì¶”ì¶œ
    priority_keywords = [
        'ì‚¬ì—…ì˜ ê°œìš”', 'ì§€ì£¼íšŒì‚¬', 'ì˜ìœ„', 'ì£¼ìš” ì‚¬ì—…', 'ì‚¬ì—… ë‚´ìš©',
        'ë°°ë‹¹ê¸ˆìˆ˜ìµ', 'ì„ëŒ€ìˆ˜ìµ', 'ë¡œì—´í‹°', 'ê³„ì—´ì‚¬', 'ìíšŒì‚¬',
        'ë§¤ì¶œ ë¹„ì¤‘', 'ì‚¬ì—…ë¶€ë¬¸', 'ë¶€ë¬¸ë³„ ë§¤ì¶œ'
    ]
    
    # ë¬¸ë‹¨ ë¶„ë¦¬
    import re
    paragraphs = re.split(r'\n\s*\n+', biz_summary)
    paragraphs = [p.strip() for p in paragraphs if p.strip()]
    
    if not paragraphs:
        # ë¬¸ë‹¨ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
        return _fallback_biz_summary_extraction(biz_summary, max_chars, use_semantic_extraction)
    
    # ìš°ì„ ìˆœìœ„ ë¬¸ë‹¨ê³¼ ì¼ë°˜ ë¬¸ë‹¨ ë¶„ë¦¬
    priority_paragraphs = []
    other_paragraphs = []
    
    for para in paragraphs:
        para_lower = para.lower()
        if any(kw in para_lower for kw in priority_keywords):
            priority_paragraphs.append(para)
        else:
            other_paragraphs.append(para)
    
    # ìš°ì„  ë¬¸ë‹¨ ë¨¼ì € í¬í•¨
    selected = []
    remaining_chars = max_chars
    
    # ìµœëŒ€ 2ê°œ ìš°ì„  ë¬¸ë‹¨ í¬í•¨
    for para in priority_paragraphs[:2]:
        if len(para) <= remaining_chars:
            selected.append(para)
            remaining_chars -= len(para) + 2  # \n\n í¬í•¨
        elif remaining_chars > 100:
            # ë¬¸ë‹¨ ì¼ë¶€ë§Œ í¬í•¨ (ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°)
            truncated = truncate_to_sentences(para, max_chars=remaining_chars, prefer_paragraphs=False)
            if truncated:
                selected.append(truncated)
                remaining_chars = 0
            break
    
    # ë‚¨ì€ ê³µê°„ì— ì¼ë°˜ ë¬¸ë‹¨ ì¶”ê°€
    if remaining_chars > 100:
        for para in other_paragraphs:
            if len(para) <= remaining_chars:
                selected.append(para)
                remaining_chars -= len(para) + 2
            elif remaining_chars > 50:
                # ë¬¸ë‹¨ ì¼ë¶€ë§Œ í¬í•¨
                truncated = truncate_to_sentences(para, max_chars=remaining_chars, prefer_paragraphs=False)
                if truncated:
                    selected.append(truncated)
                    break
            else:
                break
    
    # ê²°ê³¼ ì¡°í•©
    if selected:
        result = '\n\n'.join(selected)
        if len(result) > max_chars:
            result = result[:max_chars].rstrip() + "..."
        return result
    
    # ìš°ì„  ë¬¸ë‹¨ì´ ì—†ê±°ë‚˜ ì„ íƒ ì‹¤íŒ¨ ì‹œ Fallback
    return _fallback_biz_summary_extraction(biz_summary, max_chars, use_semantic_extraction)


def _fallback_biz_summary_extraction(
    biz_summary: str,
    max_chars: int = 500,
    use_semantic_extraction: bool = True
) -> str:
    """
    Fallback: ì˜ë¯¸ ê¸°ë°˜ ì¶”ì¶œ ë˜ëŠ” ì¼ë°˜ ì••ì¶•
    """
    if use_semantic_extraction and SEMANTIC_EXTRACTION_AVAILABLE:
        try:
            summary = extract_key_sentences_for_sector(
                biz_summary,
                max_chars=max_chars,
                min_chars=300,
                top_n=5,
                keyword_weight=0.4,
                embedding_weight=0.6,
                use_embedding=True
            )
            original_length = len(biz_summary)
            compression_ratio = (len(summary) / original_length * 100) if original_length > 0 else 0
            logger.debug(f"ì˜ë¯¸ ê¸°ë°˜ ë¬¸ì¥ ì¶”ì¶œ ì™„ë£Œ: {len(summary)}ì (ì••ì¶•ë¥ : {compression_ratio:.1f}%)")
            return summary
        except Exception as e:
            logger.warning(f"ì˜ë¯¸ ê¸°ë°˜ ë¬¸ì¥ ì¶”ì¶œ ì‹¤íŒ¨, Fallback ì‚¬ìš©: {e}")
    
    # ìµœì¢… Fallback: ë¬¸ë‹¨/ë¬¸ì¥ ë‹¨ìœ„ ìë¥´ê¸°
    return truncate_to_sentences(
        biz_summary,
        max_chars=max_chars,
        prefer_paragraphs=True
    )


def _prepare_company_text(
    company_detail: CompanyDetail,
    company_name: Optional[str] = None,
    use_semantic_extraction: bool = True
) -> str:
    """
    íšŒì‚¬ í…ìŠ¤íŠ¸ ì¤€ë¹„ (biz_summary + products + keywords)
    
    âš ï¸ Deprecated: ë‹¨ê³„ë³„ í•¨ìˆ˜ ì‚¬ìš© ê¶Œì¥
    - Step 2: _prepare_company_text_for_embedding()
    - Step 3: _prepare_company_text_for_bge()
    - Step 4: _prepare_company_text_for_gpt()
    
    í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜)
    """
    text_parts = []
    
    if company_name:
        text_parts.append(f"íšŒì‚¬ëª…: {company_name}")
    
    if company_detail.biz_summary:
        # ğŸ†• "ì‚¬ì—…ì˜ ê°œìš”" ìš°ì„  í¬í•¨ ë¡œì§
        summary = _extract_biz_summary_with_priority(
            company_detail.biz_summary,
            use_semantic_extraction=use_semantic_extraction
        )
        text_parts.append(f"ì‚¬ì—… ê°œìš”: {summary}")
    
    if company_detail.products:
        products_text = ', '.join([str(p) for p in company_detail.products[:20]])
        text_parts.append(f"ì£¼ìš” ì œí’ˆ: {products_text}")
    
    if company_detail.keywords:
        keywords_text = ', '.join([str(k) for k in company_detail.keywords[:20]])
        text_parts.append(f"í‚¤ì›Œë“œ: {keywords_text}")
    
    return '\n\n'.join(text_parts)


def classify_sector_ensemble(
    db: Session,
    ticker: str,
    llm_handler: Optional[LLMHandler] = None,
    use_gpt: bool = True,
    use_embedding: bool = True,
    use_reranking: bool = True,
    max_sectors: int = 3,
    use_semantic_extraction: bool = True  # Phase 1 ìµœì í™”: ì˜ë¯¸ ê¸°ë°˜ í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ
) -> Optional[List[Dict[str, Any]]]:
    """
    4ë‹¨ê³„ ë©€í‹° ëª¨ë¸ ì•™ìƒë¸” ì„¹í„° ë¶„ë¥˜
    
    Args:
        db: DB ì„¸ì…˜
        ticker: ì¢…ëª©ì½”ë“œ
        llm_handler: LLMHandler ê°ì²´ (GPT ì‚¬ìš© ì‹œ)
        use_gpt: GPT ìµœì¢… ê²€ì¦ ì‚¬ìš© ì—¬ë¶€
        use_embedding: ì„ë² ë”© ëª¨ë¸ ê¸°ë°˜ í›„ë³´ ìƒì„± ì‚¬ìš© ì—¬ë¶€
        use_reranking: BGE-M3 Re-ranking ì‚¬ìš© ì—¬ë¶€
        max_sectors: ìµœëŒ€ ì„¹í„° ê°œìˆ˜ (ê¸°ë³¸ê°’: 3)
        use_semantic_extraction: Phase 1 ìµœì í™” ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
                                 ì˜ë¯¸ ê¸°ë°˜ í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œë¡œ biz_summary ì••ì¶•
    
    Returns:
        [
            {
                'major_sector': 'SEC_SEMI',
                'sub_sector': 'MEMORY',
                'value_chain': 'MIDSTREAM',
                'weight': 0.6,
                'is_primary': True,
                'confidence': 'HIGH',
                'method': 'ENSEMBLE',
                'rule_score': 0.95,
                'embedding_score': 0.85,
                'bge_score': 0.82,
                'gpt_score': 0.9,
                'ensemble_score': 0.88,
                'reasoning': 'GPTê°€ ì œê³µí•œ ê·¼ê±°...'
            },
            ...
        ]
    """
    # CompanyDetail ì¡°íšŒ
    from app.utils.stock_query import get_stock_by_ticker_safe
    company_detail = db.query(CompanyDetail).filter(
        CompanyDetail.ticker == ticker
    ).first()
    
    if not company_detail:
        logger.warning(f"[{ticker}] CompanyDetail ë°ì´í„° ì—†ìŒ")
        return None
    
    stock = get_stock_by_ticker_safe(db, ticker)
    company_name = stock.stock_name if stock else None
    
    # ========================================================================
    # Step 0: KRX ì—…ì¢… Prior (ì‹ ê·œ ì¶”ê°€) â­
    # ========================================================================
    logger.info(f"[{ticker}] Step 0: KRX ì—…ì¢… Prior ì‹œì‘")
    krx_major = None
    krx_sub = None
    krx_confidence = "LOW"
    try:
        from app.services.hierarchical_sector_classifier import classify_sector_step1_krx
        krx_major, krx_sub, krx_confidence = classify_sector_step1_krx(db, ticker)
        if krx_major:
            logger.info(f"[{ticker}] KRX ì—…ì¢… Prior: {krx_major}/{krx_sub} (confidence: {krx_confidence})")
        else:
            logger.debug(f"[{ticker}] KRX ì—…ì¢… ì •ë³´ ì—†ìŒ")
    except Exception as e:
        logger.warning(f"[{ticker}] KRX ì—…ì¢… Prior ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    # ========================================================================
    # Step 1: Rule-based Classification (ê°€ì¤‘ì¹˜ 40%)
    # ========================================================================
    logger.info(f"[{ticker}] Step 1: Rule-based ë¶„ë¥˜ ì‹œì‘")
    
    rule_major, rule_sub, rule_vc, rule_conf, _ = classify_sector_rule_based(
        company_detail, company_name
    )
    
    rule_score_map = {'HIGH': 1.0, 'MEDIUM': 0.7, 'LOW': 0.4}
    rule_score = rule_score_map.get(rule_conf, 0.4)
    
    # ê¸°ì¡´ ì„¹í„° ì½”ë“œë¥¼ ìƒˆ ì„¹í„° ì½”ë“œë¡œ ë§¤í•‘ (Rule-based ê²°ê³¼ë„)
    if rule_major and rule_major in LEGACY_SECTOR_MAPPING:
        mapped_major = LEGACY_SECTOR_MAPPING[rule_major]
        logger.info(f"[{ticker}] Rule-based ì„¹í„° ë§¤í•‘: {rule_major} â†’ {mapped_major}")
        rule_major = mapped_major
    
    # Step 0 ê²°ê³¼ì™€ Step 1 ê²°ê³¼ ë¹„êµ (KRX-Rule ì¼ì¹˜ ì—¬ë¶€)
    if krx_major and rule_major:
        if krx_major == rule_major:
            # ì¼ì¹˜ â†’ Confidence ë³´ë„ˆìŠ¤
            rule_score += 0.1
            rule_score = min(1.0, rule_score)
            logger.info(f"[{ticker}] KRX-Rule ì¼ì¹˜ â†’ Confidence ë³´ë„ˆìŠ¤ (+0.1, ìµœì¢…: {rule_score:.2f})")
        else:
            # ë¶ˆì¼ì¹˜ â†’ KRX ì„¹í„°ë¥¼ í›„ë³´ì— ì¶”ê°€í•  ì˜ˆì • (Step 2ì—ì„œ ì²˜ë¦¬)
            logger.info(f"[{ticker}] KRX-Rule ë¶ˆì¼ì¹˜ (KRX: {krx_major}, Rule: {rule_major})")
    
    # ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜ (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)
    value_chain_results = None
    if VALUE_CHAIN_CLASSIFIER_AVAILABLE and rule_major:
        try:
            value_chain_results = classify_value_chain_hybrid(
                company_detail,
                rule_major,  # ì„¹í„° ì½”ë“œ ì‚¬ìš©
                company_name,
                use_ensemble=True
            )
            if value_chain_results:
                # Primary value chain ì‚¬ìš©
                rule_vc = value_chain_results[0].get('value_chain', rule_vc)
                logger.debug(f"[{ticker}] í•˜ì´ë¸Œë¦¬ë“œ ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜: {rule_vc}")
        except Exception as e:
            logger.warning(f"[{ticker}] ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜ ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©: {e}")
    
    # Confidence HIGHë©´ ì¦‰ì‹œ ë°˜í™˜ (ê°€ì¤‘ì¹˜ 40% ì¶©ë¶„)
    if rule_conf == "HIGH" and rule_score >= 0.9:
        logger.info(f"[{ticker}] Rule-based HIGH confidence â†’ ì¦‰ì‹œ ë°˜í™˜")
        return [{
            'major_sector': rule_major,
            'sub_sector': rule_sub,
            'value_chain': rule_vc,
            'weight': 1.0,
            'is_primary': True,
            'confidence': rule_conf,
            'method': 'RULE_BASED',
            'rule_score': rule_score,
            'embedding_score': None,
            'bge_score': None,
            'gpt_score': None,
            'ensemble_score': rule_score,
            'reasoning': f'Rule-based í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ HIGH confidence ({rule_score:.2f})'
        }]
    
    # ========================================================================
    # Step 2: ì„ë² ë”© ëª¨ë¸ ê¸°ë°˜ í›„ë³´ ìƒì„±ê¸° (ê°€ì¤‘ì¹˜ 30%)
    # ========================================================================
    if not use_embedding or not EMBEDDING_AVAILABLE:
        logger.info(f"[{ticker}] ì„ë² ë”© ëª¨ë¸ ìŠ¤í‚µ (use_embedding={use_embedding}, available={EMBEDDING_AVAILABLE})")
        candidates = []
    else:
        logger.info(f"[{ticker}] Step 2: ì„ë² ë”© ëª¨ë¸ í›„ë³´ ìƒì„± ì‹œì‘")
        
        try:
            # â­ Step 2 ì „ìš©: ìµœì í™”ëœ 400ì í…ìŠ¤íŠ¸ ì‚¬ìš©
            company_text = _prepare_company_text_for_embedding(
                company_detail, 
                company_name
            )
            candidates = generate_sector_candidates(
                company_text,
                top_k=5,
                min_threshold=0.3,  # 0.4 â†’ 0.3ìœ¼ë¡œ ë‚®ì¶¤ (ë” ë§ì€ í›„ë³´ ìƒì„±)
                model_name=None,
                db=db,
                ticker=ticker,
                force_regenerate=False
            )
            
            if candidates:
                logger.info(f"[{ticker}] ì„ë² ë”© ëª¨ë¸ í›„ë³´ ìƒì„± ì™„ë£Œ: {len(candidates)}ê°œ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(company_text)}ì)")
            else:
                logger.warning(f"[{ticker}] ì„ë² ë”© ëª¨ë¸ í›„ë³´ ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” í›„ë³´ ì—†ìŒ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(company_text) if company_text else 0}ì)")
        except Exception as e:
            logger.error(f"[{ticker}] ì„ë² ë”© ëª¨ë¸ í›„ë³´ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            candidates = []
            
    # Step 2.5: Anchor Boosting (ì „ëµ B) - Budget ìƒíƒœ ê´€ë¦¬ ë°©ì‹
    # ë™ì  ê¹¨ê¸°ë§Œ í—ˆìš©, ë²”ìš© ì„¹í„° ì™„ì „ ê¸ˆì§€, Role Gate ê°ì‡  ì ìš©
    top2_gap = None
    if len(candidates) >= 2:
        top2_gap = candidates[0]['score'] - candidates[1]['score']
    
    # Budget ìƒíƒœ ì´ˆê¸°í™”
    remaining_budget = MAX_TOTAL_BOOST
    
    # Anchor Boosting ë‹¨ê³„
    candidates, anchor_boosting_log, anchor_boost = apply_anchor_boosting(
        candidates, 
        company_detail, 
        company_name,
        top2_gap=top2_gap,
        remaining_budget=remaining_budget
    )
    
    # Budget ì—…ë°ì´íŠ¸
    remaining_budget -= anchor_boost
    
    # Role Gateì—ì„œ ê³„ì‚°ëœ multiplier ì¶”ì¶œ (KG Boostingì—ì„œ ì¬ì‚¬ìš©)
    multiplier = anchor_boosting_log.get('multiplier', 1.0)
    
    # Step 2.6: KG Edge Boosting (ì‹ ê·œ) - Budget ìƒíƒœ ê´€ë¦¬ ë°©ì‹
    # ì•ˆì „í•œ Edge íƒ€ì…ë§Œ ì‚¬ìš©, Edge íƒ€ì…ë³„ ê°€ì¤‘ì¹˜ ì°¨ë“±, Boosting Budget ì¤€ìˆ˜
    candidates, kg_boosting_log, kg_boost = apply_kg_edge_boosting(
        candidates, 
        ticker, 
        db,
        company_detail,
        company_name,
        top2_gap=top2_gap,
        remaining_budget=remaining_budget,
        multiplier=multiplier
    )
    
    # Budget ì—…ë°ì´íŠ¸
    remaining_budget -= kg_boost
    
    # ì´ ì ìš©ëœ boost ê³„ì‚°
    total_boost = anchor_boost + kg_boost
    
    # Boosting ë¡œê·¸ í†µí•© (ìµœì¢… ê²°ê³¼ì— í¬í•¨)
    boosting_info = {
        "anchor_applied": anchor_boosting_log.get('anchor_applied', False),
        "kg_applied": kg_boosting_log.get('kg_applied', False),
        "reason": anchor_boosting_log.get('reason', '') or kg_boosting_log.get('reason', ''),
        "multiplier": multiplier,
        "final_boost": total_boost
    }
    
    # Rule-based ê²°ê³¼ê°€ ìˆìœ¼ë©´ í›„ë³´ì— ì¶”ê°€
    if rule_major and rule_score >= 0.4:
        # ê¸°ì¡´ ì„¹í„° ì½”ë“œë¥¼ ìƒˆ ì„¹í„° ì½”ë“œë¡œ ë§¤í•‘
        mapped_sector = LEGACY_SECTOR_MAPPING.get(rule_major, rule_major)
        if mapped_sector != rule_major:
            logger.info(f"[{ticker}] Rule-based ì„¹í„° ë§¤í•‘: {rule_major} â†’ {mapped_sector}")
            rule_major = mapped_sector
        
        # ì´ë¯¸ í›„ë³´ì— ìˆëŠ”ì§€ í™•ì¸
        existing = next((c for c in candidates if c['sector'] == rule_major), None)
        if not existing:
            candidates.append({
                'sector': rule_major,
                'score': rule_score
            })
        else:
            # Rule-based ì ìˆ˜ì™€ í‰ê· 
            existing['score'] = (existing['score'] + rule_score) / 2
    
    # Step 0 ê²°ê³¼: KRX-Rule ë¶ˆì¼ì¹˜ ì‹œ KRX ì„¹í„°ë¥¼ í›„ë³´ì— ì¶”ê°€
    if krx_major and rule_major and krx_major != rule_major:
        # KRX ì„¹í„°ê°€ í›„ë³´ì— ì—†ëŠ” ê²½ìš°ë§Œ ì¶”ê°€
        existing_krx = next((c for c in candidates if c['sector'] == krx_major), None)
        if not existing_krx:
            krx_score = 0.3  # ë‚®ì€ ì ìˆ˜ë¡œ í›„ë³´ì—ë§Œ ì¶”ê°€
            candidates.append({
                'sector': krx_major,
                'score': krx_score,
                'reasoning': f'KRX ì—…ì¢… ê¸°ë°˜ ({krx_confidence})'
            })
            logger.info(f"[{ticker}] KRX ì„¹í„°ë¥¼ í›„ë³´ì— ì¶”ê°€: {krx_major} (score: {krx_score})")
    
    if not candidates:
        logger.warning(f"[{ticker}] í›„ë³´ ì„¹í„° ì—†ìŒ. Rule-based ê²°ê³¼ ë°˜í™˜")
        if rule_major:
            return [{
                'major_sector': rule_major,
                'sub_sector': rule_sub,
                'value_chain': rule_vc,
                'weight': 1.0,
                'is_primary': True,
                'confidence': rule_conf,
                'method': 'RULE_BASED',
                'rule_score': rule_score,
                'ensemble_score': rule_score,
                'reasoning': 'Rule-based ë¶„ë¥˜ (í›„ë³´ ìƒì„± ì‹¤íŒ¨)'
            }]
        return None
    
    # ========================================================================
    # Step 3: BGE-M3 Re-ranking ì œê±° (Solar Embeddingìœ¼ë¡œ í†µí•©)
    # ========================================================================
    # â­ BGE-M3 ì œê±°: Solar Embeddingì´ ì¶©ë¶„íˆ ì •í™•í•˜ë¯€ë¡œ Re-ranking ë¶ˆí•„ìš”
    # Step 2 ê²°ê³¼ì—ì„œ Top-2 ì§ì ‘ ì„ íƒ
    logger.info(f"[{ticker}] Step 3: BGE-M3 Re-ranking ì œê±° (Solar Embedding ì‚¬ìš©)")
    reranked_candidates = candidates[:2]  # Top-2 ì§ì ‘ ì„ íƒ
    
    if not reranked_candidates:
        logger.warning(f"[{ticker}] Re-ranking ê²°ê³¼ ì—†ìŒ. Rule-based ë˜ëŠ” ì›ë³¸ í›„ë³´ ì‚¬ìš©")
        # Re-ranking ì‹¤íŒ¨ ì‹œ ì›ë³¸ í›„ë³´ ë˜ëŠ” Rule-based ê²°ê³¼ ì‚¬ìš©
        if candidates:
            # ì›ë³¸ í›„ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            reranked_candidates = candidates[:2]  # top_k ë³€ìˆ˜ ëŒ€ì‹  2 ì‚¬ìš©
        elif rule_major:
            # Rule-based ê²°ê³¼ë§Œ ì‚¬ìš©
            return [{
                'major_sector': rule_major,
                'sub_sector': rule_sub,
                'value_chain': rule_vc,
                'weight': 1.0,
                'is_primary': True,
                'confidence': rule_conf,
                'method': 'RULE_BASED',
                'rule_score': rule_score,
                'ensemble_score': rule_score,
                'reasoning': 'Rule-based ë¶„ë¥˜ (Re-ranking ì‹¤íŒ¨)'
            }]
        else:
            logger.error(f"[{ticker}] ëª¨ë“  ë¶„ë¥˜ ë°©ë²• ì‹¤íŒ¨")
            return None
    
    # ========================================================================
    # Step 3.5: Sub-sector ë¶„ë¥˜ (ì‹ ê·œ ì¶”ê°€) â­
    # ========================================================================
    # Major Top-2 í›„ë³´ë³„ë¡œ ê°ê° Sub-sector ê²°ì •
    logger.info(f"[{ticker}] Step 3.5: Sub-sector ë¶„ë¥˜ ì‹œì‘")
    
    def classify_sub_sector(
        major_sector: str,
        company_detail: CompanyDetail,
        company_name: Optional[str] = None
    ) -> Optional[str]:
        """
        Major Sector ê¸°ë°˜ Sub-sector ë¶„ë¥˜
        
        Args:
            major_sector: Major Sector ì½”ë“œ
            company_detail: CompanyDetail ê°ì²´
            company_name: íšŒì‚¬ëª…
        
        Returns:
            Sub-sector ì½”ë“œ ë˜ëŠ” None
        """
        from app.models.sector_reference import SUB_SECTOR_DEFINITIONS
        
        if major_sector not in SUB_SECTOR_DEFINITIONS:
            return None
        
        sub_sectors = SUB_SECTOR_DEFINITIONS[major_sector]
        sub_sector_scores = {}
        
        # í…ìŠ¤íŠ¸ ì¤€ë¹„
        text_parts = []
        if company_detail.biz_summary:
            text_parts.append(company_detail.biz_summary.lower())
        if company_detail.products:
            products_text = ' '.join([str(p) for p in company_detail.products]).lower()
            text_parts.append(products_text)
        if company_detail.keywords:
            keywords_text = ' '.join([str(k) for k in company_detail.keywords]).lower()
            text_parts.append(keywords_text)
        
        combined_text = ' '.join(text_parts)
        
        # ê° Sub-sectorë³„ í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        for sub_code, sub_def in sub_sectors.items():
            score = 0
            keywords = sub_def.get('keywords', [])
            for keyword in keywords:
                if keyword.lower() in combined_text:
                    score += 1
            
            if score > 0:
                sub_sector_scores[sub_code] = score
        
        # ìµœê³  ì ìˆ˜ Sub-sector ë°˜í™˜
        if sub_sector_scores:
            best_sub = max(sub_sector_scores.items(), key=lambda x: x[1])
            if best_sub[1] > 0:
                logger.debug(f"Sub-sector ë¶„ë¥˜: {major_sector} â†’ {best_sub[0]} (ì ìˆ˜: {best_sub[1]})")
                return best_sub[0]
        
        return None
    
    # Top-2 í›„ë³´ë³„ë¡œ Sub-sector ë¶„ë¥˜ (Step 3.5 ìµœì¢… í™•ì •)
    # â­ ì¤‘ìš”: ì´ ê²°ê³¼ê°€ ìµœì¢… Sub-sectorì´ë©°, GPTëŠ” ë³€ê²½í•  ìˆ˜ ì—†ìŒ
    sub_sector_final_map = {}  # {major_sector: sub_sector} ë§¤í•‘ ì €ì¥
    for candidate in reranked_candidates[:2]:
        major_sector = candidate.get('sector')
        if major_sector:
            sub_sector = classify_sub_sector(major_sector, company_detail, company_name)
            if sub_sector:
                candidate['sub_sector'] = sub_sector
                sub_sector_final_map[major_sector] = sub_sector  # ìµœì¢… í™•ì •ê°’ ì €ì¥
                logger.info(f"[{ticker}] Step 3.5 ìµœì¢… í™•ì •: {major_sector} â†’ Sub-sector: {sub_sector}")
    
    # ========================================================================
    # Step 5: Confidence ê¸°ë°˜ Fallback ì •êµí™” (ê°œì„ ) â­
    # ========================================================================
    # 3ë‹¨ê³„ ë¶„ë¦¬:
    # - â‰¥ 0.90: ì¦‰ì‹œ í™•ì • (GPT ìŠ¤í‚µ)
    # - 0.70 ~ 0.90: Sub-sectorë§Œ ìˆ˜í–‰ (GPT ìŠ¤í‚µ, BGE-M3 ì œê±°ë¨)
    # - < 0.70: GPT Deep Validation
    should_use_gpt = use_gpt and GPT_AVAILABLE and llm_handler
    should_use_bge_final = False  # BGE-M3 ì œê±°ë¨ (Solar Embeddingìœ¼ë¡œ í†µí•©)
    
    if should_use_gpt:
        if rule_score >= 0.90:
            # ì¦‰ì‹œ í™•ì • (GPT ìŠ¤í‚µ)
            logger.info(f"[{ticker}] Rule confidence ë§¤ìš° ë†’ìŒ ({rule_score:.2f}) â†’ ì¦‰ì‹œ í™•ì • (GPT ìŠ¤í‚µ)")
            should_use_gpt = False
            should_use_bge_final = False
        elif rule_score >= 0.70:
            # Sub-sectorë§Œ ìˆ˜í–‰ (GPT ìŠ¤í‚µ, BGE-M3 ì œê±°ë¨)
            logger.info(f"[{ticker}] Rule confidence ì¤‘ê°„ ({rule_score:.2f}) â†’ Sub-sectorë§Œ ìˆ˜í–‰ (GPT ìŠ¤í‚µ)")
            should_use_gpt = False
            should_use_bge_final = False
        else:
            # GPT Deep Validation
            logger.info(f"[{ticker}] Rule confidence ë‚®ìŒ ({rule_score:.2f}) â†’ GPT Deep Validation")
            should_use_gpt = True
            should_use_bge_final = False  # BGE-M3 ì œê±°ë¨
    
    # ========================================================================
    # Step 4: GPT ìµœì¢… ê²€ì¦ (ê°€ì¤‘ì¹˜ 10%, ì¡°ê±´ë¶€ ì‚¬ìš©)
    # ========================================================================
    
    # ë³µì¡ë„ ê³„ì‚°
    try:
        is_complex = is_complex_company(company_detail, company_name)
    except Exception:
        is_complex = False
    
    dynamic_weights = get_dynamic_weights(
        rule_conf=rule_conf,
        is_complex=is_complex,
        candidate_count=len(candidates),
        bge_used=should_use_bge_final,
        gpt_used=should_use_gpt
    )

    if not should_use_gpt:
        logger.info(f"[{ticker}] GPT ìµœì¢… ê²€ì¦ ìŠ¤í‚µ")
        # GPT ì—†ì´ BGE-M3 ê²°ê³¼ë¡œ ìµœì¢… ê²°ì • (Step 3.5 Sub-sector ì‚¬ìš©)
        final_sectors = _create_result_from_candidates(
            reranked_candidates,
            rule_major,
            rule_sub,
            rule_vc,
            rule_score,
            max_sectors,
            dynamic_weights
        )
        
        # Step 3.5 Sub-sectorë¥¼ ìµœì¢… ê²°ê³¼ì— ë°˜ì˜
        for fs in final_sectors:
            sector_code = fs.get('major_sector')
            if sector_code and sector_code in sub_sector_final_map:
                fs['sub_sector'] = sub_sector_final_map[sector_code]
                logger.debug(f"[{ticker}] Step 3.5 Sub-sector ë°˜ì˜: {sector_code} â†’ {fs['sub_sector']}")
    else:
        logger.info(f"[{ticker}] Step 4: GPT ìµœì¢… ê²€ì¦ ì‹œì‘")
        
        # â­ Step 4 ì „ìš©: ì „ì²´ ì •ë³´ í¬í•¨ í…ìŠ¤íŠ¸ ì‚¬ìš© (3000ì, ì¸ê³¼ ë¶„ì„ìš©)
        company_text = _prepare_company_text_for_gpt(
            company_detail, 
            company_name
        )
        validated_sectors = validate_sectors_with_gpt(
            company_text,
            company_name,
            reranked_candidates,
            llm_handler,
            max_sectors=max_sectors,
            company_detail=company_detail  # ì¸ê³¼ ë¶„ì„ìš© ì¶”ê°€
        )
        
        if validated_sectors:
            # GPT ê²°ê³¼ë¥¼ ìµœì¢… í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            final_sectors = []
            for vs in validated_sectors:
                sector_code = vs.get('sector')
                if not sector_code:
                    logger.warning(f"[{ticker}] GPT ê²€ì¦ ê²°ê³¼ì— ì„¹í„° ì½”ë“œ ì—†ìŒ: {vs}")
                    continue
                
                # â­ Sub-sector ê²°ì •: Step 3.5 ê²°ê³¼ë§Œ ì‚¬ìš© (GPTëŠ” ë³€ê²½ ë¶ˆê°€)
                # GPTëŠ” ê²€ì¦ ë° ì¸ê³¼ ë¶„ì„ë§Œ ìˆ˜í–‰í•˜ë©°, Sub-sectorë¥¼ ìƒì„±í•˜ê±°ë‚˜ ë³€ê²½í•˜ì§€ ì•ŠìŒ
                sub_sector = (
                    sub_sector_final_map.get(sector_code) or  # Step 3.5 ìµœì¢… í™•ì •ê°’ (ìµœìš°ì„ )
                    next((c.get('sub_sector') for c in reranked_candidates if c.get('sector') == sector_code), None) or  # Fallback: Step 3.5 ê²°ê³¼
                    (rule_sub if rule_major == sector_code else None)  # Fallback: Rule-based
                )
                
                # GPTê°€ Sub-sectorë¥¼ ì œì•ˆí–ˆëŠ”ì§€ í™•ì¸ (ë¡œê¹…ìš©, ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                gpt_suggested_sub = vs.get('sub_sector') or vs.get('sub_sector_suggestion')
                if gpt_suggested_sub and gpt_suggested_sub != sub_sector:
                    logger.debug(f"[{ticker}] GPTê°€ Sub-sector ì œì•ˆ: {gpt_suggested_sub} (ë¬´ì‹œë¨, Step 3.5 ê²°ê³¼ ì‚¬ìš©: {sub_sector})")
                
                # Value Chain ê²°ì • (Rule-based ë˜ëŠ” ê¸°ë³¸ê°’)
                value_chain = rule_vc if rule_major == sector_code else None
                
                # Confidence ê²°ì •
                ensemble_score = (
                    vs.get('embedding_score', 0.0) * dynamic_weights.get('embedding', 0.0) +
                    vs.get('bge_score', 0.0) * dynamic_weights.get('bge', 0.0) +
                    vs.get('gpt_score', 0.0) * dynamic_weights.get('gpt', 0.0) +
                    (rule_score if rule_major == sector_code else 0.0) * dynamic_weights.get('rule', 0.0)
                )
                
                if ensemble_score >= 0.8:
                    confidence = "HIGH"
                elif ensemble_score >= 0.6:
                    confidence = "MEDIUM"
                else:
                    confidence = "LOW"
                
                final_sectors.append({
                    'major_sector': sector_code,
                    'sub_sector': sub_sector,
                    'value_chain': value_chain,
                    'weight': vs.get('weight', 0.5),
                    'is_primary': vs.get('is_primary', False),
                    'confidence': confidence,
                    'method': 'ENSEMBLE',
                    'rule_score': rule_score if rule_major == sector_code else None,
                    'embedding_score': vs.get('embedding_score', 0.0),
                    'bge_score': vs.get('bge_score', 0.0),
                    'gpt_score': vs.get('gpt_score', 0.0),
                    'ensemble_score': ensemble_score,
                    'reasoning': vs.get('reasoning', ''),
                    # â­ ì¸ê³¼ êµ¬ì¡° ë¶„ì„ ê²°ê³¼ (ë ˆë²¨ 2)
                    'causal_structure': vs.get('causal_structure'),
                    'investment_insights': vs.get('investment_insights')
                })
            
            if final_sectors:
                logger.info(f"[{ticker}] GPT ìµœì¢… ê²€ì¦ ì™„ë£Œ: {len(final_sectors)}ê°œ ì„¹í„°")
                
                # ========================================================================
                # Step 4.5: Granular Tags í•„í„°ë§ + Exposure Drivers ì¶”ì¶œ â­
                # ========================================================================
                logger.info(f"[{ticker}] Step 4.5: Granular Tags í•„í„°ë§ ë° Exposure Drivers ì¶”ì¶œ ì‹œì‘")
                
                # ê° ì„¹í„°ë³„ë¡œ Granular Tags í•„í„°ë§ ë° Exposure Drivers ì¶”ì¶œ (Step 3.5 Sub-sector ê¸°ì¤€)
                for fs in final_sectors:
                    sector_code = fs.get('major_sector')
                    sub_sector_code = fs.get('sub_sector')  # â­ Step 3.5ì—ì„œ í™•ì •í•œ Sub-sector
                    causal_structure = fs.get('causal_structure')
                    
                    if sector_code:
                        # â­ Granular Tags í•„í„°ë§
                        if causal_structure and 'granular_tags' in causal_structure:
                            gpt_granular_tags = causal_structure.get('granular_tags', [])
                            filtered_tags = filter_granular_tags_by_sub_sector(
                                gpt_granular_tags,
                                sector_code,
                                sub_sector_code,
                                ticker=ticker  # ë¡œê¹…ìš©
                            )
                            # í•„í„°ë§ëœ íƒœê·¸ë¡œ ì—…ë°ì´íŠ¸
                            causal_structure['granular_tags'] = filtered_tags
                            fs['causal_structure'] = causal_structure
                            
                            if len(filtered_tags) < len(gpt_granular_tags):
                                logger.info(f"[{ticker}] Granular íƒœê·¸ í•„í„°ë§: {len(gpt_granular_tags)}ê°œ â†’ {len(filtered_tags)}ê°œ (Sub-sector: {sub_sector_code})")
                        
                        # â­ Exposure Drivers ë¶„ë¦¬ ì¶”ì¶œ
                        exposure_drivers, supporting_drivers = extract_exposure_drivers(
                            sector_code,
                            sub_sector_code,  # Step 3.5 í™•ì •ê°’ ì „ë‹¬
                            causal_structure,
                            company_detail
                        )
                        
                        if exposure_drivers:
                            fs['exposure_drivers'] = exposure_drivers
                            logger.debug(f"[{ticker}] {sector_code}/{sub_sector_code} â†’ Exposure Drivers: {len(exposure_drivers)}ê°œ (í‘œì¤€ ë“œë¼ì´ë²„)")
                        
                        if supporting_drivers:
                            fs['supporting_drivers'] = supporting_drivers
                            logger.debug(f"[{ticker}] {sector_code} â†’ Supporting Drivers: {len(supporting_drivers)}ê°œ (GPT ì„¤ëª…ìš©)")
            else:
                logger.warning(f"[{ticker}] GPT ê²€ì¦ ê²°ê³¼ ë³€í™˜ ì‹¤íŒ¨. BGE-M3 ê²°ê³¼ ì‚¬ìš©")
                final_sectors = _create_result_from_candidates(
                    reranked_candidates,
                    rule_major,
                    rule_sub,
                    rule_vc,
                    rule_score,
                    max_sectors,
                    dynamic_weights
                )
                
                # Step 3.5 Sub-sectorë¥¼ ìµœì¢… ê²°ê³¼ì— ë°˜ì˜
                for fs in final_sectors:
                    sector_code = fs.get('major_sector')
                    if sector_code and sector_code in sub_sector_final_map:
                        fs['sub_sector'] = sub_sector_final_map[sector_code]
                        logger.debug(f"[{ticker}] Step 3.5 Sub-sector ë°˜ì˜ (ë³€í™˜ ì‹¤íŒ¨ Fallback): {sector_code} â†’ {fs['sub_sector']}")
        else:
            # GPT ê²€ì¦ ì‹¤íŒ¨ ì‹œ Fallback (Step 3.5 Sub-sector ì‚¬ìš©)
            logger.warning(f"[{ticker}] GPT ê²€ì¦ ì‹¤íŒ¨. BGE-M3 ê²°ê³¼ ì‚¬ìš©")
            final_sectors = _create_result_from_candidates(
                reranked_candidates,
                rule_major,
                rule_sub,
                rule_vc,
                rule_score,
                max_sectors,
                dynamic_weights
            )
            
            # Step 3.5 Sub-sectorë¥¼ ìµœì¢… ê²°ê³¼ì— ë°˜ì˜
            for fs in final_sectors:
                sector_code = fs.get('major_sector')
                if sector_code and sector_code in sub_sector_final_map:
                    fs['sub_sector'] = sub_sector_final_map[sector_code]
                    logger.debug(f"[{ticker}] Step 3.5 Sub-sector ë°˜ì˜ (Fallback): {sector_code} â†’ {fs['sub_sector']}")
    
    # ìµœì¢… ê²°ê³¼ ê²€ì¦ ë° NULL ì„¹í„° êµ¬ì¶œ
    if not final_sectors:
        logger.error(f"[{ticker}] ìµœì¢… ì„¹í„° ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
        
        # Fallback 1: Rule-based ê²°ê³¼ ì‚¬ìš©
        if rule_major:
            logger.warning(f"[{ticker}] Rule-based ê²°ê³¼ë¥¼ ìµœì¢… ê²°ê³¼ë¡œ ì‚¬ìš©")
            fallback_result = [{
                'major_sector': rule_major,
                'sub_sector': rule_sub,
                'value_chain': rule_vc,
                'sector_l1': rule_major,
                'sector_l2': rule_sub,
                'weight': 1.0,
                'is_primary': True,
                'confidence': rule_conf,
                'method': 'RULE_BASED',
                'fallback_used': 'TRUE',  # â­ Fallback ì‚¬ìš© ì—¬ë¶€ (VARCHARì— ë¬¸ìì—´ ì €ì¥)
                'fallback_type': 'RULE',  # â­ Fallback íƒ€ì…
                'rule_score': rule_score,
                'ensemble_score': rule_score,
                'reasoning': 'Rule-based ë¶„ë¥˜ (Fallback)',
                'boosting_log': boosting_info  # Boosting ë¡œê·¸ í¬í•¨
            }]
            return fallback_result
        
        # Fallback 2: Candidatesì—ì„œ Top-1 ì‚¬ìš© (Ensemble Score 0.3 ì´ìƒ)
        if candidates and len(candidates) > 0:
            top_candidate = candidates[0]
            top_score = top_candidate.get('score', 0.0)
            
            if top_score >= 0.3:  # ìµœì†Œ ì„ê³„ê°’
                logger.warning(f"[{ticker}] Candidates Top-1ì„ ìµœì¢… ê²°ê³¼ë¡œ ì‚¬ìš© (score: {top_score:.3f}, VERY_LOW confidence)")
                fallback_result = [{
                    'major_sector': top_candidate.get('sector'),
                    'sub_sector': None,
                    'value_chain': None,
                    'sector_l1': top_candidate.get('sector'),
                    'sector_l2': None,
                    'weight': 1.0,
                    'is_primary': True,
                    'confidence': 'VERY_LOW',  # â­ ìƒˆë¡œìš´ confidence ë ˆë²¨
                    'method': 'ENSEMBLE_FALLBACK',
                    'fallback_used': 'TRUE',  # â­ Fallback ì‚¬ìš© ì—¬ë¶€ (VARCHARì— ë¬¸ìì—´ ì €ì¥)
                    'fallback_type': 'TOP1',  # â­ Fallback íƒ€ì…
                    'rule_score': None,
                    'embedding_score': top_score,
                    'ensemble_score': top_score,
                    'reasoning': f'Ensemble Fallback: Top-1 candidate (score: {top_score:.3f})',
                    'boosting_log': boosting_info
                }]
                return fallback_result
        
        # Fallback 3: KRX ì„¹í„° ì‚¬ìš©
        if krx_major:
            logger.warning(f"[{ticker}] KRX ì„¹í„°ë¥¼ ìµœì¢… ê²°ê³¼ë¡œ ì‚¬ìš© (VERY_LOW confidence)")
            fallback_result = [{
                'major_sector': krx_major,
                'sub_sector': krx_sub,
                'value_chain': None,
                'sector_l1': krx_major,
                'sector_l2': krx_sub,
                'weight': 1.0,
                'is_primary': True,
                'confidence': 'VERY_LOW',
                'method': 'KRX_FALLBACK',
                'fallback_used': 'TRUE',  # â­ Fallback ì‚¬ìš© ì—¬ë¶€ (VARCHARì— ë¬¸ìì—´ ì €ì¥)
                'fallback_type': 'KRX',  # â­ Fallback íƒ€ì…
                'rule_score': None,
                'ensemble_score': 0.3,  # ê¸°ë³¸ê°’
                'reasoning': f'KRX ì„¹í„° Fallback: {krx_major}/{krx_sub}',
                'boosting_log': boosting_info
            }]
            return fallback_result
        
        # ìµœì¢… Fallback: ì¼ë°˜ì ì¸ ì„¹í„° í• ë‹¹ (UNKNOWN)
        logger.error(f"[{ticker}] ëª¨ë“  Fallback ì‹¤íŒ¨, UNKNOWN ì„¹í„° í• ë‹¹")
        return [{
            'major_sector': 'SEC_UNKNOWN',
            'sub_sector': None,
            'value_chain': None,
            'sector_l1': 'SEC_UNKNOWN',
            'sector_l2': None,
            'weight': 1.0,
            'is_primary': True,
            'confidence': 'VERY_LOW',
            'method': 'FALLBACK_UNKNOWN',
            'fallback_used': 'TRUE',  # â­ Fallback ì‚¬ìš© ì—¬ë¶€ (VARCHARì— ë¬¸ìì—´ ì €ì¥)
            'fallback_type': 'UNKNOWN',  # â­ Fallback íƒ€ì…
            'rule_score': None,
            'ensemble_score': 0.0,
            'reasoning': 'ëª¨ë“  ë¶„ë¥˜ ë°©ë²• ì‹¤íŒ¨, UNKNOWN ì„¹í„° í• ë‹¹',
            'boosting_log': boosting_info
        }]
    
    # â­ NEW: final_sectorsê°€ ìˆì§€ë§Œ NULL ì„¹í„°ì¸ ê²½ìš° ì²˜ë¦¬
    if final_sectors and len(final_sectors) > 0:
        primary_result = next((r for r in final_sectors if r.get('is_primary')), final_sectors[0])
        
        # â­ í•µì‹¬: sector_l1ì´ NULLì´ë©´ ê°•ì œ Fallback
        if not primary_result.get('sector_l1') and not primary_result.get('major_sector'):
            logger.warning(f"[{ticker}] âš ï¸ Primary ì„¹í„°ê°€ NULL, ê°•ì œ Fallback ì‹¤í–‰")
            
            # í™•ì •ì  ê·œì¹™ ì ìš©
            primary_result['sector_l1'] = 'SEC_UNKNOWN'
            primary_result['major_sector'] = 'SEC_UNKNOWN'
            primary_result['fallback_used'] = 'TRUE'  # â­ VARCHARì— ë¬¸ìì—´ ì €ì¥
            primary_result['fallback_type'] = 'UNKNOWN'  # â­ íƒ€ì… ë¶„ë¦¬
            primary_result['confidence'] = 'VERY_LOW'
            primary_result['method'] = 'FALLBACK_UNKNOWN'
            primary_result['ensemble_score'] = 0.0
            primary_result['reasoning'] = 'NULL ì„¹í„° ê°ì§€, UNKNOWN í• ë‹¹'
            
            logger.info(f"[{ticker}] âœ… NULL ì„¹í„° â†’ SEC_UNKNOWN í• ë‹¹ ì™„ë£Œ")
    
    # Boosting ë¡œê·¸ë¥¼ ì²« ë²ˆì§¸ ì„¹í„°ì— ì¶”ê°€ (ë©”íƒ€ë°ì´í„°)
    if final_sectors and boosting_info:
        final_sectors[0]['boosting_log'] = boosting_info
        logger.info(
            f"[{ticker}] Boosting ë¡œê·¸: "
            f"anchor_applied={boosting_info.get('anchor_applied')}, "
            f"kg_applied={boosting_info.get('kg_applied')}, "
            f"multiplier={boosting_info.get('multiplier'):.2f}, "
            f"final_boost={boosting_info.get('final_boost'):.3f}, "
            f"reason={boosting_info.get('reason')}"
        )
    
    return final_sectors
    
    # Boosting ë¡œê·¸ë¥¼ ì²« ë²ˆì§¸ ì„¹í„°ì— ì¶”ê°€ (ë©”íƒ€ë°ì´í„°)
    if final_sectors and boosting_info:
        final_sectors[0]['boosting_log'] = boosting_info
        logger.info(
            f"[{ticker}] Boosting ë¡œê·¸: "
            f"anchor_applied={boosting_info.get('anchor_applied')}, "
            f"kg_applied={boosting_info.get('kg_applied')}, "
            f"multiplier={boosting_info.get('multiplier'):.2f}, "
            f"final_boost={boosting_info.get('final_boost'):.3f}, "
            f"reason={boosting_info.get('reason')}"
        )
    
    return final_sectors


def filter_granular_tags_by_sub_sector(
    granular_tags: List[str],
    major_sector: str,
    sub_sector: Optional[str],
    ticker: Optional[str] = None  # ë¡œê¹…ìš© (ì„ íƒì )
) -> List[str]:
    """
    GPTê°€ ìƒì„±í•œ granular_tagsë¥¼ Sub-sector ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§
    
    â­ ì¤‘ìš”: Sub-sectorì™€ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” íƒœê·¸ëŠ” ì œê±°í•˜ì—¬ ë…¼ë¦¬ ì¶©ëŒ ë°©ì§€
    
    Args:
        granular_tags: GPTê°€ ìƒì„±í•œ íƒœê·¸ ë¦¬ìŠ¤íŠ¸
        major_sector: Major Sector ì½”ë“œ
        sub_sector: Step 3.5ì—ì„œ í™•ì •í•œ Sub-sector ì½”ë“œ
        ticker: ì¢…ëª©ì½”ë“œ (ë¡œê¹…ìš©, ì„ íƒì )
    
    Returns:
        í•„í„°ë§ëœ íƒœê·¸ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 5ê°œ)
    """
    from app.models.sector_reference import SUB_SECTOR_DEFINITIONS
    
    if not granular_tags or not sub_sector:
        return []
    
    # Sub-sectorì˜ keywordsë¥¼ ê¸°ë°˜ìœ¼ë¡œ í—ˆìš© íƒœê·¸ ìƒì„±
    allowed_keywords = []
    if major_sector in SUB_SECTOR_DEFINITIONS:
        if sub_sector in SUB_SECTOR_DEFINITIONS[major_sector]:
            sub_def = SUB_SECTOR_DEFINITIONS[major_sector][sub_sector]
            # keywordsë¥¼ íƒœê·¸ë¡œ ì‚¬ìš© (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            allowed_keywords = [k.upper() for k in sub_def.get('keywords', [])]
    
    # GPT íƒœê·¸ë¥¼ í—ˆìš© íƒœê·¸ì™€ ë§¤ì¹­ (ë¶€ë¶„ ë§¤ì¹­)
    filtered_tags = []
    for tag in granular_tags:
        tag_upper = str(tag).upper()
        # í—ˆìš© íƒœê·¸ì™€ ë¶€ë¶„ ë§¤ì¹­ í™•ì¸
        matched = False
        for allowed in allowed_keywords:
            if allowed in tag_upper or tag_upper in allowed:
                filtered_tags.append(tag)
                matched = True
                break
        
        # ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ë¡œê¹… (ë””ë²„ê¹…ìš©)
        if not matched and ticker:
            logger.debug(f"[{ticker}] Granular íƒœê·¸ í•„í„°ë§ë¨: '{tag}' (Sub-sector: {sub_sector}ì™€ ë¶ˆì¼ì¹˜)")
    
    return filtered_tags[:5]  # ìµœëŒ€ 5ê°œë¡œ ì œí•œ


def extract_exposure_drivers(
    sector_code: str,
    sub_sector_code: Optional[str],  # â­ Step 3.5ì—ì„œ í™•ì •í•œ Sub-sector
    causal_structure: Optional[Dict],
    company_detail: CompanyDetail
) -> Tuple[List[Dict], List[Dict]]:
    """
    ì„¹í„°ì˜ í‘œì¤€ ë“œë¼ì´ë²„ì™€ GPT ê²°ê³¼ë¥¼ ë¶„ë¦¬í•˜ì—¬ ë°˜í™˜
    
    â­ ì¤‘ìš”: í‘œì¤€ ë“œë¼ì´ë²„ì™€ GPT ì„¤ëª…ìš© ë“œë¼ì´ë²„ë¥¼ ë¶„ë¦¬
    - exposure_drivers: í‘œì¤€ ë“œë¼ì´ë²„ë§Œ (ì •í™•í•œ ê²½ì œ ë³€ìˆ˜)
    - supporting_drivers: GPT ì„¤ëª…ìš© (ì¼ë°˜ì ì¸ ì„¤ëª…)
    
    Args:
        sector_code: Major Sector ì½”ë“œ
        sub_sector_code: Step 3.5ì—ì„œ í™•ì •í•œ Sub-sector ì½”ë“œ
        causal_structure: GPTê°€ ìƒì„±í•œ causal_structure (key_drivers í¬í•¨, ì„¤ëª…ìš©)
        company_detail: CompanyDetail ê°ì²´
    
    Returns:
        (exposure_drivers: í‘œì¤€ ë“œë¼ì´ë²„, supporting_drivers: GPT ì„¤ëª…ìš©)
    """
    from app.models.sector_reference import (
        SUB_SECTOR_DEFINITIONS,
        ECONVAR_MASTER
    )
    
    exposure_drivers = []  # â­ í‘œì¤€ ë“œë¼ì´ë²„ë§Œ
    supporting_drivers = []  # â­ GPT ì„¤ëª…ìš©
    
    # 1. â­ Step 3.5ì—ì„œ í™•ì •í•œ Sub-sectorì˜ í‘œì¤€ ë“œë¼ì´ë²„ë§Œ ìˆ˜ì§‘
    standard_drivers = []
    if sector_code in SUB_SECTOR_DEFINITIONS:
        if sub_sector_code and sub_sector_code in SUB_SECTOR_DEFINITIONS[sector_code]:
            # Step 3.5 í™•ì • Sub-sectorì˜ ë“œë¼ì´ë²„ë§Œ ì‚¬ìš©
            sub_def = SUB_SECTOR_DEFINITIONS[sector_code][sub_sector_code]
            drivers = sub_def.get('drivers', [])
            for driver_code in drivers:
                if driver_code not in standard_drivers:
                    standard_drivers.append(driver_code)
            
            # â­ í‘œì¤€ ë“œë¼ì´ë²„ë¥¼ exposure_driversì— ì¶”ê°€
            for driver_code in standard_drivers:
                econvar_info = ECONVAR_MASTER.get(driver_code, {})
                exposure_drivers.append({
                    'var': econvar_info.get('display_name', driver_code),
                    'code': driver_code,
                    'type': econvar_info.get('type', ''),
                    'description': econvar_info.get('description', '')
                })
            
            logger.debug(f"Step 3.5 Sub-sector ê¸°ì¤€ í‘œì¤€ ë“œë¼ì´ë²„: {sub_sector_code} â†’ {len(exposure_drivers)}ê°œ")
        else:
            # Sub-sectorê°€ ì—†ìœ¼ë©´ Major Sectorì˜ ëª¨ë“  Sub-sector ë“œë¼ì´ë²„ ìˆ˜ì§‘
            for sub_code, sub_def in SUB_SECTOR_DEFINITIONS[sector_code].items():
                drivers = sub_def.get('drivers', [])
                for driver_code in drivers:
                    if driver_code not in standard_drivers:
                        standard_drivers.append(driver_code)
            
            # í‘œì¤€ ë“œë¼ì´ë²„ ì¶”ê°€
            for driver_code in standard_drivers:
                econvar_info = ECONVAR_MASTER.get(driver_code, {})
                exposure_drivers.append({
                    'var': econvar_info.get('display_name', driver_code),
                    'code': driver_code,
                    'type': econvar_info.get('type', ''),
                    'description': econvar_info.get('description', '')
                })
    
    # 2. GPTì˜ key_drivers ê°€ì ¸ì˜¤ê¸° (ì„¤ëª…ìš©ìœ¼ë¡œë§Œ)
    gpt_drivers = []
    if causal_structure:
        gpt_drivers = causal_structure.get('key_drivers', [])
    
    # 3. GPT ë“œë¼ì´ë²„ë¥¼ í‘œì¤€ ë“œë¼ì´ë²„ì™€ ë§¤ì¹­
    for gpt_driver in gpt_drivers:
        var_name = gpt_driver.get('var', '')
        var_type = gpt_driver.get('type', '')
        description = gpt_driver.get('description', '')
        
        # í‘œì¤€ ë“œë¼ì´ë²„ ì½”ë“œ ì°¾ê¸° (ë¶€ë¶„ ë§¤ì¹­)
        matched_code = None
        for std_code in standard_drivers:
            std_code_normalized = std_code.replace('_', ' ').upper()
            var_name_normalized = var_name.upper()
            if std_code_normalized in var_name_normalized or \
               var_name_normalized in std_code_normalized:
                matched_code = std_code
                break
        
        if matched_code:
            # â­ í‘œì¤€ ë“œë¼ì´ë²„ì™€ ë§¤ì¹­ë˜ë©´ exposure_driversì˜ descriptionë§Œ ì—…ë°ì´íŠ¸
            for ed in exposure_drivers:
                if ed['code'] == matched_code:
                    # GPT descriptionì´ ë” êµ¬ì²´ì ì´ë©´ ì—…ë°ì´íŠ¸
                    if description and len(description) > len(ed.get('description', '')):
                        ed['description'] = description
                    break
        else:
            # â­ í‘œì¤€ ë“œë¼ì´ë²„ì™€ ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ supporting_driversì— ì¶”ê°€
            supporting_drivers.append({
                'var': var_name,
                'type': var_type,
                'description': description
            })
    
    return exposure_drivers, supporting_drivers


def _create_result_from_candidates(
    candidates: List[Dict[str, float]],
    rule_major: Optional[str],
    rule_sub: Optional[str],
    rule_vc: Optional[str],
    rule_score: float,
    max_sectors: int,
    weights: Dict[str, float]
) -> List[Dict[str, Any]]:
    """
    í›„ë³´ ê²°ê³¼ë¡œë¶€í„° ìµœì¢… ê²°ê³¼ ìƒì„± (GPT ì—†ì´)
    
    Args:
        candidates: BGE-M3 Re-ranking ê²°ê³¼
        rule_major: Rule-based ì„¹í„°
        rule_sub: Rule-based Sub-sector
        rule_vc: Rule-based Value Chain
        rule_score: Rule-based ì ìˆ˜
        max_sectors: ìµœëŒ€ ì„¹í„° ê°œìˆ˜
    
    Returns:
        ìµœì¢… ì„¹í„° ë¦¬ìŠ¤íŠ¸
    """
    if not candidates:
        return []
    
    results = []
    total_score = sum(c.get('bge_score', c.get('score', 0.0)) for c in candidates[:max_sectors])
    
    for i, candidate in enumerate(candidates[:max_sectors]):
        sector_code = candidate['sector']
        bge_score = candidate.get('bge_score', candidate.get('score', 0.0))
        embedding_score = candidate.get('score', 0.0)
        
        weight = bge_score / total_score if total_score > 0 else 1.0 / len(candidates[:max_sectors])
        
        # Ensemble ì ìˆ˜ ê³„ì‚°
        ensemble_score = (
            embedding_score * weights.get('embedding', 0.0) +
            bge_score * weights.get('bge', 0.0) +
            (rule_score if rule_major == sector_code else 0.0) * weights.get('rule', 0.0)
        )
        
        if ensemble_score >= 0.8:
            confidence = "HIGH"
        elif ensemble_score >= 0.6:
            confidence = "MEDIUM"
        else:
            confidence = "LOW"
        
        results.append({
            'major_sector': sector_code,
            'sub_sector': rule_sub if rule_major == sector_code else None,
            'value_chain': rule_vc if rule_major == sector_code else None,
            'weight': float(weight),
            'is_primary': (i == 0),
            'confidence': confidence,
            'method': 'ENSEMBLE',
            'rule_score': rule_score if rule_major == sector_code else None,
            'embedding_score': embedding_score,
            'bge_score': bge_score,
            'gpt_score': None,
            'ensemble_score': ensemble_score,
            'reasoning': f'GPT ê²€ì¦ ì—†ì´ BGE-M3 + ì„ë² ë”© ëª¨ë¸ ê²°ê³¼ ì‚¬ìš©'
        })
    
    return results

