"""
Gemini-Reasoning ê¸°ë°˜ ì„¹í„° ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸

Step 0-3.5: ê¸°ì¡´ ë°©ì‹ ìœ ì§€ (Rule + Embedding + Sub-sector)
Step 4A: KF-DeBERTa Driver Signal Extraction
Step 4B: Gemini-Reasoning Industrial Graph (EXAONE/WON ëŒ€ì²´)
Step 4.5: Exposure Drivers ì¶”ì¶œ

LLM: Gemini APIë¡œ ì „í™˜ ì™„ë£Œ
"""
import logging
from typing import Optional, Dict, Any, List
from sqlalchemy.orm import Session
import time

logger = logging.getLogger(__name__)

# ê¸°ì¡´ ensemble ë¡œì§ ì¬ì‚¬ìš© (Step 0-3.5)
from app.services.sector_classifier_ensemble import (
    classify_sector_ensemble as _classify_sector_ensemble_base,
    apply_anchor_boosting,
    apply_kg_edge_boosting,
    filter_granular_tags_by_sub_sector,
    extract_exposure_drivers
)

# Gemini-Reasoning ë° Signal Extractor
from app.services.gemini_handler import GeminiHandler, get_gemini_handler
from app.services.sentence_signal_extractor import extract_driver_signals_from_sentences
from app.services.l3_tag_enricher import enrich_l3_tags_from_company_detail
from app.services.driver_tag_enricher import enrich_driver_tags, enrich_driver_tags_with_supersession
from app.services.kg_edge_builder import build_edges_from_causal_structure, save_edges_to_db
from app.services.holding_company_classifier import classify_holding_with_multi_sector
from app.services.reit_classifier import classify_reit_with_multi_sector
from app.services.spac_classifier import classify_spac
from app.services.primary_sector_determiner import apply_primary_sector_flags

# ê¸°ì¡´ ëª¨ë¸ë“¤
from app.models.company_detail import CompanyDetail
from app.models.stock import Stock
from app.models.investor_sector import InvestorSector  # â­ ê¸°ì¡´ íƒœê·¸ ì¡°íšŒìš©
from app.models.sector_reference import (
    SUB_SECTOR_DEFINITIONS,
    classify_l2_by_rule,  # â­ L2 ê·œì¹™ ë¶„ë¥˜
    get_l2_split_type,    # â­ L2 ë¶„ë¦¬ íƒ€ì… í™•ì¸
    ANALYSIS_STATE        # â­ ë¶„ì„ ìƒíƒœ ìƒìˆ˜
)
# ECONVAR_MASTERëŠ” í•„ìš”ì‹œ ë³„ë„ import (í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)


def classify_manufacturing_vs_distribution(
    company_detail: CompanyDetail
) -> Optional[str]:
    """
    ì œì¡° vs ìœ í†µ êµ¬ë¶„
    
    Returns:
        'DISTRIBUTION', 'MANUFACTURING', ë˜ëŠ” None
    """
    text = (company_detail.biz_summary or "").lower()
    
    # ìœ í†µ í‚¤ì›Œë“œ
    distribution_keywords = [
        'ìœ í†µ', 'ìˆ˜ì…', 'ìˆ˜ì¶œ', 'íŒë§¤', 'ë„ë§¤', 'ì†Œë§¤',
        'import', 'export', 'distribution', 'retail'
    ]
    
    # ì œì¡° í‚¤ì›Œë“œ
    manufacturing_keywords = [
        'ì œì¡°', 'ìƒì‚°', 'ê³µì¥', 'ì œì‘', 'manufacturing', 'production'
    ]
    
    dist_score = sum(1 for kw in distribution_keywords if kw in text)
    mfg_score = sum(1 for kw in manufacturing_keywords if kw in text)
    
    if dist_score > mfg_score and dist_score >= 2:
        return 'DISTRIBUTION'
    elif mfg_score > dist_score and mfg_score >= 2:
        return 'MANUFACTURING'
    
    return None

logger.info("Gemini-Reasoning ê¸°ë°˜ ì„¹í„° ë¶„ë¥˜ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")


def classify_sector_ensemble_won(
    db: Session,
    ticker: str,
    gemini_handler: Optional[GeminiHandler] = None,
    use_embedding: bool = True,
    use_reranking: bool = True,
    max_sectors: int = 3,
    force_reclassify: bool = False  # SPAC ì¬ë¶„ë¥˜ìš© í”Œë˜ê·¸
) -> Optional[List[Dict[str, Any]]]:
    """
    Gemini-Reasoning ê¸°ë°˜ ì„¹í„° ë¶„ë¥˜ (ë¡œì»¬ LLM â†’ Gemini API ì „í™˜ ì™„ë£Œ)
    
    í”„ë¡œì„¸ìŠ¤:
    1. Step 0-3.5: ê¸°ì¡´ ensemble ë°©ì‹ (Rule + Embedding + BGE + Sub-sector)
    2. Step 4A: KF-DeBERTa ë¬¸ì¥ ê¸°ë°˜ ë“œë¼ì´ë²„ ì‹œê·¸ë„ ì¶”ì¶œ
    3. Step 4B: Gemini-Reasoning ì¸ê³¼ êµ¬ì¡° ìƒì„± (ë¡œì»¬ LLM ëŒ€ì²´)
    4. Step 4C: GPT Style Polishing (ë¹„í™œì„±í™”)
    5. Step 4.5: Exposure Drivers ì¶”ì¶œ
    
    Args:
        db: DB ì„¸ì…˜
        ticker: ì¢…ëª©ì½”ë“œ
        gemini_handler: GeminiHandler ê°ì²´ (Noneì´ë©´ ìë™ ìƒì„±)
        use_embedding: ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
        use_reranking: BGE-M3 Re-ranking ì‚¬ìš© ì—¬ë¶€
        max_sectors: ìµœëŒ€ ì„¹í„° ê°œìˆ˜
    
    Returns:
        ì„¹í„° ë¶„ë¥˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    # CompanyDetail ì¡°íšŒ
    company_detail = db.query(CompanyDetail).filter(
        CompanyDetail.ticker == ticker
    ).first()
    
    if not company_detail:
        logger.warning(f"[{ticker}] CompanyDetail ë°ì´í„° ì—†ìŒ")
        return None
    
    from app.utils.stock_query import get_stock_by_ticker_safe
    stock = get_stock_by_ticker_safe(db, ticker)
    company_name = stock.stock_name if stock else None
    
    # Step 0.0: SPAC ì—¬ë¶€ í™•ì¸ (ì„¹í„° ë¶„ë¥˜ ì „ì— í•„í„°ë§)
    # force_reclassifyê°€ Trueì´ë©´ SPAC ì²´í¬ ê±´ë„ˆëœ€ (ì¬ë¶„ë¥˜ ì‹œ)
    if stock and not force_reclassify:
        spac_result = classify_spac(stock, company_detail)
        if spac_result.get('is_spac'):
            spac_status = spac_result.get('status')
            logger.info(f"[{ticker}] âš ï¸ SPAC ê°ì§€: ìƒíƒœ={spac_status}, ì˜ˆìƒì„¹í„°={spac_result.get('expected_sector')}")
            
            # POST_MERGER ìƒíƒœì¸ ê²½ìš° ì„¹í„° ë¶„ë¥˜ ì§„í–‰
            if spac_status == 'POST_MERGER':
                logger.info(f"[{ticker}] â„¹ï¸ POST_MERGER SPAC: ì„¹í„° ë¶„ë¥˜ ì§„í–‰ (í•©ë³‘ ì™„ë£Œ)")
                # SPAC í•„í„°ë§ ê±´ë„ˆë›°ê³  ì¼ë°˜ íŒŒì´í”„ë¼ì¸ ì§„í–‰
            else:
                # PRE_MERGER ë˜ëŠ” TARGET_ANNOUNCED: SPAC ì „ìš© ì¸ì‚¬ì´íŠ¸ ë°˜í™˜
                logger.info(f"[{ticker}] â„¹ï¸ SPACì€ ì„¹í„° ë¶„ë¥˜ ëŒ€ìƒì´ ì•„ë‹™ë‹ˆë‹¤. ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return [{
                    'major_sector': None,
                    'sector_l1': None,
                    'company_type': 'SPAC',
                    'spac_status': spac_status,
                    'expected_sector': spac_result.get('expected_sector'),
                    'classification_method': 'RULE_BASED_SPAC',
                    'rule_version': 'v1.0',  # Rule ë²„ì „
                    'rule_confidence': spac_result.get('confidence', 0.5),  # Rule ì‹ ë¢°ë„
                    'training_label': spac_result.get('confidence', 0.5) >= 0.7,  # í•™ìŠµìš© ë¼ë²¨ (ì‹ ë¢°ë„ 0.7 ì´ìƒ)
                    'classification_reasoning': f"SPAC ê°ì§€: {', '.join(spac_result.get('evidence', []))}",
                    'insight': 'SPACì€ í•©ë³‘ ì „ ë‹¨ê³„ë¡œ, ì‹¤ì œ ì‚¬ì—… ë‚´ìš©ì´ ì—†ì–´ ì„¹í„° ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.',
                    'confidence': spac_result.get('confidence', 0.5),
                }]
    
    # â­ Step 0-3.4: ì„ë² ë”© ê°•ì œ ìƒì„± (ë¶„ë¥˜ ì„±ê³µ ì—¬ë¶€ì™€ ìƒê´€ì—†ì´)
    # í–¥í›„ ë°¸ë¥˜ì²´ì¸ ë¶„ì„ì„ ìœ„í•´ ëª¨ë“  ê¸°ì—…ì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ì €ì¥
    try:
        from app.services.solar_embedding_model import get_or_create_embedding, prepare_company_text_for_solar
        
        embedding_start = time.time()
        logger.info(f"[{ticker}] ğŸ”„ Step 0-3.4: ì„ë² ë”© ê°•ì œ ìƒì„± ì‹œì‘ (ë°¸ë¥˜ì²´ì¸ ë¶„ì„ìš©)")
        
        # íšŒì‚¬ í…ìŠ¤íŠ¸ ì¤€ë¹„
        company_text = prepare_company_text_for_solar(company_detail, company_name)
        
        # ì„ë² ë”© ìƒì„± ë˜ëŠ” ì¡°íšŒ (ì´ë¯¸ ìˆìœ¼ë©´ ìŠ¤í‚µ)
        embedding = get_or_create_embedding(
            db=db,
            ticker=ticker,
            text=company_text,
            force_regenerate=False  # ì´ë¯¸ ìˆìœ¼ë©´ ì¬ìƒì„± ì•ˆ í•¨
        )
        
        if embedding is not None:
            embedding_time = time.time() - embedding_start
            logger.info(f"[{ticker}] âœ… ì„ë² ë”© ìƒì„±/ì¡°íšŒ ì™„ë£Œ ({embedding_time:.2f}ì´ˆ, ë²¡í„° DB ì €ì¥ë¨)")
        else:
            embedding_time = time.time() - embedding_start
            logger.warning(f"[{ticker}] âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ ({embedding_time:.2f}ì´ˆ, Rule-basedë¡œ ì§„í–‰)")
    except Exception as e:
        logger.warning(f"[{ticker}] âš ï¸ ì„ë² ë”© ê°•ì œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ê°€ ìˆì–´ë„ ë¶„ë¥˜ëŠ” ê³„ì† ì§„í–‰
    
    # Step 0-3.5: ê¸°ì¡´ ensemble ë°©ì‹ ì‚¬ìš© (GPT ì—†ì´)
    # use_gpt=Falseë¡œ ì„¤ì •í•˜ì—¬ Step 4ë¥¼ ìŠ¤í‚µí•˜ê³  Step 3.5ê¹Œì§€ë§Œ ìˆ˜í–‰
    step035_start = time.time()
    logger.info(f"[{ticker}] ğŸ”„ Step 0-3.5: ê¸°ì¡´ Ensemble ë°©ì‹ ì‹œì‘ (GPT ì—†ì´)")
    
    base_results = _classify_sector_ensemble_base(
        db=db,
        ticker=ticker,
        llm_handler=None,  # GPT ì‚¬ìš© ì•ˆ í•¨
        use_gpt=False,  # GPT ë¹„í™œì„±í™”
        use_embedding=use_embedding,
        use_reranking=use_reranking,
        max_sectors=max_sectors
    )
    
    step035_time = time.time() - step035_start
    if not base_results:
        logger.warning(f"[{ticker}] âŒ Step 0-3.5 ê²°ê³¼ ì—†ìŒ ({step035_time:.2f}ì´ˆ)")
        return None
    
    logger.info(f"[{ticker}] âœ… Step 0-3.5 ì™„ë£Œ: {len(base_results)}ê°œ ì„¹í„° ({step035_time:.2f}ì´ˆ)")
    
    # Step 0.5: ì§€ì£¼ì‚¬ ìë™ ë¶„ë¥˜ (Multi-sector ì§€ì›)
    if stock:
        holding_start = time.time()
        logger.info(f"[{ticker}] ğŸ”„ Step 0.5: ì§€ì£¼ì‚¬ ìë™ ë¶„ë¥˜ ì‹œì‘")
        
        existing_sectors = [r.get('major_sector') for r in base_results if r.get('major_sector')]
        holding_result = classify_holding_with_multi_sector(
            stock=stock,
            company_detail=company_detail,
            existing_sectors=existing_sectors
        )
        
        if holding_result.get('is_holding'):
            # ì§€ì£¼ì‚¬ ì„¹í„° ì¶”ê°€
            holding_sector = {
                'major_sector': 'SEC_HOLDING',
                'sub_sector': holding_result.get('l2_sector', 'GENERAL_HOLDING'),
                'sector_l1': 'SEC_HOLDING',
                'sector_l2': holding_result.get('l2_sector', 'GENERAL_HOLDING'),
                'confidence': holding_result.get('confidence', 0.5),
                'classification_method': 'RULE_BASED_HOLDING',
                'rule_version': 'v1.0',  # Rule ë²„ì „
                'rule_confidence': holding_result.get('confidence', 0.5),  # Rule ì‹ ë¢°ë„
                'training_label': holding_result.get('confidence', 0.5) >= 0.7,  # í•™ìŠµìš© ë¼ë²¨ (ì‹ ë¢°ë„ 0.7 ì´ìƒ)
                'classification_reasoning': f"ì§€ì£¼ì‚¬ ìë™ ë¶„ë¥˜: {', '.join(holding_result.get('evidence', []))}",
                'is_primary': False,  # Multi-sectorì´ë¯€ë¡œ primaryëŠ” ê¸°ì¡´ ì„¹í„° ìœ ì§€
                'sector_weight': 0.3 if holding_result.get('multi_sector') else 0.5,
            }
            base_results.append(holding_sector)
            holding_time = time.time() - holding_start
            logger.info(f"[{ticker}] âœ… ì§€ì£¼ì‚¬ ë¶„ë¥˜ ì™„ë£Œ: {holding_result.get('l2_sector')} (ì‹ ë¢°ë„: {holding_result.get('confidence', 0):.2f}, {holding_time:.2f}ì´ˆ)")
            if holding_result.get('multi_sector'):
                logger.info(f"[{ticker}] â„¹ï¸ Multi-sector: ì§€ì£¼ì‚¬ + {', '.join(existing_sectors)}")
    
    # Step 0.6: ë¦¬ì¸ (REITs) ìë™ ë¶„ë¥˜ (Multi-sector ì§€ì›)
    if stock:
        reit_start = time.time()
        logger.info(f"[{ticker}] ğŸ”„ Step 0.6: ë¦¬ì¸  ìë™ ë¶„ë¥˜ ì‹œì‘")
        
        existing_sectors_after_holding = [r.get('major_sector') for r in base_results if r.get('major_sector')]
        reit_result = classify_reit_with_multi_sector(
            stock=stock,
            company_detail=company_detail,
            existing_sectors=existing_sectors_after_holding
        )
        
        if reit_result.get('is_reit'):
            # ë¦¬ì¸  ì„¹í„° ì¶”ê°€
            reit_sector = {
                'major_sector': 'SEC_REIT',
                'sub_sector': reit_result.get('l2_sector', 'COMMERCIAL_REIT'),
                'sector_l1': 'SEC_REIT',
                'sector_l2': reit_result.get('l2_sector', 'COMMERCIAL_REIT'),
                'confidence': reit_result.get('confidence', 0.5),
                'classification_method': 'RULE_BASED_REIT',
                'rule_version': 'v1.0',  # Rule ë²„ì „
                'rule_confidence': reit_result.get('confidence', 0.5),  # Rule ì‹ ë¢°ë„
                'training_label': reit_result.get('confidence', 0.5) >= 0.7,  # í•™ìŠµìš© ë¼ë²¨ (ì‹ ë¢°ë„ 0.7 ì´ìƒ)
                'classification_reasoning': f"ë¦¬ì¸  ìë™ ë¶„ë¥˜: {', '.join(reit_result.get('evidence', []))}",
                'is_primary': False,  # Multi-sectorì´ë¯€ë¡œ primaryëŠ” ê¸°ì¡´ ì„¹í„° ìœ ì§€
                'sector_weight': 0.3 if reit_result.get('multi_sector') else 0.5,
            }
            base_results.append(reit_sector)
            reit_time = time.time() - reit_start
            logger.info(f"[{ticker}] âœ… ë¦¬ì¸  ë¶„ë¥˜ ì™„ë£Œ: {reit_result.get('l2_sector')} (ì‹ ë¢°ë„: {reit_result.get('confidence', 0):.2f}, {reit_time:.2f}ì´ˆ)")
            if reit_result.get('multi_sector'):
                logger.info(f"[{ticker}] â„¹ï¸ Multi-sector: ë¦¬ì¸  + {', '.join(existing_sectors_after_holding)}")
    
    # Step 0.7: Primary ì„¹í„° ê²°ì • (Multi-sector ì¼€ì´ìŠ¤)
    if len(base_results) > 1:
        logger.info(f"[{ticker}] ğŸ”„ Step 0.7: Primary ì„¹í„° ê²°ì • (Multi-sector: {len(base_results)}ê°œ)")
        base_results = apply_primary_sector_flags(base_results)
        primary_sector = next((r.get('major_sector') or r.get('sector_l1') for r in base_results if r.get('is_primary')), None)
        if primary_sector:
            logger.info(f"[{ticker}] âœ… Primary ì„¹í„°: {primary_sector}")
    
    # Step 0.8: L2 ë¶„ë¦¬ (ê·œì¹™ ê¸°ë°˜ - í™•ì¥ì„± ê°œì„ )
    if company_detail:
        logger.info(f"[{ticker}] ğŸ”„ Step 0.8: L2 ë¶„ë¦¬ ì‹œì‘ (ê·œì¹™ ê¸°ë°˜)")
        for result in base_results:
            major_sector = result.get('major_sector')
            
            # ì´ë¯¸ L2ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ (Rule-based ë“±ìœ¼ë¡œ ì„¤ì •ëœ ê²½ìš°)
            if result.get('sector_l2'):
                continue
                
            # ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ L2 ë¶„ë¦¬ ì—¬ë¶€ í™•ì¸
            split_type = get_l2_split_type(major_sector)
            if split_type:
                l2_code, l2_conf = classify_l2_by_rule(major_sector, company_detail.biz_summary)
                if l2_code:
                    result['sector_l2'] = l2_code
                    result['sub_sector'] = l2_code  # í•˜ìœ„ í˜¸í™˜ì„±
                    result['l2_split_type'] = split_type
                    result['confidence_l2'] = l2_conf  # â­ L2 confidence ì €ì¥
                    # â­ L2 Confidence ë¡œê¹… ê°•í™” (ë””ë²„ê¹…/ì„¤ëª…ìë£Œìš©)
                    logger.info(f"[L2_CONF] {ticker} {major_sector}â†’{l2_code} (Rule: {split_type}, Conf: {l2_conf:.2f})")
                    logger.info(f"[{ticker}] âœ… {major_sector} â†’ L2: {l2_code} (ê·œì¹™: {split_type}, conf: {l2_conf:.2f})")
                else:
                    logger.debug(f"[{ticker}] {major_sector} â†’ L2 ë¶„ë¥˜ ë¶ˆê°€ (í‚¤ì›Œë“œ ì—†ìŒ)")
            else:
                logger.debug(f"[{ticker}] {major_sector} â†’ L2 ë¶„ë¦¬ ê·œì¹™ ì—†ìŒ")
    
    # Step 4A: KF-DeBERTa Driver Signal Extraction
    step4a_start = time.time()
    logger.info(f"[{ticker}] ğŸ”„ Step 4A: KF-DeBERTa Driver Signal Extraction ì‹œì‘")
    
    driver_signals = {}
    for result in base_results:
        major_sector = result.get('major_sector')
        sub_sector = result.get('sub_sector')
        
        if major_sector:
            try:
                sector_start = time.time()
                signals = extract_driver_signals_from_sentences(
                    company_detail=company_detail,
                    major_sector=major_sector,
                    sub_sector=sub_sector,
                    sector_l2=result.get('sector_l2')  # â­ L2 ì •ë³´ ì „ë‹¬
                )
                
                # â­ Fallback: ë“œë¼ì´ë²„ê°€ ì—†ê³  Multi-sectorì¸ ê²½ìš°
                is_empty = (
                    not signals.get('price_signals') and 
                    not signals.get('quantity_signals') and 
                    not signals.get('cost_signals')
                )
                
                if is_empty and len(base_results) > 1:
                    logger.warning(f"[{ticker}] âš ï¸ {major_sector} ë“œë¼ì´ë²„ ì—†ìŒ, ë‹¤ë¥¸ ì„¹í„°ì—ì„œ Fallback ì‹œë„")
                    # Primary ì„¹í„°ê°€ ì•„ë‹ˆë©´ Primary ì„¹í„°ì˜ ë“œë¼ì´ë²„ ì¬ì‚¬ìš©
                    primary_result = next((r for r in base_results if r.get('is_primary')), None)
                    if primary_result and primary_result.get('major_sector') != major_sector:
                        primary_signals = driver_signals.get(primary_result.get('major_sector'), {})
                        if primary_signals and (primary_signals.get('price_signals') or primary_signals.get('quantity_signals') or primary_signals.get('cost_signals')):
                            signals = primary_signals
                            logger.info(f"[{ticker}] âœ… {primary_result.get('major_sector')} ë“œë¼ì´ë²„ ì¬ì‚¬ìš©")
                sector_time = time.time() - sector_start
                driver_signals[major_sector] = signals
                logger.info(f"[{ticker}] âœ… {major_sector} ë“œë¼ì´ë²„ ì‹œê·¸ë„ ì¶”ì¶œ ì™„ë£Œ: P={len(signals.get('price_signals', []))}, Q={len(signals.get('quantity_signals', []))}, C={len(signals.get('cost_signals', []))} ({sector_time:.2f}ì´ˆ)")
            except Exception as e:
                logger.error(f"[{ticker}] âŒ ë“œë¼ì´ë²„ ì‹œê·¸ë„ ì¶”ì¶œ ì‹¤íŒ¨ ({major_sector}): {e}", exc_info=True)
                driver_signals[major_sector] = {
                    "price_signals": [],
                    "quantity_signals": [],
                    "cost_signals": []
                }
    
    step4a_time = time.time() - step4a_start
    logger.info(f"[{ticker}] âœ… Step 4A ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {step4a_time:.2f}ì´ˆ)")
    
    # Step 4B: Gemini-Reasoning Industrial Graph (ë¡œì»¬ LLM ëŒ€ì²´)
    step4b_start = time.time()
    logger.info(f"[{ticker}] ğŸ”„ Step 4B: Gemini-Reasoning Industrial Graph ì‹œì‘")
    
    # Gemini Handler ì´ˆê¸°í™” (ì—†ìœ¼ë©´ ì‹±ê¸€í†¤ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°)
    if gemini_handler is None:
        try:
            gemini_init_start = time.time()
            logger.info(f"[{ticker}] ğŸ”„ Gemini-Reasoning Handler ì´ˆê¸°í™” ì¤‘...")
            gemini_handler = get_gemini_handler()
            gemini_init_time = time.time() - gemini_init_start
            logger.info(f"[{ticker}] âœ… Gemini-Reasoning Handler ì´ˆê¸°í™” ì™„ë£Œ ({gemini_init_time:.2f}ì´ˆ)")
        except Exception as e:
            logger.error(f"[{ticker}] âŒ Gemini-Reasoning Handler ìƒì„± ì‹¤íŒ¨: {e}")
            # Fallback: ê¸°ì¡´ ê²°ê³¼ ë°˜í™˜ (ì¸ê³¼ êµ¬ì¡° ì—†ì´)
            return base_results
    
    # ê° ì„¹í„°ë³„ë¡œ Gemini-Reasoning ìˆ˜í–‰
    for result in base_results:
        major_sector = result.get('major_sector')
        sub_sector = result.get('sub_sector')
        
        if not major_sector:
            continue
        
        try:
            # í•´ë‹¹ ì„¹í„°ì˜ ë“œë¼ì´ë²„ ì‹œê·¸ë„ ê°€ì ¸ì˜¤ê¸°
            signals = driver_signals.get(major_sector, {})
            
            # â­ Driver-less Reasoning ì°¨ë‹¨ (INSUFFICIENT_DRIVER_SIGNAL)
            total_signals = sum(len(signals.get(k, [])) for k in ['price_signals', 'quantity_signals', 'cost_signals'])
            
            if total_signals == 0:
                logger.info(f"[{ticker}] â„¹ï¸ {major_sector} driver_signals ì—†ìŒ â†’ ì œí•œì  ë¶„ì„ ëª¨ë“œ ({ANALYSIS_STATE['INSUFFICIENT_DRIVER_SIGNAL']})")
                
                # ì œí•œì  ë¶„ì„ ê²°ê³¼ ìƒì„± (Gemini í˜¸ì¶œ ìŠ¤í‚µ)
                result['causal_structure'] = {
                    'schema_version': 'v1.0',
                    'summary_sentence': f'{company_name or ticker}ì˜ í•µì‹¬ ê²½ì œ ë³€ìˆ˜ë¥¼ ì‹ë³„í•˜ì§€ ëª»í•´ ìƒì„¸ ì¸ê³¼ ë¶„ì„ì´ ì œí•œë©ë‹ˆë‹¤.',
                    'easy_explanation': 'í˜„ì¬ ì´ ê¸°ì—…ì— ëŒ€í•œ ì¶©ë¶„í•œ ë“œë¼ì´ë²„ ì •ë³´ê°€ ì—†ì–´ ìƒì„¸í•œ ì¸ê³¼ ë¶„ì„ì´ ì–´ë µìŠµë‹ˆë‹¤. ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ í›„ ì¬ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.',
                    'sentiment_label': 'Neutral',
                    'key_drivers': [],
                    'upstream_impacts': [],
                    'downstream_impacts': [],
                    'risk_factors': [],
                    'opportunity_factors': [],
                    'granular_tags': [],
                    'analysis_state': ANALYSIS_STATE['INSUFFICIENT_DRIVER_SIGNAL'],  # â­ ìƒìˆ˜ ì‚¬ìš©
                    'analysis_note': f'L2({result.get("sector_l2")}) ê¸°ë°˜ ë“œë¼ì´ë²„ ì¶”ì¶œ ì‹¤íŒ¨'
                }
                result['causal_structure_status'] = ANALYSIS_STATE['LIMITED']  # â­ ìƒìˆ˜ ì‚¬ìš©
                continue  # Gemini í˜¸ì¶œ ìŠ¤í‚µ
            
            # ë“œë¼ì´ë²„ ì‹œê·¸ë„ í†µê³„ ë¡œê¹…
            signal_counts = {
                'P': len(signals.get('price_signals', [])),
                'Q': len(signals.get('quantity_signals', [])),
                'C': len(signals.get('cost_signals', []))
            }
            logger.info(f"[{ticker}] ğŸ“Š {major_sector} ë“œë¼ì´ë²„ ì‹œê·¸ë„: P={signal_counts['P']}, Q={signal_counts['Q']}, C={signal_counts['C']}")
            
            # Gemini-Reasoning í˜¸ì¶œ
            sector_reasoning_start = time.time()
            causal_structure = gemini_handler.generate_causal_structure(
                company_detail=company_detail,
                major_sector=major_sector,
                sub_sector=sub_sector,
                driver_signals=signals
            )
            sector_reasoning_time = time.time() - sector_reasoning_start
            
            # ì¸ê³¼ êµ¬ì¡° í†µê³„ ë¡œê¹…
            upstream_count = len(causal_structure.get('upstream_impacts', []))
            downstream_count = len(causal_structure.get('downstream_impacts', []))
            drivers_count = len(causal_structure.get('key_drivers', []))
            logger.info(f"[{ticker}] âœ… {major_sector} Gemini-Reasoning ì™„ë£Œ ({sector_reasoning_time:.2f}ì´ˆ)")
            logger.info(f"[{ticker}] ğŸ“ˆ ì¸ê³¼ êµ¬ì¡°: ì—…ìŠ¤íŠ¸ë¦¼={upstream_count}, ë‹¤ìš´ìŠ¤íŠ¸ë¦¼={downstream_count}, ë“œë¼ì´ë²„={drivers_count}")
            
            # ê²°ê³¼ì— ì¸ê³¼ êµ¬ì¡° ì¶”ê°€
            result['causal_structure'] = causal_structure
            result['causal_structure_status'] = ANALYSIS_STATE['SUCCESS']  # â­ ìƒìˆ˜ ì‚¬ìš©
            
        except Exception as e:
            logger.error(f"[{ticker}] âŒ Gemini-Reasoning ì‹¤íŒ¨ ({major_sector}): {e}", exc_info=True)
            result['causal_structure_status'] = ANALYSIS_STATE['ERROR']  # â­ ìƒìˆ˜ ì‚¬ìš©
    
    # Step 4C: GPT Style Polishing (ë¹„í™œì„±í™”)
    # ì‚¬ìš©ìê°€ ìš”ì²­í•œ ëŒ€ë¡œ GPT ì‚¬ìš© ì•ˆ í•¨
    logger.info(f"[{ticker}] Step 4C: GPT Style Polishing ìŠ¤í‚µ (ë¹„í™œì„±í™”)")
    
    # Step 4.5: Exposure Drivers ì¶”ì¶œ ë° Granular Tags í•„í„°ë§
    logger.info(f"[{ticker}] Step 4.5: Exposure Drivers ì¶”ì¶œ ë° Granular Tags í•„í„°ë§ ì‹œì‘")
    
    for result in base_results:
        sector_code = result.get('major_sector')
        sub_sector_code = result.get('sub_sector')
        causal_structure = result.get('causal_structure')
        
        if not sector_code:
            continue
        
        # L3 íƒœê·¸ Enrichment (Backendì—ì„œ ìë™ ë¶€ì—¬)
        if causal_structure:
            # LLMì´ ìƒì„±í•œ granular_tagsëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©
            llm_granular_tags = causal_structure.get('granular_tags', [])
            
            # Backendì—ì„œ ì •í™•í•œ L3 íƒœê·¸ ìë™ ë¶€ì—¬
            enriched_l3_tags = enrich_l3_tags_from_company_detail(
                sector_l1=sector_code,
                company_detail=company_detail,
                causal_structure=causal_structure
            )
            
            # L3 íƒœê·¸ ì—…ë°ì´íŠ¸ (enriched íƒœê·¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ LLM íƒœê·¸ ìœ ì§€)
            if enriched_l3_tags:
                causal_structure['granular_tags'] = enriched_l3_tags
                causal_structure['l3_tags'] = enriched_l3_tags  # ìƒˆë¡œìš´ í•„ë“œ ì¶”ê°€
                logger.info(f"[{ticker}] L3 íƒœê·¸ Enrichment: {len(enriched_l3_tags)}ê°œ íƒœê·¸ ë¶€ì—¬ ({sector_code})")
            elif llm_granular_tags:
                # LLM íƒœê·¸ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ (ì°¸ê³ ìš©)
                logger.debug(f"[{ticker}] L3 íƒœê·¸ Enrichment ì‹¤íŒ¨, LLM íƒœê·¸ ìœ ì§€: {llm_granular_tags}")
            
            # â­ Driver Tags ë¶€ì—¬ (Backend Rule - 100% ì‹œìŠ¤í…œ ìƒì„±)
            key_drivers = causal_structure.get('key_drivers', [])
            sector_l2 = result.get('sector_l2') or result.get('sub_sector')
            sector_l2_confidence = result.get('confidence_l2')
            
            # â­ ê¸°ì¡´ íƒœê·¸ ì¡°íšŒ (Supersessionìš©)
            existing_driver_tags_map = {}
            if db:
                try:
                    existing_investor_sector = db.query(InvestorSector).filter(
                        InvestorSector.ticker == ticker,
                        InvestorSector.major_sector == sector_code
                    ).first()
                    
                    if existing_investor_sector and existing_investor_sector.causal_structure:
                        old_causal = existing_investor_sector.causal_structure
                        old_drivers = old_causal.get('key_drivers', [])
                        for old_driver in old_drivers:
                            old_code = old_driver.get('code')
                            if old_code:
                                existing_driver_tags_map[old_code] = old_driver.get('driver_tags_metadata', [])
                        
                        if existing_driver_tags_map:
                            logger.debug(f"[{ticker}] ê¸°ì¡´ Driver Tags ì¡°íšŒ: {len(existing_driver_tags_map)}ê°œ ë“œë¼ì´ë²„")
                except Exception as e:
                    logger.warning(f"[{ticker}] ê¸°ì¡´ Driver Tags ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
            if key_drivers:
                driver_tags_count = 0
                for driver in key_drivers:
                    driver_code = driver.get('code')
                    if not driver_code:
                        continue
                    
                    # â­ ê¸°ì¡´ íƒœê·¸ê°€ ìˆìœ¼ë©´ Supersession í•¨ìˆ˜ ì‚¬ìš©
                    existing_tags = existing_driver_tags_map.get(driver_code)
                    
                    if existing_tags:
                        # ê¸°ì¡´ íƒœê·¸ì™€ ë¹„êµí•˜ì—¬ Supersession ì ìš©
                        driver_tags = enrich_driver_tags_with_supersession(
                            driver_code=driver_code,
                            sector_l1=sector_code,
                            sector_l2=sector_l2,
                            sector_l2_confidence=sector_l2_confidence,
                            company_detail=company_detail,
                            existing_tags=existing_tags
                        )
                    else:
                        # ê¸°ì¡´ íƒœê·¸ ì—†ìŒ â†’ ìƒˆë¡œ ìƒì„±
                        driver_tags = enrich_driver_tags(
                            driver_code=driver_code,
                            sector_l1=sector_code,
                            sector_l2=sector_l2,
                            sector_l2_confidence=sector_l2_confidence,
                            company_detail=company_detail
                        )
                    
                    if driver_tags:
                        # driver_tagsë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥ (í•˜ìœ„ í˜¸í™˜ì„±)
                        driver['driver_tags'] = [tag_info['tag'] for tag_info in driver_tags]
                        # ë©”íƒ€ë°ì´í„°ë„ í•¨ê»˜ ì €ì¥ (ìˆ˜ëª… ê´€ë¦¬ìš©)
                        driver['driver_tags_metadata'] = driver_tags
                        driver_tags_count += len(driver_tags)
                        logger.debug(f"[{ticker}] {driver_code}: {len(driver_tags)}ê°œ Driver Tags ë¶€ì—¬")
                    else:
                        # Driver Tagsê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ëª…ì‹œ
                        driver['driver_tags'] = []
                        driver['driver_tags_metadata'] = []
                        logger.debug(f"[{ticker}] {driver_code}: Driver Tags ì—†ìŒ (Allowlist ì—†ìŒ ë˜ëŠ” ë§¤ì¹­ ì‹¤íŒ¨)")
                
                if driver_tags_count > 0:
                    logger.info(f"[{ticker}] Driver Tags Enrichment: ì´ {driver_tags_count}ê°œ íƒœê·¸ ë¶€ì—¬ ({sector_code})")
            
            result['causal_structure'] = causal_structure
        
        # Exposure Drivers ì¶”ì¶œ (ë©”ëª¨ë¦¬/ë¡œê·¸ë§Œ ì‚¬ìš©, DB ì €ì¥ ì•ˆ í•¨)
        exposure_drivers, supporting_drivers = extract_exposure_drivers(
            sector_code,
            sub_sector_code,
            causal_structure,
            company_detail
        )
        
        # âš ï¸ exposure_driversëŠ” ë©”ëª¨ë¦¬ì—ì„œë§Œ ì‚¬ìš© (Fallbackìš©)
        # DB ì €ì¥ ì•ˆ í•¨ (causal_structure.key_driversë§Œ ì €ì¥)
        if exposure_drivers:
            logger.debug(f"[{ticker}] {sector_code}/{sub_sector_code} â†’ Exposure Drivers: {len(exposure_drivers)}ê°œ (ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš©)")
        
        if supporting_drivers:
            logger.debug(f"[{ticker}] {sector_code} â†’ Supporting Drivers: {len(supporting_drivers)}ê°œ (ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš©)")
        
        # â­ Fallback: key_driversê°€ ë¹„ì–´ìˆìœ¼ë©´ exposure_driversë¥¼ key_driversë¡œ ë³€í™˜
        if causal_structure:
            key_drivers = causal_structure.get('key_drivers', [])
            analysis_state = causal_structure.get('analysis_state')
            
            # INSUFFICIENT_DRIVER_SIGNAL ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ Fallback ìˆ˜í–‰ (ì •ì§í•œ ì‹¤íŒ¨ ìœ ì§€)
            if not key_drivers and exposure_drivers and analysis_state != 'INSUFFICIENT_DRIVER_SIGNAL':
                logger.warning(f"[{ticker}] âš ï¸ {sector_code} key_driversê°€ ë¹„ì–´ìˆìŒ, exposure_driversë¥¼ key_driversë¡œ ë³€í™˜")
                # exposure_driversë¥¼ key_drivers í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                converted_key_drivers = []
                for ed in exposure_drivers[:5]:  # ìµœëŒ€ 5ê°œë§Œ
                    converted_key_drivers.append({
                        'var': ed.get('var', ed.get('code', '')),
                        'code': ed.get('code', ''),
                        'type': ed.get('type', ''),
                        'direction': ed.get('direction', ''),
                        'description': ed.get('description', ''),
                        'evidence': ed.get('evidence', [])
                    })
                causal_structure['key_drivers'] = converted_key_drivers
                result['causal_structure'] = causal_structure
                logger.info(f"[{ticker}] âœ… {sector_code} exposure_drivers â†’ key_drivers ë³€í™˜ ì™„ë£Œ: {len(converted_key_drivers)}ê°œ")
            elif not key_drivers and analysis_state == 'INSUFFICIENT_DRIVER_SIGNAL':
                logger.info(f"[{ticker}] â„¹ï¸ {sector_code} ë“œë¼ì´ë²„ ë¶€ì¡± ìƒíƒœì´ë¯€ë¡œ Fallback ìˆ˜í–‰ ì•ˆ í•¨ (ì •ì§í•œ ì‹¤íŒ¨)")
    
    step4b_time = time.time() - step4b_start
    logger.info(f"[{ticker}] âœ… Step 4B ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {step4b_time:.2f}ì´ˆ)")
    
    # Step 4.6: KG Edge ìƒì„± (Post-processing)
    logger.info(f"[{ticker}] Step 4.6: KG Edge ìƒì„± ì‹œì‘")
    kg_edge_start = time.time()
    
    try:
        for result in base_results:
            causal_structure = result.get('causal_structure')
            major_sector = result.get('major_sector')
            sector_l2 = result.get('sector_l2') or result.get('sub_sector')
            
            if causal_structure:
                edges = build_edges_from_causal_structure(
                    ticker=ticker,
                    causal_structure=causal_structure,
                    major_sector=major_sector,
                    sector_l2=sector_l2
                )
                
                if edges:
                    saved_count = save_edges_to_db(db, edges, upsert=True)
                    logger.info(f"[{ticker}] âœ… KG Edge ìƒì„± ì™„ë£Œ: {saved_count}ê°œ ì €ì¥ ({major_sector})")
        
        kg_edge_time = time.time() - kg_edge_start
        logger.info(f"[{ticker}] âœ… Step 4.6 ì™„ë£Œ (ì†Œìš” ì‹œê°„: {kg_edge_time:.2f}ì´ˆ)")
    except Exception as e:
        logger.error(f"[{ticker}] âŒ KG Edge ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
    
    # â­ NEW: NULL ì„¹í„° ìµœì¢… ê²€ì¦
    for result in base_results:
        if result.get('is_primary') or base_results.index(result) == 0:
            if not result.get('sector_l1') and not result.get('major_sector'):
                logger.warning(f"[{ticker}] âš ï¸ Primary ì„¹í„°ê°€ NULL, ê°•ì œ Fallback ì ìš©")
                
                # í™•ì •ì  ê·œì¹™ ì ìš©
                result['sector_l1'] = 'SEC_UNKNOWN'
                result['major_sector'] = 'SEC_UNKNOWN'
                result['fallback_used'] = 'TRUE'  # â­ VARCHARì— ë¬¸ìì—´ ì €ì¥
                result['fallback_type'] = 'UNKNOWN'  # â­ íƒ€ì… ë¶„ë¦¬
                result['confidence'] = 'VERY_LOW'
                result['method'] = 'FALLBACK_UNKNOWN'
                result['ensemble_score'] = 0.0
                result['reasoning'] = 'NULL ì„¹í„° ê°ì§€, UNKNOWN í• ë‹¹'
                
                logger.info(f"[{ticker}] âœ… NULL ì„¹í„° â†’ SEC_UNKNOWN í• ë‹¹ ì™„ë£Œ")
                break
    
    logger.info(f"[{ticker}] âœ… Gemini ê¸°ë°˜ ì„¹í„° ë¶„ë¥˜ ì™„ë£Œ: {len(base_results)}ê°œ ì„¹í„°")
    
    return base_results
    
    logger.info(f"[{ticker}] âœ… Gemini ê¸°ë°˜ ì„¹í„° ë¶„ë¥˜ ì™„ë£Œ: {len(base_results)}ê°œ ì„¹í„°")
    
    return base_results


def classify_sector_ensemble_won_batch(
    db: Session,
    tickers: List[str],
    gemini_handler: Optional[GeminiHandler] = None,
    use_embedding: bool = True,
    use_reranking: bool = True,
    max_sectors: int = 3
) -> Dict[str, Optional[List[Dict[str, Any]]]]:
    """
    ë°°ì¹˜ ì²˜ë¦¬: ì—¬ëŸ¬ ê¸°ì—…ì„ í•œ ë²ˆì— ì²˜ë¦¬ (ëª¨ë¸ì€ í•œ ë²ˆë§Œ ë¡œë“œ)
    
    Args:
        db: DB ì„¸ì…˜
        tickers: ì¢…ëª©ì½”ë“œ ë¦¬ìŠ¤íŠ¸
        gemini_handler: GeminiHandler ê°ì²´ (Noneì´ë©´ ìë™ ìƒì„±)
        use_embedding: ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
        use_reranking: BGE-M3 Re-ranking ì‚¬ìš© ì—¬ë¶€
        max_sectors: ìµœëŒ€ ì„¹í„° ê°œìˆ˜
    
    Returns:
        {ticker: results} ë”•ì…”ë„ˆë¦¬
    """
    logger.info(f"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(tickers)}ê°œ ê¸°ì—…")
    batch_start = time.time()
    
    # ========================================================================
    # ëª¨ë¸ ì‚¬ì „ ë¡œë”© (ë³‘ë ¬í™” ëŒ€ì‹  ìˆœì°¨ ë¡œë”©, í•˜ì§€ë§Œ ë¯¸ë¦¬ ë¡œë“œ)
    # ========================================================================
    logger.info("ğŸ”„ [ì‚¬ì „ ë¡œë”©] í•„ìš”í•œ ëª¨ë¸ë“¤ì„ ë¯¸ë¦¬ ë¡œë”© ì¤‘...")
    preload_start = time.time()
    
    # 1. Gemini Handler ì´ˆê¸°í™” (í•œ ë²ˆë§Œ)
    if gemini_handler is None:
        logger.info("  ğŸ“¥ [ì‚¬ì „ ë¡œë”©] Gemini-Reasoning í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì¤‘...")
        import sys
        sys.stdout.flush()  # ë¡œê·¸ ì¦‰ì‹œ ì¶œë ¥
        gemini_init_start = time.time()
        try:
            gemini_handler = get_gemini_handler()
            gemini_init_time = time.time() - gemini_init_start
            logger.info(f"  âœ… [ì‚¬ì „ ë¡œë”©] Gemini-Reasoning í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ ({gemini_init_time:.2f}ì´ˆ)")
            sys.stdout.flush()  # ë¡œê·¸ ì¦‰ì‹œ ì¶œë ¥
        except Exception as e:
            logger.error(f"  âŒ [ì‚¬ì „ ë¡œë”©] Gemini-Reasoning í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
            sys.stdout.flush()
            raise
    
    # 2. KF-DeBERTa ëª¨ë¸ ì‚¬ì „ ë¡œë”© (Step 4Aì—ì„œ ì‚¬ìš©)
    try:
        logger.info("  ğŸ“¥ [ì‚¬ì „ ë¡œë”©] KF-DeBERTa ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        kf_start = time.time()
        # KF-DeBERTa ëª¨ë¸ì€ ì œê±°ë¨ (Solar Embeddingìœ¼ë¡œ ëŒ€ì²´)
        # from app.services.embedding_model_direct import get_direct_embedding_model
        # kf_model = get_direct_embedding_model()  # ì‹±ê¸€í†¤ìœ¼ë¡œ í•œ ë²ˆë§Œ ë¡œë“œ
        kf_time = time.time() - kf_start
        logger.info(f"  âœ… [ì‚¬ì „ ë¡œë”©] KF-DeBERTa ëª¨ë¸ ì œê±°ë¨ (Solar Embedding ì‚¬ìš©) ({kf_time:.2f}ì´ˆ)")
    except Exception as e:
        logger.warning(f"  âš ï¸ [ì‚¬ì „ ë¡œë”©] KF-DeBERTa ëª¨ë¸ ì œê±°ë¨: {e}")
    
    # 3. ì„ë² ë”© ëª¨ë¸ ì‚¬ì „ ë¡œë”© (Step 0-3.5ì—ì„œ ì‚¬ìš©)
    if use_embedding:
        try:
            logger.info("  ğŸ“¥ [ì‚¬ì „ ë¡œë”©] ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
            emb_start = time.time()
            from app.services.sector_classifier_embedding import get_embedding_model
            emb_model = get_embedding_model()  # ì‹±ê¸€í†¤ìœ¼ë¡œ í•œ ë²ˆë§Œ ë¡œë“œ
            emb_time = time.time() - emb_start
            logger.info(f"  âœ… [ì‚¬ì „ ë¡œë”©] ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ ({emb_time:.2f}ì´ˆ)")
        except Exception as e:
            logger.warning(f"  âš ï¸ [ì‚¬ì „ ë¡œë”©] ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ (ë‚˜ì¤‘ì— ë¡œë“œë¨): {e}")
    
    # 4. BGE-M3 ëª¨ë¸ ì‚¬ì „ ë¡œë”© (Step 0-3.5ì—ì„œ ì‚¬ìš©)
    if use_reranking:
        try:
            logger.info("  ğŸ“¥ [ì‚¬ì „ ë¡œë”©] BGE-M3 ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
            bge_start = time.time()
            from app.services.sector_classifier_reranker import get_bge_model
            bge_model = get_bge_model()  # ì‹±ê¸€í†¤ìœ¼ë¡œ í•œ ë²ˆë§Œ ë¡œë“œ
            bge_time = time.time() - bge_start
            logger.info(f"  âœ… [ì‚¬ì „ ë¡œë”©] BGE-M3 ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ ({bge_time:.2f}ì´ˆ)")
        except Exception as e:
            logger.warning(f"  âš ï¸ [ì‚¬ì „ ë¡œë”©] BGE-M3 ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ (ë‚˜ì¤‘ì— ë¡œë“œë¨): {e}")
    
    preload_time = time.time() - preload_start
    logger.info(f"âœ… [ì‚¬ì „ ë¡œë”©] ëª¨ë“  ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {preload_time:.2f}ì´ˆ)")
    import sys
    sys.stdout.flush()  # ë¡œê·¸ ì¦‰ì‹œ ì¶œë ¥
    
    # GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
    try:
        import torch
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
            gpu_allocated = torch.cuda.memory_allocated(0) / 1024**3  # GB
            gpu_reserved = torch.cuda.memory_reserved(0) / 1024**3  # GB
            logger.info(f"ğŸ“Š [GPU ë©”ëª¨ë¦¬] ì´: {gpu_memory:.2f}GB, í• ë‹¹: {gpu_allocated:.2f}GB, ì˜ˆì•½: {gpu_reserved:.2f}GB, ì‚¬ìš©ë¥ : {(gpu_reserved/gpu_memory)*100:.1f}%")
    except Exception as e:
        logger.debug(f"GPU ë©”ëª¨ë¦¬ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    # ëª¨ë“  ê¸°ì—…ì˜ CompanyDetail ë¯¸ë¦¬ ì¡°íšŒ
    logger.info("ğŸ”„ [ë°ì´í„° ì¡°íšŒ] ê¸°ì—… ë°ì´í„° ì¡°íšŒ ì¤‘...")
    data_start = time.time()
    company_details_map = {}
    for ticker in tickers:
        company_detail = db.query(CompanyDetail).filter(
            CompanyDetail.ticker == ticker
        ).first()
        if company_detail:
            company_details_map[ticker] = company_detail
    data_time = time.time() - data_start
    logger.info(f"âœ… [ë°ì´í„° ì¡°íšŒ] {len(company_details_map)}ê°œ ê¸°ì—… ë°ì´í„° ì¡°íšŒ ì™„ë£Œ ({data_time:.2f}ì´ˆ)")
    
    # ê° ê¸°ì—…ë³„ë¡œ ì²˜ë¦¬ (ìˆœì°¨ ì²˜ë¦¬, í•˜ì§€ë§Œ ëª¨ë¸ì€ í•œ ë²ˆë§Œ ë¡œë“œ)
    results = {}
    for i, ticker in enumerate(tickers, 1):
        logger.info(f"\n[{i}/{len(tickers)}] {ticker} ì²˜ë¦¬ ì¤‘...")
        ticker_start = time.time()
        
        try:
            result = classify_sector_ensemble_won(
                db=db,
                ticker=ticker,
                gemini_handler=gemini_handler,  # ì¬ì‚¬ìš©
                use_embedding=use_embedding,
                use_reranking=use_reranking,
                max_sectors=max_sectors
            )
            ticker_time = time.time() - ticker_start
            results[ticker] = result
            logger.info(f"âœ… {ticker} ì™„ë£Œ (ì†Œìš” ì‹œê°„: {ticker_time:.2f}ì´ˆ)")
        except Exception as e:
            logger.error(f"âŒ {ticker} ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
            results[ticker] = None
    
    batch_time = time.time() - batch_start
    avg_time = batch_time / len(tickers) if tickers else 0
    logger.info(f"\nâœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(tickers)}ê°œ ê¸°ì—…, ì´ ì†Œìš” ì‹œê°„: {batch_time:.2f}ì´ˆ, ê¸°ì—…ë‹¹ í‰ê· : {avg_time:.2f}ì´ˆ")
    
    return results


