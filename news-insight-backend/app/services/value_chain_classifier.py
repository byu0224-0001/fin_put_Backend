"""
ë°¸ë¥˜ì²´ì¸ ë¶„ì„ ë° ë¶„ë¥˜ ëª¨ë“ˆ

í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: Rule-based (ê¸°ì¡´) + Ensemble (ì‹ ê·œ)
- Rule confidence HIGH â†’ Rule-based ì¦‰ì‹œ ë°˜í™˜
- Rule confidence LOW â†’ Ensemble ì‹¤í–‰
"""
import os
import logging
from typing import Optional, List, Dict, Any, Tuple
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)

# ê¸°ì¡´ Rule-based ë¶„ë¥˜ê¸°
from app.services.sector_classifier import VALUE_CHAIN_KEYWORDS, SECTOR_KEYWORDS
from app.models.company_detail import CompanyDetail
from app.utils.text_chunking import truncate_to_sentences

# Phase 1: ì„ë² ë”© ëª¨ë¸ ê¸°ë°˜ í›„ë³´ ìƒì„±ê¸°
EMBEDDING_AVAILABLE = False
try:
    from app.services.value_chain_classifier_embedding import classify_value_chain_embedding, SENTENCE_TRANSFORMERS_AVAILABLE
    if SENTENCE_TRANSFORMERS_AVAILABLE:
        EMBEDDING_AVAILABLE = True
        logger.info("ì„ë² ë”© ëª¨ë¸ ëª¨ë“ˆ import ì„±ê³µ (ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜ìš©, lazy loading - ì‹¤ì œ ì‚¬ìš© ì‹œì ì— ë¡œë“œ)")
    else:
        EMBEDDING_AVAILABLE = False
        logger.warning("sentence-transformers not installed. Embedding model not available.")
except ImportError as e:
    EMBEDDING_AVAILABLE = False
    logger.warning(f"ì„ë² ë”© ëª¨ë¸ import ì‹¤íŒ¨: {e}. Will skip embedding-based classification.")

# Phase 2: BGE-M3 Re-ranking
try:
    from app.services.value_chain_classifier_reranker import rerank_value_chain_candidates
    BGE_AVAILABLE = True
except ImportError:
    BGE_AVAILABLE = False
    logger.warning("BGE-M3 not available. Will skip reranking.")

# Phase 3: GPT ìµœì¢… ê²€ì¦
try:
    from app.services.value_chain_classifier_validator import validate_value_chain_with_gpt
    GPT_AVAILABLE = True
except ImportError:
    GPT_AVAILABLE = False
    logger.warning("GPT validator not available. Will skip final validation.")

from app.services.llm_handler import LLMHandler


# ============================================================================
# ì„¹í„°ë³„ ë°¸ë¥˜ì²´ì¸ í‚¤ì›Œë“œ (28ê°œ ì„¹í„°)
# ============================================================================

SECTOR_SPECIFIC_VALUE_CHAIN_KEYWORDS = {
    # [Tech & Growth] - 5ê°œ
    'SEC_SEMI': {
        'UPSTREAM': [
            'ì›¨ì´í¼', 'ì†Œì¬', 'í™”í•™ì•½í’ˆ', 'ê°€ìŠ¤', 'ì›ì¬ë£Œ ì¡°ë‹¬',
            'ë¶€í’ˆ', 'ì¥ë¹„ ë¶€í’ˆ', 'ì†Œë¶€ì¥', 'í™”í•™ì•½í’ˆ', 'ì‹¤ë¦¬ì½˜'
        ],
        'MIDSTREAM': [
            'ì œì¡°', 'ê³µì •', 'íŒ¨í‚¤ì§•', 'í…ŒìŠ¤íŠ¸', 'ê²€ì‚¬',
            'ì›¨ì´í¼ ê°€ê³µ', 'íšŒë¡œ í˜•ì„±', 'ì´ì˜¨ ì£¼ì…', 'ì‹ê°', 'ì¦ì°©'
        ],
        'DOWNSTREAM': [
            'íŒë§¤', 'ê³ ê°ì‚¬', 'ë‚©í’ˆ', 'ëª¨ë“ˆ', 'ì‹œìŠ¤í…œ',
            'ìµœì¢… ì œí’ˆ', 'ë°˜ë„ì²´ íŒë§¤', 'ì¹© íŒë§¤'
        ]
    },
    'SEC_BATTERY': {
        'UPSTREAM': [
            'ì–‘ê·¹ì¬', 'ìŒê·¹ì¬', 'ì „í•´ì•¡', 'ë¶„ë¦¬ë§‰', 'ë¦¬íŠ¬',
            'ë‹ˆì¼ˆ', 'ì½”ë°œíŠ¸', 'ì›ì¬ë£Œ', 'ì†Œì¬ ì¡°ë‹¬'
        ],
        'MIDSTREAM': [
            'ì…€ ì œì¡°', 'ë°°í„°ë¦¬íŒ© ì¡°ë¦½', 'ì¶©ë°©ì „ í…ŒìŠ¤íŠ¸',
            'ì œì¡°', 'ìƒì‚°', 'ê°€ê³µ'
        ],
        'DOWNSTREAM': [
            'ë°°í„°ë¦¬ íŒë§¤', 'ì „ê¸°ì°¨ ë‚©í’ˆ', 'ì—ë„ˆì§€ì €ì¥ì‹œìŠ¤í…œ',
            'íŒë§¤', 'ë‚©í’ˆ', 'ê³ ê°ì‚¬'
        ]
    },
    'SEC_IT': {
        'UPSTREAM': [
            'ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ì„ ìŠ¤', 'í´ë¼ìš°ë“œ ì¸í”„ë¼', 'API',
            'ê°œë°œ ë„êµ¬', 'í”Œë«í¼'
        ],
        'MIDSTREAM': [
            'ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ', 'ì‹œìŠ¤í…œ êµ¬ì¶•', 'ì†”ë£¨ì…˜ ê°œë°œ',
            'ê°œë°œ', 'êµ¬ì¶•', 'ì œì‘'
        ],
        'DOWNSTREAM': [
            'ì„œë¹„ìŠ¤ ì œê³µ', 'ê³ ê° ì§€ì›', 'ìœ ì§€ë³´ìˆ˜',
            'íŒë§¤', 'ì„œë¹„ìŠ¤', 'ê³ ê°'
        ]
    },
    'SEC_GAME': {
        'UPSTREAM': [
            'ê²Œì„ ì—”ì§„', 'ë¼ì´ì„ ìŠ¤', 'IP', 'ê°œë°œ ë„êµ¬'
        ],
        'MIDSTREAM': [
            'ê²Œì„ ê°œë°œ', 'í¼ë¸”ë¦¬ì‹±', 'QA', 'í…ŒìŠ¤íŠ¸',
            'ê°œë°œ', 'ì œì‘'
        ],
        'DOWNSTREAM': [
            'ê²Œì„ íŒë§¤', 'ë‹¤ìš´ë¡œë“œ', 'ì¸ì•±ê²°ì œ', 'ì„œë¹„ìŠ¤',
            'íŒë§¤', 'ì„œë¹„ìŠ¤'
        ]
    },
    'SEC_ELECTRONICS': {
        'UPSTREAM': [
            'ë¶€í’ˆ', 'ì†Œì¬', 'íŒ¨ë„', 'ëª¨ë“ˆ', 'ì›ì¬ë£Œ'
        ],
        'MIDSTREAM': [
            'ì œì¡°', 'ì¡°ë¦½', 'ìƒì‚°', 'ê°€ê³µ', 'ê²€ì‚¬'
        ],
        'DOWNSTREAM': [
            'ì œí’ˆ íŒë§¤', 'ìœ í†µ', 'ê³ ê°', 'A/S'
        ]
    },
    
    # [Mobility] - 2ê°œ
    'SEC_AUTO': {
        'UPSTREAM': [
            'ë¶€í’ˆ', 'ì†Œì¬', 'ê°•íŒ', 'í”Œë¼ìŠ¤í‹±', 'ì „ìë¶€í’ˆ',
            'ëª¨í„°', 'ë°°í„°ë¦¬', 'ì„¼ì„œ', 'ì›ì¬ë£Œ'
        ],
        'MIDSTREAM': [
            'ì¡°ë¦½', 'ìš©ì ‘', 'ë„ì¥', 'ê²€ì‚¬', 'ì™„ì„±ì°¨ ì œì¡°',
            'ìƒì‚°ë¼ì¸', 'ì¡°ë¦½ë¼ì¸', 'ì œì¡°'
        ],
        'DOWNSTREAM': [
            'ìë™ì°¨ íŒë§¤', 'ë”œëŸ¬', 'ê³ ê°', 'A/S', 'ì„œë¹„ìŠ¤',
            'íŒë§¤', 'ìœ í†µ'
        ]
    },
    'SEC_TIRE': {
        'UPSTREAM': [
            'ê³ ë¬´', 'ì¹´ë³¸ë¸”ë™', 'ì›ì¬ë£Œ', 'ì†Œì¬'
        ],
        'MIDSTREAM': [
            'íƒ€ì´ì–´ ì œì¡°', 'ê°€ê³µ', 'ì„±í˜•', 'ë²Œì»¤ë‚˜ì´ì§•',
            'ì œì¡°', 'ìƒì‚°'
        ],
        'DOWNSTREAM': [
            'íƒ€ì´ì–´ íŒë§¤', 'ìë™ì°¨ì‚¬ ë‚©í’ˆ', 'ìœ í†µ',
            'íŒë§¤', 'ë‚©í’ˆ'
        ]
    },
    
    # [Industry & Cyclical] - 6ê°œ
    'SEC_SHIP': {
        'UPSTREAM': [
            'ê°•íŒ', 'ì—”ì§„', 'ë¶€í’ˆ', 'ê¸°ìì¬', 'ì›ì¬ë£Œ'
        ],
        'MIDSTREAM': [
            'ì¡°ì„ ', 'ì„ ë°• ê±´ì¡°', 'ìš©ì ‘', 'ë„ì¥', 'ì‹œìš´ì „',
            'ì œì¡°', 'ê±´ì¡°'
        ],
        'DOWNSTREAM': [
            'ì„ ë°• ì¸ë„', 'í•´ìš´ì‚¬ ë‚©í’ˆ', 'íŒë§¤',
            'ì¸ë„', 'íŒë§¤'
        ]
    },
    'SEC_DEFENSE': {
        'UPSTREAM': [
            'ë¶€í’ˆ', 'ì†Œì¬', 'ì „ìë¶€í’ˆ', 'ì›ì¬ë£Œ'
        ],
        'MIDSTREAM': [
            'ë¬´ê¸° ì œì¡°', 'ì¡°ë¦½', 'í…ŒìŠ¤íŠ¸', 'ê²€ì‚¬',
            'ì œì¡°', 'ìƒì‚°'
        ],
        'DOWNSTREAM': [
            'êµ­ë°© ë‚©í’ˆ', 'ìˆ˜ì¶œ', 'íŒë§¤',
            'ë‚©í’ˆ', 'íŒë§¤'
        ]
    },
    'SEC_MACH': {
        'UPSTREAM': [
            'ë¶€í’ˆ', 'ì†Œì¬', 'ê°•íŒ', 'ì›ì¬ë£Œ'
        ],
        'MIDSTREAM': [
            'ê¸°ê³„ ì œì¡°', 'ì¡°ë¦½', 'ê°€ê³µ', 'ê²€ì‚¬',
            'ì œì¡°', 'ìƒì‚°'
        ],
        'DOWNSTREAM': [
            'ê¸°ê³„ íŒë§¤', 'ì„¤ì¹˜', 'A/S', 'ì„œë¹„ìŠ¤',
            'íŒë§¤', 'ì„œë¹„ìŠ¤'
        ]
    },
    'SEC_CONST': {
        'UPSTREAM': [
            'ê±´ì¶•ìì¬', 'ì‹œë©˜íŠ¸', 'ì² ê°•', 'ì›ì¬ë£Œ'
        ],
        'MIDSTREAM': [
            'ê±´ì„¤', 'ê³µì‚¬', 'ì‹œê³µ', 'ì°©ê³µ',
            'ê±´ì¶•', 'í† ëª©'
        ],
        'DOWNSTREAM': [
            'ì¤€ê³µ', 'ì¸ë„', 'íŒë§¤', 'ì„ëŒ€',
            'ì™„ê³µ', 'ì¸ë„'
        ]
    },
    'SEC_STEEL': {
        'UPSTREAM': [
            'ì² ê´‘ì„', 'ì„íƒ„', 'ì›ì¬ë£Œ', 'ì›ë£Œ'
        ],
        'MIDSTREAM': [
            'ì œì² ', 'ì••ì—°', 'ê°•íŒ ì œì¡°', 'ê°€ê³µ',
            'ì œì¡°', 'ìƒì‚°'
        ],
        'DOWNSTREAM': [
            'ê°•íŒ íŒë§¤', 'ë‚©í’ˆ', 'ìœ í†µ',
            'íŒë§¤', 'ë‚©í’ˆ'
        ]
    },
    'SEC_CHEM': {
        'UPSTREAM': [
            'ì›ìœ ', 'ë‚˜í”„íƒ€', 'ê°€ìŠ¤', 'ì›ì¬ë£Œ'
        ],
        'MIDSTREAM': [
            'ì •ìœ ', 'ì„ìœ í™”í•™', 'í•©ì„±', 'ê°€ê³µ',
            'ì œì¡°', 'ìƒì‚°'
        ],
        'DOWNSTREAM': [
            'í™”í•™ì œí’ˆ íŒë§¤', 'ë‚©í’ˆ', 'ìœ í†µ',
            'íŒë§¤', 'ë‚©í’ˆ'
        ]
    },
    
    # [Consumer & K-Culture] - 6ê°œ
    'SEC_ENT': {
        'UPSTREAM': [
            'IP', 'ì €ì‘ê¶Œ', 'ìŒì›', 'ì½˜í…ì¸ '
        ],
        'MIDSTREAM': [
            'ì½˜í…ì¸  ì œì‘', 'ì•¨ë²” ì œì‘', 'ì˜í™” ì œì‘',
            'ì œì‘', 'ê°œë°œ'
        ],
        'DOWNSTREAM': [
            'ìŒì•… íŒë§¤', 'ìŠ¤íŠ¸ë¦¬ë°', 'ë°©ì†¡', 'ì„œë¹„ìŠ¤',
            'íŒë§¤', 'ì„œë¹„ìŠ¤'
        ]
    },
    'SEC_COSMETIC': {
        'UPSTREAM': [
            'ì›ë£Œ', 'í–¥ë£Œ', 'í¬ì¥ì¬', 'ì†Œì¬'
        ],
        'MIDSTREAM': [
            'í™”ì¥í’ˆ ì œì¡°', 'ìƒì‚°', 'í¬ì¥',
            'ì œì¡°', 'ìƒì‚°'
        ],
        'DOWNSTREAM': [
            'í™”ì¥í’ˆ íŒë§¤', 'ìœ í†µ', 'ê³ ê°',
            'íŒë§¤', 'ìœ í†µ'
        ]
    },
    'SEC_TRAVEL': {
        'UPSTREAM': [
            'í•­ê³µê¸°', 'ì—°ë£Œ', 'ì¸í”„ë¼'
        ],
        'MIDSTREAM': [
            'ìš´í•­', 'ì„œë¹„ìŠ¤ ìš´ì˜', 'ê´€ë¦¬',
            'ìš´ì˜', 'ì„œë¹„ìŠ¤'
        ],
        'DOWNSTREAM': [
            'í•­ê³µê¶Œ íŒë§¤', 'ê³ ê° ì„œë¹„ìŠ¤', 'ì—¬í–‰ ìƒí’ˆ',
            'íŒë§¤', 'ì„œë¹„ìŠ¤'
        ]
    },
    'SEC_FOOD': {
        'UPSTREAM': [
            'ë†ì‚°ë¬¼', 'ì¶•ì‚°ë¬¼', 'ìˆ˜ì‚°ë¬¼', 'ì›ì¬ë£Œ'
        ],
        'MIDSTREAM': [
            'ì‹í’ˆ ê°€ê³µ', 'ì œì¡°', 'ìƒì‚°', 'í¬ì¥',
            'ê°€ê³µ', 'ì œì¡°'
        ],
        'DOWNSTREAM': [
            'ì‹í’ˆ íŒë§¤', 'ìœ í†µ', 'ê³ ê°',
            'íŒë§¤', 'ìœ í†µ'
        ]
    },
    'SEC_RETAIL': {
        'UPSTREAM': [
            'ìƒí’ˆ ì¡°ë‹¬', 'ë§¤ì…', 'ê³µê¸‰'
        ],
        'MIDSTREAM': [
            'ì¬ê³  ê´€ë¦¬', 'ë¬¼ë¥˜', 'ì°½ê³ '
        ],
        'DOWNSTREAM': [
            'íŒë§¤', 'ê³ ê°', 'ì„œë¹„ìŠ¤', 'ìœ í†µ'
        ]
    },
    'SEC_CONSUMER': {
        'UPSTREAM': [
            'ì›ì¬ë£Œ', 'ë¶€í’ˆ', 'ì†Œì¬'
        ],
        'MIDSTREAM': [
            'ì œì¡°', 'ìƒì‚°', 'ê°€ê³µ'
        ],
        'DOWNSTREAM': [
            'íŒë§¤', 'ìœ í†µ', 'ê³ ê°', 'ì„œë¹„ìŠ¤'
        ]
    },
    
    # [Healthcare] - 2ê°œ
    'SEC_BIO': {
        'UPSTREAM': [
            'ì›ë£Œ', 'ì‹œì•½', 'ì„¸í¬ì£¼', 'ì›ì¬ë£Œ'
        ],
        'MIDSTREAM': [
            'ì œì•½', 'ì‹ ì•½ ê°œë°œ', 'ì„ìƒ', 'ìƒì‚°',
            'ê°œë°œ', 'ì œì¡°'
        ],
        'DOWNSTREAM': [
            'ì˜ì•½í’ˆ íŒë§¤', 'ë³‘ì› ë‚©í’ˆ', 'ìœ í†µ',
            'íŒë§¤', 'ë‚©í’ˆ'
        ]
    },
    'SEC_MEDDEV': {
        'UPSTREAM': [
            'ë¶€í’ˆ', 'ì†Œì¬', 'ì›ì¬ë£Œ'
        ],
        'MIDSTREAM': [
            'ì˜ë£Œê¸°ê¸° ì œì¡°', 'ì¡°ë¦½', 'ê²€ì‚¬',
            'ì œì¡°', 'ìƒì‚°'
        ],
        'DOWNSTREAM': [
            'ì˜ë£Œê¸°ê¸° íŒë§¤', 'ë³‘ì› ë‚©í’ˆ', 'ì„œë¹„ìŠ¤',
            'íŒë§¤', 'ë‚©í’ˆ'
        ]
    },
    
    # [Finance] - 5ê°œ
    'SEC_BANK': {
        'UPSTREAM': [
            'ì˜ˆê¸ˆ', 'ì €ì¶•', 'ìê¸ˆ ì¡°ë‹¬', 'ì°¨ì…', 'ìê¸ˆ í™•ë³´'
        ],
        'MIDSTREAM': [
            'ëŒ€ì¶œ', 'íˆ¬ì', 'ìì‚°ìš´ìš©', 'ë¦¬ìŠ¤í¬ ê´€ë¦¬', 'ì‹ ìš© í‰ê°€',
            'ìš´ìš©', 'ê´€ë¦¬'
        ],
        'DOWNSTREAM': [
            'ì´ì ìˆ˜ìµ', 'ìˆ˜ìˆ˜ë£Œ', 'ê³ ê° ì„œë¹„ìŠ¤', 'ê¸ˆìœµ ìƒí’ˆ íŒë§¤',
            'ìˆ˜ìµ', 'ì„œë¹„ìŠ¤'
        ]
    },
    'SEC_SEC': {
        'UPSTREAM': [
            'ìê¸ˆ ì¡°ë‹¬', 'í€ë“œ ëª¨ì§‘'
        ],
        'MIDSTREAM': [
            'íˆ¬ì', 'ìì‚°ìš´ìš©', 'ë¸Œë¡œì»¤ë¦¬ì§€', 'ìƒì¥',
            'ìš´ìš©', 'ì¤‘ê°œ'
        ],
        'DOWNSTREAM': [
            'ìˆ˜ìˆ˜ë£Œ ìˆ˜ìµ', 'ê³ ê° ì„œë¹„ìŠ¤', 'ìƒë‹´',
            'ìˆ˜ìµ', 'ì„œë¹„ìŠ¤'
        ]
    },
    'SEC_INS': {
        'UPSTREAM': [
            'ë³´í—˜ë£Œ ìˆ˜ì§‘', 'ìê¸ˆ ì¡°ë‹¬'
        ],
        'MIDSTREAM': [
            'ë³´í—˜ ìš´ì˜', 'ë¦¬ìŠ¤í¬ ê´€ë¦¬', 'ì¬ë³´í—˜',
            'ìš´ì˜', 'ê´€ë¦¬'
        ],
        'DOWNSTREAM': [
            'ë³´ìƒ', 'ê³ ê° ì„œë¹„ìŠ¤', 'ìƒë‹´',
            'ë³´ìƒ', 'ì„œë¹„ìŠ¤'
        ]
    },
    'SEC_CARD': {
        'UPSTREAM': [
            'ìê¸ˆ ì¡°ë‹¬', 'ì°¨ì…'
        ],
        'MIDSTREAM': [
            'ê²°ì œ ì²˜ë¦¬', 'ìŠ¹ì¸', 'ë¦¬ìŠ¤í¬ ê´€ë¦¬',
            'ì²˜ë¦¬', 'ê´€ë¦¬'
        ],
        'DOWNSTREAM': [
            'ìˆ˜ìˆ˜ë£Œ ìˆ˜ìµ', 'ê³ ê° ì„œë¹„ìŠ¤',
            'ìˆ˜ìµ', 'ì„œë¹„ìŠ¤'
        ]
    },
    'SEC_HOLDING': {
        'UPSTREAM': [
            'ìê¸ˆ ì¡°ë‹¬', 'íˆ¬ì ìœ ì¹˜'
        ],
        'MIDSTREAM': [
            'íˆ¬ì', 'ê²½ì˜', 'ê´€ë¦¬', 'ì§€ë°°êµ¬ì¡°',
            'ìš´ì˜', 'ê´€ë¦¬'
        ],
        'DOWNSTREAM': [
            'ë°°ë‹¹', 'ìˆ˜ìµ', 'ê°€ì¹˜ ì°½ì¶œ',
            'ìˆ˜ìµ', 'ë°°ë‹¹'
        ]
    },
    
    # [Utility] - 2ê°œ
    'SEC_UTIL': {
        'UPSTREAM': [
            'ì—°ë£Œ', 'ì›ìë ¥', 'ê°€ìŠ¤', 'ì›ì¬ë£Œ'
        ],
        'MIDSTREAM': [
            'ë°œì „', 'ì†¡ì „', 'ë°°ì „', 'ê³µê¸‰',
            'ìƒì‚°', 'ê³µê¸‰'
        ],
        'DOWNSTREAM': [
            'ì „ë ¥ íŒë§¤', 'ê³ ê°', 'ì„œë¹„ìŠ¤',
            'íŒë§¤', 'ì„œë¹„ìŠ¤'
        ]
    },
    'SEC_TELECOM': {
        'UPSTREAM': [
            'ì¥ë¹„', 'ì¸í”„ë¼', 'ë„¤íŠ¸ì›Œí¬'
        ],
        'MIDSTREAM': [
            'í†µì‹ ë§ êµ¬ì¶•', 'ìš´ì˜', 'ê´€ë¦¬',
            'êµ¬ì¶•', 'ìš´ì˜'
        ],
        'DOWNSTREAM': [
            'í†µì‹  ì„œë¹„ìŠ¤', 'ê³ ê°', 'ìš”ê¸ˆ',
            'ì„œë¹„ìŠ¤', 'ê³ ê°'
        ]
    }
}


# ============================================================================
# Rule-based ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜ (ê¸°ì¡´ ë¡œì§ ê°œì„ )
# ============================================================================

# ğŸ†• P1-1: Revenue Segment â†’ Value Chain ë§¤í•‘
REVENUE_TO_VALUE_CHAIN_MAP = {
    # ë°°í„°ë¦¬ ê´€ë ¨
    'ë°°í„°ë¦¬': 'VC_BATTERY_MATERIALS',
    'ë°°í„°ë¦¬ì¬ë£Œ': 'VC_BATTERY_MATERIALS',
    'ì–‘ê·¹ì¬': 'VC_BATTERY_MATERIALS',
    'ìŒê·¹ì¬': 'VC_BATTERY_MATERIALS',
    'ì „í•´ì•¡': 'VC_BATTERY_MATERIALS',
    'ë¶„ë¦¬ë§‰': 'VC_BATTERY_MATERIALS',
    'ì…€': 'VC_BATTERY_MIDSTREAM',
    'ë°°í„°ë¦¬íŒ©': 'VC_BATTERY_MIDSTREAM',
    'ë°°í„°ë¦¬ì‹œìŠ¤í…œ': 'VC_BATTERY_DOWNSTREAM',
    
    # ì¬í™œìš© ê´€ë ¨
    'ì¬í™œìš©': 'VC_BATTERY_RECYCLING',
    'ë¦¬ì‚¬ì´í´ë§': 'VC_BATTERY_RECYCLING',
    'íë°°í„°ë¦¬': 'VC_BATTERY_RECYCLING',
    
    # ë™ë°• ê´€ë ¨
    'ë™ë°•': 'VC_BATTERY_MATERIALS',
    'êµ¬ë¦¬ë°•': 'VC_BATTERY_MATERIALS',
    
    # ë°˜ë„ì²´ ê´€ë ¨
    'ë°˜ë„ì²´': 'VC_SEMI_MIDSTREAM',
    'ì›¨ì´í¼': 'VC_SEMI_UPSTREAM',
    'íŒ¨í‚¤ì§•': 'VC_SEMI_MIDSTREAM',
    
    # í™”í•™ ê´€ë ¨
    'í™”í•™': 'VC_CHEMICAL_MIDSTREAM',
    'ì„ìœ í™”í•™': 'VC_CHEMICAL_MIDSTREAM',
    'ì •ìœ ': 'VC_CHEMICAL_MIDSTREAM',
    
    # ì² ê°• ê´€ë ¨
    'ì² ê°•': 'VC_STEEL_MIDSTREAM',
    'ì œì² ': 'VC_STEEL_MIDSTREAM',
    
    # ê±´ì„¤ ê´€ë ¨
    'ê±´ì„¤': 'VC_CONST_DOWNSTREAM',
    'ê³µì‚¬': 'VC_CONST_DOWNSTREAM',
    
    # ìœ í†µ ê´€ë ¨
    'ìœ í†µ': 'VC_DIST_DOWNSTREAM',
    'íŒë§¤': 'VC_DIST_DOWNSTREAM',
    'ì†Œë§¤': 'VC_DIST_DOWNSTREAM',
}

def classify_value_chain_rule_based(
    company_detail: CompanyDetail,
    sector: str,
    company_name: Optional[str] = None,
    sector_l2: Optional[str] = None,
    driver_tags: Optional[List[str]] = None
) -> Tuple[Optional[str], float, List[Dict[str, Any]]]:
    """
    Rule-based ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜ (Confidence ì¶”ê°€, L2 ë° Driver Tags ì •ë³´ í™œìš©)
    
    Args:
        company_detail: CompanyDetail ê°ì²´
        sector: ì„¹í„° ì½”ë“œ
        company_name: íšŒì‚¬ëª… (ì„ íƒ)
        sector_l2: L2 ì„¹í„° ì½”ë“œ (ì„ íƒ, ì˜ˆ: 'DISTRIBUTION', 'MANUFACTURING')
        driver_tags: Driver Tags ë¦¬ìŠ¤íŠ¸ (ì„ íƒ, ì˜ˆ: ['IMPORT_DEPENDENT', 'EXPORT_DRIVEN'])
    
    Returns:
        (value_chain, confidence_score, vc_candidates)
        - value_chain: 'UPSTREAM', 'MIDSTREAM', 'DOWNSTREAM' ë˜ëŠ” None
        - confidence_score: 0.0 ~ 1.0
        - vc_candidates: [{'value_chain': 'UPSTREAM', 'weight': 0.8, 'confidence': 'HIGH', 'evidence': [...], 'source': 'revenue_segment'}, ...]
    """
    if not company_detail:
        return None, 0.0, []
    
    # í…ìŠ¤íŠ¸ ìˆ˜ì§‘
    text_parts = []
    if company_detail.biz_summary:
        text_parts.append(company_detail.biz_summary.lower())
    if company_detail.products:
        products_text = ' '.join([str(p) for p in company_detail.products]).lower()
        text_parts.append(products_text)
    if company_detail.keywords:
        keywords_text = ' '.join([str(k) for k in company_detail.keywords]).lower()
        text_parts.append(keywords_text)
    if company_detail.clients:
        if isinstance(company_detail.clients, list):
            clients_text = ' '.join([str(c) for c in company_detail.clients if c]).lower()
        else:
            clients_text = str(company_detail.clients).lower()
        text_parts.append(clients_text)
    if company_detail.supply_chain:
        if isinstance(company_detail.supply_chain, list):
            supply_chain_text = ' '.join([
                f"{item.get('item','')} {item.get('supplier','')}".strip()
                if isinstance(item, dict) else str(item)
                for item in company_detail.supply_chain if item
            ]).lower()
        else:
            supply_chain_text = str(company_detail.supply_chain).lower()
        if supply_chain_text:
            text_parts.append(supply_chain_text)
    if company_detail.raw_materials:
        raw_materials_text = ' '.join([str(m) for m in company_detail.raw_materials if m]).lower()
        text_parts.append(raw_materials_text)
    # ğŸ†• P1-1: revenue_by_segmentë¥¼ í…ìŠ¤íŠ¸ë¿ë§Œ ì•„ë‹ˆë¼ êµ¬ì¡°í™”ëœ ë¶„ì„ì—ë„ ì‚¬ìš©
    revenue_segments_for_vc = {}  # ë°¸ë¥˜ì²´ì¸ ë§¤í•‘ìš©
    revenue_vc_candidates = []  # Revenue ê¸°ë°˜ ë°¸ë¥˜ì²´ì¸ í›„ë³´
    if company_detail.revenue_by_segment:
        if isinstance(company_detail.revenue_by_segment, dict):
            revenue_text = ' '.join([
                f"{segment}:{value}" for segment, value in company_detail.revenue_by_segment.items()
            ]).lower()
            revenue_segments_for_vc = company_detail.revenue_by_segment
            
            # ğŸ†• P1-1: Revenue Segment â†’ Value Chain ë§¤í•‘
            for segment_name, pct in revenue_segments_for_vc.items():
                segment_lower = segment_name.lower().strip()
                # REVENUE_TO_VALUE_CHAIN_MAPì—ì„œ ë§¤ì¹­
                for revenue_key, vc_code in REVENUE_TO_VALUE_CHAIN_MAP.items():
                    if revenue_key in segment_lower:
                        # VC ì½”ë“œë¥¼ UPSTREAM/MIDSTREAM/DOWNSTREAMìœ¼ë¡œ ë³€í™˜
                        if 'UPSTREAM' in vc_code or 'RECYCLING' in vc_code:
                            vc_type = 'UPSTREAM'
                        elif 'DOWNSTREAM' in vc_code:
                            vc_type = 'DOWNSTREAM'
                        else:
                            vc_type = 'MIDSTREAM'
                        
                        revenue_vc_candidates.append({
                            'vc': vc_type,
                            'pct': pct,
                            'evidence': f"revenue_segment: {segment_name} ({pct}%)"
                        })
                        break
        else:
            revenue_text = str(company_detail.revenue_by_segment).lower()
        text_parts.append(revenue_text)
    if company_name:
        text_parts.append(company_name.lower())
    
    combined_text = ' '.join(text_parts)
    
    # ì„¹í„°ë³„ íŠ¹í™” í‚¤ì›Œë“œ ì‚¬ìš© (ìˆìœ¼ë©´)
    if sector in SECTOR_SPECIFIC_VALUE_CHAIN_KEYWORDS:
        vc_keywords_map = SECTOR_SPECIFIC_VALUE_CHAIN_KEYWORDS[sector]
    else:
        # ì¼ë°˜ í‚¤ì›Œë“œ ì‚¬ìš©
        vc_keywords_map = {
            'UPSTREAM': VALUE_CHAIN_KEYWORDS['UPSTREAM'],
            'MIDSTREAM': VALUE_CHAIN_KEYWORDS['MIDSTREAM'],
            'DOWNSTREAM': VALUE_CHAIN_KEYWORDS['DOWNSTREAM']
        }
    
    # ê° ë°¸ë¥˜ì²´ì¸ ìœ„ì¹˜ë³„ ì ìˆ˜ ê³„ì‚°
    vc_scores = {}
    for vc_type, vc_keywords in vc_keywords_map.items():
        score = 0
        matched_keywords = []
        
        for keyword in vc_keywords:
            if keyword.lower() in combined_text:
                score += 2
                matched_keywords.append(keyword)
        
        # ì œí’ˆ í•„ë“œì—ì„œ ì¶”ê°€ ë§¤ì¹­
        if company_detail.products:
            for product in company_detail.products:
                product_lower = str(product).lower()
                for keyword in vc_keywords:
                    if keyword.lower() in product_lower:
                        score += 3
                        matched_keywords.append(keyword)
                        break
        
        if score > 0:
            vc_scores[vc_type] = {
                'score': score,
                'matched_keywords': matched_keywords
            }
    
    if not vc_scores:
        return None, 0.0, []
    
    # ìµœê³  ì ìˆ˜ ë°¸ë¥˜ì²´ì¸ ì„ íƒ
    best_vc = max(vc_scores.items(), key=lambda x: x[1]['score'])
    value_chain = best_vc[0]
    score = best_vc[1]['score']
    matched_keywords = best_vc[1]['matched_keywords']
    
    # Confidence ê³„ì‚° (ê°œì„ : ë” ì •í™•í•œ confidence ê³„ì‚°)
    total_keywords = len(vc_keywords_map[value_chain])
    matched_keywords_unique = len(set(matched_keywords))
    matched_ratio = matched_keywords_unique / total_keywords if total_keywords > 0 else 0.0
    
    # ì ìˆ˜ ê¸°ë°˜ confidence (í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ì— ë”°ë¼)
    score_based_confidence = min(score / (total_keywords * 3) * 2, 1.0)  # ìµœëŒ€ ì ìˆ˜: í‚¤ì›Œë“œë‹¹ 3ì 
    
    # ë¬¸ë§¥ ë³´ë„ˆìŠ¤ (í™•ì¥)
    context_bonus = 0.0
    if company_detail.biz_summary:
        summary_lower = company_detail.biz_summary.lower()
        if value_chain == 'UPSTREAM':
            upstream_phrases = [
                'ì›ì¬ë£Œë¥¼', 'ë¶€í’ˆì„', 'ì†Œì¬ë¥¼', 'ì¡°ë‹¬', 'êµ¬ë§¤', 'ìˆ˜ì…',
                'ì›ë£Œ', 'ë¬¼ì', 'ìì¬', 'ê³µê¸‰ë°›', 'ë„ì…'
            ]
            if any(phrase in summary_lower for phrase in upstream_phrases):
                context_bonus = 0.25
        elif value_chain == 'MIDSTREAM':
            midstream_phrases = [
                'ì œì¡°í•˜ê³ ', 'ìƒì‚°í•˜ê³ ', 'ê°€ê³µí•˜ì—¬', 'ì¡°ë¦½', 'ê°€ê³µ', 'ì œì‘',
                'ìƒì‚°', 'ì œì¡°', 'ê°€ê³µ', 'ì¡°ë¦½', 'ê³µì •', 'ì œì‘'
            ]
            if any(phrase in summary_lower for phrase in midstream_phrases):
                context_bonus = 0.25
        elif value_chain == 'DOWNSTREAM':
            downstream_phrases = [
                'íŒë§¤í•˜ê³ ', 'ê³ ê°ì—ê²Œ', 'ë‚©í’ˆí•˜ì—¬', 'ìœ í†µ', 'íŒë§¤', 'ê³µê¸‰',
                'ë‚©í’ˆ', 'ì¶œê³ ', 'ì „ë‹¬', 'ì¸ë„', 'ì„œë¹„ìŠ¤', 'ìš´ì˜'
            ]
            if any(phrase in summary_lower for phrase in downstream_phrases):
                context_bonus = 0.25
    
    # ì œí’ˆëª…ì—ì„œë„ ì¶”ê°€ ê²€ìƒ‰ (ë³´ë„ˆìŠ¤)
    product_bonus = 0.0
    if company_detail.products and matched_keywords_unique >= 1:
        product_bonus = 0.1  # ì œí’ˆì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­ ì‹œ ë³´ë„ˆìŠ¤
    
    # â­ L2 ê¸°ë°˜ íŒíŠ¸ ì¶”ê°€
    l2_bonus = 0.0
    if sector_l2:
        if sector_l2 == 'DISTRIBUTION':
            if value_chain == 'DOWNSTREAM':
                l2_bonus = 0.2
            elif value_chain == 'MIDSTREAM':
                l2_bonus = 0.1
        elif sector_l2 == 'MANUFACTURING':
            if value_chain == 'MIDSTREAM':
                l2_bonus = 0.2
            elif value_chain == 'UPSTREAM':
                l2_bonus = 0.1
        elif sector_l2 in ['PG', 'PLATFORM']:
            if value_chain in ['MIDSTREAM', 'DOWNSTREAM']:
                l2_bonus = 0.15
    
    # â­ Driver Tags ê¸°ë°˜ íŒíŠ¸ ì¶”ê°€
    driver_tag_bonus = 0.0
    if driver_tags:
        for tag in driver_tags:
            if tag == 'IMPORT_DEPENDENT':
                if value_chain == 'UPSTREAM':
                    driver_tag_bonus = max(driver_tag_bonus, 0.2)
            elif tag == 'EXPORT_DRIVEN':
                if value_chain == 'DOWNSTREAM':
                    driver_tag_bonus = max(driver_tag_bonus, 0.2)
            elif tag == 'DISTRIBUTION':
                if value_chain == 'DOWNSTREAM':
                    driver_tag_bonus = max(driver_tag_bonus, 0.15)
            elif tag == 'MANUFACTURING':
                if value_chain == 'MIDSTREAM':
                    driver_tag_bonus = max(driver_tag_bonus, 0.15)
            elif tag == 'PLATFORM_BIZ':
                if value_chain in ['MIDSTREAM', 'DOWNSTREAM']:
                    driver_tag_bonus = max(driver_tag_bonus, 0.1)
            elif tag == 'RECURRING_REVENUE':
                if value_chain == 'DOWNSTREAM':
                    driver_tag_bonus = max(driver_tag_bonus, 0.1)
    
    # ìµœì¢… confidence: ë§¤ì¹­ ë¹„ìœ¨, ì ìˆ˜, ë¬¸ë§¥, ì œí’ˆ ë³´ë„ˆìŠ¤, L2 ë³´ë„ˆìŠ¤, Driver Tags ë³´ë„ˆìŠ¤ ì¡°í•©
    confidence = min(
        (matched_ratio * 0.35 + score_based_confidence * 0.25 + context_bonus + product_bonus + l2_bonus + driver_tag_bonus),
        1.0
    )
    
    # ìµœì†Œ confidence ë³´ì¥ (í‚¤ì›Œë“œ ë§¤ì¹­ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ìµœì†Œ 0.15)
    if matched_keywords_unique >= 1:
        confidence = max(confidence, 0.15)
    
    logger.debug(
        f"Rule-based ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜: {value_chain} "
        f"(confidence={confidence:.2f}, score={score}, "
        f"matched={len(matched_keywords)}/{total_keywords})"
    )
    
    # ğŸ†• P1-1: Revenue Segment ê¸°ë°˜ ë°¸ë¥˜ì²´ì¸ í›„ë³´ ì¶”ê°€
    if revenue_vc_candidates:
        # revenue ê¸°ë°˜ ë°¸ë¥˜ì²´ì¸ì„ ì ìˆ˜ì— ë°˜ì˜
        for candidate in revenue_vc_candidates:
            vc_code = candidate['vc']
            pct = candidate['pct']
            # revenue ë¹„ì¤‘ì„ ì ìˆ˜ë¡œ ë³€í™˜ (ìµœëŒ€ 0.3 ê°€ì‚°)
            revenue_score = min(0.3, pct / 100.0 * 0.5)
            
            # VC ì½”ë“œë¥¼ UPSTREAM/MIDSTREAM/DOWNSTREAMìœ¼ë¡œ ë³€í™˜
            if 'UPSTREAM' in vc_code or 'RECYCLING' in vc_code:
                vc_type = 'UPSTREAM'
            elif 'DOWNSTREAM' in vc_code:
                vc_type = 'DOWNSTREAM'
            else:
                vc_type = 'MIDSTREAM'
            
            if vc_type not in vc_scores:
                vc_scores[vc_type] = {'score': 0, 'matched_keywords': []}
            vc_scores[vc_type]['score'] += revenue_score * 10  # ì ìˆ˜ ìŠ¤ì¼€ì¼ ì¡°ì •
    
    # ğŸ†• P1-3: Value Chain í›„ë³´ ì €ì¥ (ë°¸ë¥˜ì²´ì¸ ì ìˆ˜ ê¸°ë°˜)
    vc_candidates = []
    if vc_scores:
        sorted_vc = sorted(vc_scores.items(), key=lambda x: x[1]['score'], reverse=True)
        for vc_type, vc_data in sorted_vc:
            score = vc_data['score']
            matched_keywords = vc_data.get('matched_keywords', [])
            evidence_list = []
            # í‚¤ì›Œë“œ ê¸°ë°˜ ê·¼ê±°
            if matched_keywords:
                evidence_list.append(f"keywords: {', '.join(matched_keywords[:3])}")
            # Revenue ê¸°ë°˜ ê·¼ê±°
            revenue_evidence = [c['evidence'] for c in revenue_vc_candidates if vc_type in c['vc']]
            if revenue_evidence:
                evidence_list.extend(revenue_evidence[:2])
            
            # ì ìˆ˜ë¥¼ weightë¡œ ë³€í™˜ (0.0 ~ 1.0)
            weight = min(1.0, score / 20.0)  # ìµœëŒ€ ì ìˆ˜ 20 ê¸°ì¤€
            
            vc_candidates.append({
                'value_chain': vc_type,
                'weight': weight,
                'confidence': 'HIGH' if weight >= 0.5 else ('MEDIUM' if weight >= 0.3 else 'LOW'),
                'evidence': evidence_list,
                'source': 'revenue_segment' if revenue_evidence else 'keywords'
            })
    
    # ìµœì¢… ë°¸ë¥˜ì²´ì¸ ê²°ì • (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    if not vc_scores:
        return None, 0.0, []
    
    best_vc = max(vc_scores.items(), key=lambda x: x[1]['score'])
    value_chain = best_vc[0]
    score = best_vc[1]['score']
    matched_keywords = best_vc[1]['matched_keywords']
    
    # Confidence ì¬ê³„ì‚° (revenue ë°˜ì˜ í›„)
    total_keywords = len(vc_keywords_map[value_chain])
    matched_keywords_unique = len(set(matched_keywords))
    matched_ratio = matched_keywords_unique / total_keywords if total_keywords > 0 else 0.0
    score_based_confidence = min(score / (total_keywords * 3) * 2, 1.0)
    
    # ìµœì¢… confidence
    confidence = min(
        (matched_ratio * 0.35 + score_based_confidence * 0.25 + context_bonus + product_bonus + l2_bonus + driver_tag_bonus),
        1.0
    )
    
    if matched_keywords_unique >= 1:
        confidence = max(confidence, 0.15)
    
    return value_chain, confidence, vc_candidates


# ============================================================================
# í•˜ì´ë¸Œë¦¬ë“œ ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜ (ê¸°ì¡´ + ì‹ ê·œ)
# ============================================================================

def classify_value_chain_hybrid(
    company_detail: CompanyDetail,
    sector: str,
    company_name: Optional[str] = None,
    use_ensemble: bool = True,
    use_gpt: bool = True,
    sector_l2: Optional[str] = None,
    driver_tags: Optional[List[str]] = None
) -> List[Dict[str, Any]]:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜
    
    Step 1: Rule-based (ê¸°ì¡´ ë°©ë²•)
    Step 2: Confidence í™•ì¸
        - HIGH (>0.85) â†’ ì¦‰ì‹œ ë°˜í™˜ (ë¹ ë¦„)
        - LOW/MEDIUM â†’ Ensemble ì‹¤í–‰ (ì •í™•ë„)
    
    Args:
        company_detail: CompanyDetail ê°ì²´
        sector: ì„¹í„° ì½”ë“œ
        company_name: íšŒì‚¬ëª… (ì„ íƒ)
        use_ensemble: Ensemble ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    
    Returns:
        [
            {
                'value_chain': 'MIDSTREAM',
                'weight': 0.6,
                'confidence': 'HIGH',
                'method': 'RULE_BASED' or 'ENSEMBLE',
                'rule_score': 0.85,
                ...
            },
            ...
        ]
    """
    # Step 1: Rule-based (ê¸°ì¡´ ë°©ë²•, L2 ë° Driver Tags ì •ë³´ í™œìš©)
    rule_vc, rule_conf, rule_candidates = classify_value_chain_rule_based(
        company_detail, sector, company_name, sector_l2, driver_tags
    )
    
    # Step 2: Confidence í™•ì¸
    if rule_conf > 0.85:
        # ê¸°ì¡´ ë°©ë²•ìœ¼ë¡œ ì¶©ë¶„ â†’ ë¹ ë¥´ê²Œ ë°˜í™˜
        logger.info(f"Rule-based HIGH confidence ({rule_conf:.2f}) â†’ ì¦‰ì‹œ ë°˜í™˜")
        return [{
            'value_chain': rule_vc,
            'weight': 1.0,
            'confidence': 'HIGH',
            'method': 'RULE_BASED',
            'rule_score': rule_conf,
            'is_primary': True
        }]
    
    # Step 3: Ensemble ì‹¤í–‰ (ì‹ ê·œ)
    if use_ensemble:
        logger.info(f"Rule-based confidence ë‚®ìŒ ({rule_conf:.2f}) â†’ Ensemble ì‹¤í–‰")
        try:
            return classify_value_chain_ensemble(
                company_detail,
                sector,
                company_name,
                use_embedding=True,  # â­ GPU ì‚¬ìš© ë³µì›
                use_reranking=True,  # â­ GPU ì‚¬ìš© ë³µì›
                use_gpt=use_gpt
            )
        except Exception as e:
            logger.error(f"Ensemble ì‹¤í–‰ ì‹¤íŒ¨, Rule ê²°ê³¼ ë°˜í™˜: {e}", exc_info=True)
            # Ensemble ì‹¤íŒ¨ ì‹œ Rule ê²°ê³¼ ë°˜í™˜
            return [{
                'value_chain': rule_vc,
                'weight': 1.0,
                'confidence': 'MEDIUM' if rule_conf > 0.5 else 'LOW',
                'method': 'RULE_BASED',
                'rule_score': rule_conf,
                'is_primary': True
            }]
    else:
        # Ensemble ë¯¸ì‚¬ìš© ì‹œ Rule ê²°ê³¼ ë°˜í™˜
        return [{
            'value_chain': rule_vc,
            'weight': 1.0,
            'confidence': 'MEDIUM' if rule_conf > 0.5 else 'LOW',
            'method': 'RULE_BASED',
            'rule_score': rule_conf,
            'is_primary': True
        }]


# ============================================================================
# Ensemble ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜ (4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸)
# ============================================================================

def _prepare_company_text_for_vc(
    company_detail: CompanyDetail,
    company_name: Optional[str] = None
) -> str:
    """
    ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜ë¥¼ ìœ„í•œ íšŒì‚¬ í…ìŠ¤íŠ¸ ì¤€ë¹„
    
    Args:
        company_detail: CompanyDetail ê°ì²´
        company_name: íšŒì‚¬ëª…
    
    Returns:
        ê²°í•©ëœ í…ìŠ¤íŠ¸
    """
    text_parts = []
    
    if company_name:
        text_parts.append(f"íšŒì‚¬ëª…: {company_name}")
    
    if company_detail.biz_summary:
        # biz_summary ì „ì²´ ì‚¬ìš© (ë°¸ë¥˜ì²´ì¸ ë¶„ì„ì€ ë¬¸ë§¥ì´ ì¤‘ìš”)
        text_parts.append(f"ì‚¬ì—… ê°œìš”: {company_detail.biz_summary}")
    
    if company_detail.products:
        products_text = ', '.join([str(p) for p in company_detail.products[:20]])
        text_parts.append(f"ì£¼ìš” ì œí’ˆ: {products_text}")
    
    if company_detail.keywords:
        keywords_text = ', '.join([str(k) for k in company_detail.keywords[:20]])
        text_parts.append(f"í‚¤ì›Œë“œ: {keywords_text}")
    
    if company_detail.clients:
        if isinstance(company_detail.clients, list):
            clients_text = ', '.join([str(c) for c in company_detail.clients[:20] if c])
        else:
            clients_text = str(company_detail.clients)
        if clients_text:
            text_parts.append(f"ì£¼ìš” ê³ ê°: {clients_text}")
    
    if company_detail.supply_chain:
        if isinstance(company_detail.supply_chain, list):
            supply_chain_text = ', '.join([
                f"{item.get('item','')}/{item.get('supplier','')}".strip('/')
                if isinstance(item, dict) else str(item)
                for item in company_detail.supply_chain[:20] if item
            ])
        else:
            supply_chain_text = str(company_detail.supply_chain)
        if supply_chain_text:
            text_parts.append(f"ê³µê¸‰ë§: {supply_chain_text}")
    
    if company_detail.raw_materials:
        raw_materials_text = ', '.join([str(m) for m in company_detail.raw_materials[:20] if m])
        if raw_materials_text:
            text_parts.append(f"ì›ì¬ë£Œ: {raw_materials_text}")
    
    if company_detail.revenue_by_segment:
        if isinstance(company_detail.revenue_by_segment, dict):
            revenue_text = ', '.join([
                f"{segment}:{value}" for segment, value in list(company_detail.revenue_by_segment.items())[:10]
            ])
        else:
            revenue_text = str(company_detail.revenue_by_segment)
        if revenue_text:
            text_parts.append(f"ë§¤ì¶œ ë¹„ì¤‘: {revenue_text}")
    
    return ' '.join(text_parts)


def _trim_text(text: str, max_chars: int) -> str:
    text = str(text).strip()
    if len(text) > max_chars:
        return text[:max_chars].rstrip() + "..."
    return text


def _normalize_simple_list(values: Any, limit: int) -> List[str]:
    if not values:
        return []
    normalized = []
    if isinstance(values, list):
        iterable = values
    else:
        iterable = [values]
    for value in iterable:
        if value is None:
            continue
        text = str(value).strip()
        if not text:
            continue
        normalized.append(text)
        if len(normalized) >= limit:
            break
    return normalized


def _format_supply_chain_items(supply_chain: Any, limit: int) -> List[str]:
    if not supply_chain:
        return []
    formatted = []
    items = supply_chain if isinstance(supply_chain, list) else [supply_chain]
    for entry in items:
        if isinstance(entry, dict):
            item = entry.get('item') or entry.get('raw_material') or entry.get('material')
            supplier = entry.get('supplier') or entry.get('vendor') or entry.get('source')
            if item and supplier:
                text = f"{item} ê³µê¸‰: {supplier}"
            elif item:
                text = str(item)
            elif supplier:
                text = f"ê³µê¸‰ì‚¬: {supplier}"
            else:
                text = ''
        else:
            text = str(entry)
        text = text.strip()
        if not text:
            continue
        formatted.append(text)
        if len(formatted) >= limit:
            break
    return formatted


def get_value_chain_embedding_segments(
    company_detail: CompanyDetail,
    company_name: Optional[str] = None
) -> List[Dict[str, Any]]:
    """
    ì„ë² ë”© ëª¨ë¸ ì…ë ¥ìš© í…ìŠ¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± (í•„ë“œë³„ ì œí•œ ì ìš©)
    """
    segments: List[Dict[str, Any]] = []

    def add_segment(label: str, text: str, weight: float, segment_type: str):
        trimmed = _trim_text(text, 500)
        if trimmed:
            segments.append({
                'text': f"{label}: {trimmed}" if label else trimmed,
                'weight': weight,
                'type': segment_type
            })

    if company_name:
        add_segment("íšŒì‚¬ëª…", company_name, 0.05, "company")

    if company_detail.biz_summary:
        summary = truncate_to_sentences(
            company_detail.biz_summary,
            max_chars=500,
            prefer_paragraphs=True
        )
        add_segment("ì‚¬ì—… ê°œìš”", summary, 0.35, "summary")

    products = _normalize_simple_list(company_detail.products, limit=5)
    if products:
        add_segment("ì£¼ìš” ì œí’ˆ", ', '.join(products), 0.15, "products")

    clients = _normalize_simple_list(company_detail.clients, limit=10)
    if clients:
        add_segment("ì£¼ìš” ê³ ê°", '; '.join(clients), 0.2, "clients")

    supply_chain_entries = _format_supply_chain_items(company_detail.supply_chain, limit=8)
    if supply_chain_entries:
        add_segment("ê³µê¸‰ë§", '; '.join(supply_chain_entries), 0.22, "supply_chain")

    raw_materials = _normalize_simple_list(company_detail.raw_materials, limit=8)
    if raw_materials:
        add_segment("ì›ì¬ë£Œ", ', '.join(raw_materials), 0.2, "raw_materials")

    revenue_text = ""
    if company_detail.revenue_by_segment:
        if isinstance(company_detail.revenue_by_segment, dict):
            items = list(company_detail.revenue_by_segment.items())
            try:
                items.sort(key=lambda x: float(x[1]), reverse=True)
            except Exception:
                pass
            top_items = items[:5]
            revenue_text = ', '.join([f"{seg}:{val}" for seg, val in top_items])
        else:
            revenue_text = str(company_detail.revenue_by_segment)
    if revenue_text:
        add_segment("ë§¤ì¶œ ë¹„ì¤‘", revenue_text, 0.2, "revenue")

    return segments


def classify_value_chain_ensemble(
    company_detail: CompanyDetail,
    sector_code: str,
    company_name: Optional[str] = None,
    db: Optional[Session] = None,
    llm_handler: Optional[LLMHandler] = None,
    use_embedding: bool = True,  # â­ ì¶”ê°€
    use_reranking: bool = True,
    use_gpt: bool = True,
    sector_l2: Optional[str] = None,
    driver_tags: Optional[List[str]] = None
) -> List[Dict[str, Any]]:
    """
    4ë‹¨ê³„ ë©€í‹° ëª¨ë¸ ì•™ìƒë¸” ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜
    
    Step 1: Rule-based (Confidence HIGHë©´ ì¦‰ì‹œ ë°˜í™˜)
    Step 2: ì„ë² ë”© ëª¨ë¸ Embedding (Top-3 í›„ë³´)
    Step 3: BGE-M3 Re-ranking (Top-3 â†’ Top-2, ì„ íƒì )
    Step 4: GPT ìµœì¢… ê²€ì¦ (Top-2 â†’ ìµœì¢… 1~3ê°œ, ì„ íƒì )
    
    Args:
        company_detail: CompanyDetail ê°ì²´
        sector_code: ì„¹í„° ì½”ë“œ
        company_name: íšŒì‚¬ëª… (ì„ íƒ)
        db: DB ì„¸ì…˜ (ì„ íƒ)
        llm_handler: LLMHandler ì¸ìŠ¤í„´ìŠ¤ (GPT ì‚¬ìš© ì‹œ í•„ìš”)
        use_reranking: BGE-M3 Re-ranking ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        use_gpt: GPT ìµœì¢… ê²€ì¦ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    
    Returns:
        [
            {
                'value_chain': 'MIDSTREAM',
                'weight': 0.6,
                'confidence': 'HIGH',
                'method': 'ENSEMBLE',
                'rule_score': 0.85,
                'embedding_score': 0.82,
                'bge_score': 0.80,
                'gpt_score': 0.88,
                'reasoning': '...',
                'is_primary': True
            },
            ...
        ]
    """
    # Step 1: Rule-based (ë¹ ë¥¸ ì²´í¬, L2 ë° Driver Tags ì •ë³´ í™œìš©)
    rule_vc, rule_conf, rule_candidates = classify_value_chain_rule_based(
        company_detail, sector_code, company_name, sector_l2, driver_tags
    )
    
    # Rule confidenceê°€ ë§¤ìš° ë†’ìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜
    if rule_conf > 0.90:
        logger.info(f"[{company_name}] Rule-based ë§¤ìš° ë†’ì€ confidence ({rule_conf:.2f}) â†’ ì¦‰ì‹œ ë°˜í™˜")
        return [{
            'value_chain': rule_vc,
            'weight': 1.0,
            'confidence': 'HIGH',
            'method': 'RULE_BASED',
            'rule_score': rule_conf,
            'is_primary': True
        }]
    
    # Step 2: ì„ë² ë”© ëª¨ë¸ ê¸°ë°˜ Embedding (í›„ë³´ ìƒì„±)
    company_text = _prepare_company_text_for_vc(company_detail, company_name)
    embedding_segments = get_value_chain_embedding_segments(company_detail, company_name)
    if not embedding_segments and company_text:
        embedding_segments = [{'text': company_text, 'weight': 1.0, 'type': 'combined'}]
    
    # ë™ì ìœ¼ë¡œ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ì‹œë„
    is_embedding_active = False
    classify_value_chain_embedding_func = None
    
    if use_embedding:
        if EMBEDDING_AVAILABLE:
            is_embedding_active = True
            # ì´ë¯¸ importëœ í•¨ìˆ˜ ì‚¬ìš© ì‹œë„
            try:
                # ì „ì—­ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ í•¨ìˆ˜ í™•ì¸
                if 'classify_value_chain_embedding' in globals():
                    classify_value_chain_embedding_func = classify_value_chain_embedding
                else:
                    # í•¨ìˆ˜ê°€ ì—†ìœ¼ë©´ ë‹¤ì‹œ import
                    from app.services.value_chain_classifier_embedding import classify_value_chain_embedding
                    classify_value_chain_embedding_func = classify_value_chain_embedding
            except (NameError, ImportError):
                # í•¨ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš° ë‹¤ì‹œ import
                from app.services.value_chain_classifier_embedding import classify_value_chain_embedding
                classify_value_chain_embedding_func = classify_value_chain_embedding
        else:
            # í”Œë˜ê·¸ê°€ Falseì—¬ë„ ì‹¤ì œë¡œ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ìˆëŠ”ì§€ ì‹œë„
            try:
                from app.services.value_chain_classifier_embedding import get_embedding_model, classify_value_chain_embedding as classify_value_chain_embedding_func
                try:
                    model = get_embedding_model()
                    if model is not None:
                        is_embedding_active = True
                        logger.info(f"[{company_name}] Value Chain ë¶„ë¥˜ìš© ì„ë² ë”© ëª¨ë¸ ë™ì  ë¡œë“œ ì„±ê³µ")
                except Exception as model_error:
                    logger.debug(f"[{company_name}] ì„ë² ë”© ëª¨ë¸ ë™ì  ë¡œë“œ ì‹¤íŒ¨: {model_error}")
            except ImportError as import_error:
                logger.debug(f"[{company_name}] Value Chain ì„ë² ë”© ëª¨ë“ˆ import ì‹¤íŒ¨: {import_error}")
    
    if not is_embedding_active or classify_value_chain_embedding_func is None:
        logger.warning(f"[{company_name}] ì„ë² ë”© ëª¨ë¸ not available (available={EMBEDDING_AVAILABLE}). Falling back to Rule-based.")
        return [{
            'value_chain': rule_vc,
            'weight': 1.0,
            'confidence': 'MEDIUM' if rule_conf > 0.5 else 'LOW',
            'method': 'RULE_BASED',
            'rule_score': rule_conf,
            'is_primary': True
        }]
    
    try:
        total_segment_chars = sum(len(seg.get('text', '')) for seg in embedding_segments)
        logger.debug(
            f"[{company_name}] ì„ë² ë”© ëª¨ë¸ ë°¸ë¥˜ì²´ì¸ ë¶„ë¥˜ ì‹œë„... "
            f"(segments={len(embedding_segments)}, text ê¸¸ì´={total_segment_chars}ì)"
        )
        
        # í•¨ìˆ˜ê°€ Noneì´ê±°ë‚˜ ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš° ë‹¤ì‹œ import ì‹œë„
        if classify_value_chain_embedding_func is None:
            from app.services.value_chain_classifier_embedding import classify_value_chain_embedding
            classify_value_chain_embedding_func = classify_value_chain_embedding
        
        candidates = classify_value_chain_embedding_func(
            embedding_segments,
            sector_code,
            top_k=3,
            min_threshold=0.3  # 0.4 â†’ 0.3ìœ¼ë¡œ ì¡°ì • (ë” ë§ì€ í›„ë³´ ìƒì„±)
        )
        if candidates:
            logger.info(f"[{company_name}] âœ… ì„ë² ë”© ëª¨ë¸ í›„ë³´ ìƒì„± ì„±ê³µ: {len(candidates)}ê°œ")
        else:
            logger.warning(f"[{company_name}] âš ï¸ ì„ë² ë”© ëª¨ë¸ í›„ë³´ ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” í›„ë³´ ì—†ìŒ (ì„ê³„ê°’ ë¯¸ë‹¬ ë˜ëŠ” í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¬¸ì œ)")
    except Exception as e:
        logger.error(f"[{company_name}] ì„ë² ë”© ëª¨ë¸ ë¶„ë¥˜ ì‹¤íŒ¨: {e}", exc_info=True)
        candidates = []
    
    if not candidates:
        logger.warning(f"[{company_name}] ì„ë² ë”© ëª¨ë¸ í›„ë³´ ì—†ìŒ. Rule ê²°ê³¼ ë°˜í™˜.")
        return [{
            'value_chain': rule_vc,
            'weight': 1.0,
            'confidence': 'MEDIUM' if rule_conf > 0.5 else 'LOW',
            'method': 'RULE_BASED',
            'rule_score': rule_conf,
            'is_primary': True
        }]
    
    # Step 3: BGE-M3 Re-ranking (ì„ íƒì )
    # í™˜ê²½ë³€ìˆ˜ DISABLE_BGE_RERANKER=1ë¡œ ì™„ì „ ë¹„í™œì„±í™” ê°€ëŠ¥
    bge_disabled_by_env = os.environ.get('DISABLE_BGE_RERANKER', '0') == '1'
    if use_reranking and BGE_AVAILABLE and not bge_disabled_by_env:
        try:
            reranked_candidates = rerank_value_chain_candidates(
                company_text,
                sector_code,
                candidates,
                top_k=2
            )
            if reranked_candidates:
                candidates = reranked_candidates
                logger.debug(f"BGE-M3 Re-ranking ì™„ë£Œ: {len(candidates)}ê°œ í›„ë³´")
        except Exception as e:
            logger.warning(f"BGE-M3 Re-ranking ì‹¤íŒ¨, ì›ë³¸ í›„ë³´ ì‚¬ìš©: {e}")
    else:
        # Re-ranking ë¯¸ì‚¬ìš© ì‹œ Top-2ë§Œ ì„ íƒ
        candidates = candidates[:2]
    
    # Step 4: GPT ìµœì¢… ê²€ì¦ (ì„ íƒì , ì¡°ê±´ë¶€ ì‚¬ìš©)
    # ì¡°ê±´ë¶€ GPT í˜¸ì¶œ: Rule confidenceì— ë”°ë¼ ê²°ì •
    # - Rule confidence > 0.85: GPT ìŠ¤í‚µ (ë¹„ìš© ì ˆê°)
    # - Rule confidence 0.70-0.85: BGE-M3ë§Œ ì‚¬ìš© (GPT ìŠ¤í‚µ)
    # - Rule confidence < 0.70: GPT ì‚¬ìš© (ì •í™•ë„ í–¥ìƒ)
    should_use_gpt = use_gpt and GPT_AVAILABLE
    if should_use_gpt:
        if rule_conf > 0.85:
            logger.info(f"[{company_name}] Rule confidence ë†’ìŒ ({rule_conf:.2f}) â†’ GPT ìŠ¤í‚µ (ë¹„ìš© ì ˆê°)")
            should_use_gpt = False
        elif rule_conf > 0.70:
            logger.info(f"[{company_name}] Rule confidence ì¤‘ê°„ ({rule_conf:.2f}) â†’ GPT ìŠ¤í‚µ (BGE-M3ë§Œ ì‚¬ìš©)")
            should_use_gpt = False
        else:
            logger.info(f"[{company_name}] Rule confidence ë‚®ìŒ ({rule_conf:.2f}) â†’ GPT ì‚¬ìš© (ì •í™•ë„ í–¥ìƒ)")
    
    if should_use_gpt:
        # llm_handlerê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±
        if not llm_handler:
            try:
                # OpenAI API í‚¤ë¥¼ ëª…ì‹œì ìœ¼ë¡œ stringìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
                api_key = os.getenv('OPENAI_API_KEY')
                if api_key and callable(api_key):
                    try:
                        api_key = api_key()
                    except Exception as key_error:
                        logger.warning(f"API key callable í˜¸ì¶œ ì‹¤íŒ¨: {key_error}, í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°")
                        api_key = os.getenv('OPENAI_API_KEY')
                
                if api_key:
                    llm_handler = LLMHandler(api_key=str(api_key))  # stringìœ¼ë¡œ ëª…ì‹œì  ë³€í™˜
                else:
                    llm_handler = LLMHandler()  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ê°€ì ¸ì˜¤ê¸°
            except Exception as e:
                logger.warning(f"LLMHandler ìƒì„± ì‹¤íŒ¨, GPT ê²€ì¦ ìŠ¤í‚µ: {e}")
                llm_handler = None
        
        if llm_handler:
            try:
                validated_results = validate_value_chain_with_gpt(
                    company_text,
                    sector_code,
                    company_name,
                    candidates,
                    llm_handler,
                    max_positions=3
                )
                if validated_results:
                    # Rule score ì¶”ê°€
                    for result in validated_results:
                        result['rule_score'] = rule_conf
                    logger.info(f"GPT ê²€ì¦ ì™„ë£Œ: {len(validated_results)}ê°œ ìœ„ì¹˜")
                    return validated_results
            except Exception as e:
                logger.warning(f"GPT ê²€ì¦ ì‹¤íŒ¨, í›„ë³´ ê²°ê³¼ ì‚¬ìš©: {e}")
    
    # GPT ë¯¸ì‚¬ìš© ë˜ëŠ” ì‹¤íŒ¨ ì‹œ í›„ë³´ ê²°ê³¼ ë°˜í™˜
    results = []
    total_score = sum(c.get('similarity', 0.0) or c.get('score', 0.0) for c in candidates)
    
    # â­ Phase 2: value_chain_confidence ë° í˜¼í•© ë¹„ìœ¨ ê³„ì‚°
    vc_confidence = None
    vc_mix = {}
    is_hybrid = False
    
    if len(candidates) >= 2:
        top1_score = candidates[0].get('similarity', 0.0) or candidates[0].get('score', 0.0)
        top2_score = candidates[1].get('similarity', 0.0) or candidates[1].get('score', 0.0)
        # â­ ìŒìˆ˜ ë°©ì§€: max(0.0, top1 - top2)
        vc_confidence = max(0.0, top1_score - top2_score)
        is_hybrid = vc_confidence < 0.1  # gap < 0.1ì´ë©´ Hybrid
        
        # í˜¼í•© ë¹„ìœ¨ ê³„ì‚°
        if is_hybrid:
            total = top1_score + top2_score
            if total > 0:
                vc_mix[candidates[0].get('value_chain', 'MIDSTREAM')] = top1_score / total
                vc_mix[candidates[1].get('value_chain', 'MIDSTREAM')] = top2_score / total
    elif len(candidates) == 1:
        vc_confidence = 1.0  # í›„ë³´ê°€ 1ê°œë©´ confidence ìµœëŒ€
        is_hybrid = False
    
    for i, candidate in enumerate(candidates):
        score = candidate.get('similarity', 0.0) or candidate.get('score', 0.0)
        weight = score / total_score if total_score > 0 else 1.0 / len(candidates)
        vc_code = candidate.get('value_chain', 'MIDSTREAM')
        
        result = {
            'value_chain': vc_code,  # í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€
            'weight': float(weight),
            'confidence': candidate.get('confidence', 'MEDIUM'),
            'method': 'ENSEMBLE',
            'rule_score': rule_conf,
            'embedding_score': score,
            'bge_score': candidate.get('bge_score', None),
            'is_primary': (i == 0),
            'reasoning': f"ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ë¶„ë¥˜ (similarity={score:.2f})"
        }
        
        # â­ Phase 2: ìƒˆë¡œìš´ 5ë‹¨ê³„ ë°¸ë¥˜ì²´ì¸ í•„ë“œ ì¶”ê°€ (ë‹¨ìˆœí™” ë²„ì „)
        if i == 0:  # Primary ê²°ê³¼ì—ë§Œ ì¶”ê°€
            result['value_chain'] = vc_code  # top1
            result['value_chain_confidence'] = vc_confidence
            if is_hybrid and len(candidates) >= 2:
                result['value_chain_detail'] = candidates[1].get('value_chain', 'MIDSTREAM')  # top2 (gap < 0.1ì¼ ë•Œë§Œ)
            else:
                result['value_chain_detail'] = None
            result['is_hybrid'] = is_hybrid
        else:
            # Secondary ê²°ê³¼ëŠ” ê¸°ì¡´ value_chainë§Œ ìœ ì§€
            result['value_chain'] = vc_code
        
        results.append(result)
    
    return results

